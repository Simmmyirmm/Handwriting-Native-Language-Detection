{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b87656f0",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/veeranonthuvasin/Desktop/MSc-Data-Science-Bristol/Dissertation/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from urllib.request import urlopen\n",
        "from PIL import Image\n",
        "import timm\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import ast\n",
        "import glob\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "960d4cd3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>DayOfBirth</th>\n",
              "      <th>EducationalDegree</th>\n",
              "      <th>Gender</th>\n",
              "      <th>NativeCountry</th>\n",
              "      <th>NativeLanguage</th>\n",
              "      <th>OtherLanguage</th>\n",
              "      <th>Profession</th>\n",
              "      <th>WritingType</th>\n",
              "      <th>Science</th>\n",
              "      <th>WrittenLanguage</th>\n",
              "      <th>ascii_path</th>\n",
              "      <th>images_path</th>\n",
              "      <th>stroke_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>French</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['./Data/Bristol-Corpus/Real-World-GrayScale-P...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>German</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['./Data/Bristol-Corpus/Real-World-GrayScale-P...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>German</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['./Data/Bristol-Corpus/Real-World-GrayScale-P...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>French</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['./Data/Bristol-Corpus/Real-World-GrayScale-P...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>French</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['./Data/Bristol-Corpus/Real-World-GrayScale-P...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>German</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['./Data/Bristol-Corpus/Real-World-GrayScale-P...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   name  DayOfBirth  EducationalDegree  Gender  NativeCountry NativeLanguage  \\\n",
              "0     0         NaN                NaN     NaN            NaN         French   \n",
              "1     1         NaN                NaN     NaN            NaN         German   \n",
              "2     3         NaN                NaN     NaN            NaN         German   \n",
              "3     4         NaN                NaN     NaN            NaN         French   \n",
              "4     5         NaN                NaN     NaN            NaN         French   \n",
              "5     6         NaN                NaN     NaN            NaN         German   \n",
              "\n",
              "   OtherLanguage  Profession  WritingType  Science  WrittenLanguage  \\\n",
              "0            NaN         NaN          NaN      NaN              NaN   \n",
              "1            NaN         NaN          NaN      NaN              NaN   \n",
              "2            NaN         NaN          NaN      NaN              NaN   \n",
              "3            NaN         NaN          NaN      NaN              NaN   \n",
              "4            NaN         NaN          NaN      NaN              NaN   \n",
              "5            NaN         NaN          NaN      NaN              NaN   \n",
              "\n",
              "   ascii_path                                        images_path  stroke_path  \n",
              "0         NaN  ['./Data/Bristol-Corpus/Real-World-GrayScale-P...          NaN  \n",
              "1         NaN  ['./Data/Bristol-Corpus/Real-World-GrayScale-P...          NaN  \n",
              "2         NaN  ['./Data/Bristol-Corpus/Real-World-GrayScale-P...          NaN  \n",
              "3         NaN  ['./Data/Bristol-Corpus/Real-World-GrayScale-P...          NaN  \n",
              "4         NaN  ['./Data/Bristol-Corpus/Real-World-GrayScale-P...          NaN  \n",
              "5         NaN  ['./Data/Bristol-Corpus/Real-World-GrayScale-P...          NaN  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "real_world_data = pd.read_csv('../Data/Bristol-Corpus/Real-World-GrayScale-PSM3/real_world_df.csv')\n",
        "\n",
        "real_world_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed8f4577",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NativeLanguage\n",
              "French    3\n",
              "German    3\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "real_world_data['NativeLanguage'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1ea509b",
      "metadata": {},
      "source": [
        "# Utility Functions\n",
        "- Feature Extraction Functions\n",
        "- Change writer label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b804270",
      "metadata": {},
      "outputs": [],
      "source": [
        "def feature_extraction(writer_name, images_path):\n",
        "  model = timm.create_model(\n",
        "      'convnextv2_nano.fcmae_ft_in22k_in1k',\n",
        "      pretrained=True,\n",
        "      num_classes=0,  # remove classifier nn.Linear\n",
        "  )\n",
        "  model = model.eval()\n",
        "\n",
        "  data_config = timm.data.resolve_model_data_config(model)\n",
        "  transforms = timm.data.create_transform(**data_config, is_training=False)\n",
        "\n",
        "  all_features_data = []\n",
        "  writer_id_list = []\n",
        "  writer_forms_list = []\n",
        "  for name, i in tqdm(zip(writer_name,images_path)):\n",
        "      i = ast.literal_eval(i)\n",
        "      for j in i:\n",
        "        j = j.replace('./', '../')\n",
        "        image_list = glob.glob(j)\n",
        "        for k in image_list:\n",
        "          with Image.open(k) as img:\n",
        "            img = img.convert('RGB')\n",
        "            \n",
        "            with torch.no_grad():\n",
        "              output = model(transforms(img).unsqueeze(0))\n",
        "            # print(output)\n",
        "            # features = output.pooler_output.detach().numpy()\n",
        "            # print(features)\n",
        "            # last_hidden_states = outputs.last_hidden_state\n",
        "            # print(last_hidden_states.shape)\n",
        "            # features = last_hidden_states[:, 0, :]\n",
        "            # print(features)\n",
        "            # Store the results\n",
        "            image_form = os.path.splitext(os.path.basename(k))[0]\n",
        "            writer_forms_list.append(image_form)\n",
        "            writer_id_list.append(name)\n",
        "            all_features_data.append(output.detach().flatten().tolist())\n",
        "              \n",
        "\n",
        "\n",
        "  writer_features_df = pd.DataFrame(data=all_features_data)\n",
        "  writer_features_df['name'] = writer_id_list\n",
        "  writer_features_df['form'] = writer_forms_list\n",
        "  return writer_features_df\n",
        "\n",
        "def convert_y(y):\n",
        "  if y == 'German':\n",
        "    return 0\n",
        "  if y == 'French': \n",
        "    return 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18f7d9e2",
      "metadata": {},
      "source": [
        "# Feature Extraction Full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "704f4066",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6it [00:15,  2.55s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>632</th>\n",
              "      <th>633</th>\n",
              "      <th>634</th>\n",
              "      <th>635</th>\n",
              "      <th>636</th>\n",
              "      <th>637</th>\n",
              "      <th>638</th>\n",
              "      <th>639</th>\n",
              "      <th>name</th>\n",
              "      <th>form</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.900881</td>\n",
              "      <td>-1.535855</td>\n",
              "      <td>1.216326</td>\n",
              "      <td>0.263924</td>\n",
              "      <td>0.861893</td>\n",
              "      <td>0.184795</td>\n",
              "      <td>-1.468211</td>\n",
              "      <td>-0.903002</td>\n",
              "      <td>0.471242</td>\n",
              "      <td>-1.091495</td>\n",
              "      <td>...</td>\n",
              "      <td>0.058538</td>\n",
              "      <td>-1.304109</td>\n",
              "      <td>1.541442</td>\n",
              "      <td>-0.424794</td>\n",
              "      <td>-0.802706</td>\n",
              "      <td>1.041371</td>\n",
              "      <td>-0.328758</td>\n",
              "      <td>3.136823</td>\n",
              "      <td>0</td>\n",
              "      <td>page000_line003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.134265</td>\n",
              "      <td>-1.362282</td>\n",
              "      <td>2.273987</td>\n",
              "      <td>0.284600</td>\n",
              "      <td>-0.652768</td>\n",
              "      <td>-0.222237</td>\n",
              "      <td>-0.832183</td>\n",
              "      <td>-1.145109</td>\n",
              "      <td>0.296855</td>\n",
              "      <td>-2.368747</td>\n",
              "      <td>...</td>\n",
              "      <td>0.157107</td>\n",
              "      <td>-1.092878</td>\n",
              "      <td>1.892547</td>\n",
              "      <td>-0.487107</td>\n",
              "      <td>0.093969</td>\n",
              "      <td>2.060857</td>\n",
              "      <td>-1.213497</td>\n",
              "      <td>2.975895</td>\n",
              "      <td>0</td>\n",
              "      <td>page000_line002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.593472</td>\n",
              "      <td>-0.976235</td>\n",
              "      <td>0.744769</td>\n",
              "      <td>0.308163</td>\n",
              "      <td>-0.685127</td>\n",
              "      <td>-0.755348</td>\n",
              "      <td>-2.012943</td>\n",
              "      <td>0.673236</td>\n",
              "      <td>-0.896982</td>\n",
              "      <td>-1.988740</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.753516</td>\n",
              "      <td>-0.608883</td>\n",
              "      <td>1.339883</td>\n",
              "      <td>0.432048</td>\n",
              "      <td>0.636367</td>\n",
              "      <td>1.714106</td>\n",
              "      <td>0.504608</td>\n",
              "      <td>1.266553</td>\n",
              "      <td>0</td>\n",
              "      <td>page000_line000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.280957</td>\n",
              "      <td>-1.285501</td>\n",
              "      <td>1.829224</td>\n",
              "      <td>0.499230</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>0.709289</td>\n",
              "      <td>-1.074080</td>\n",
              "      <td>-1.166486</td>\n",
              "      <td>0.981797</td>\n",
              "      <td>-1.591591</td>\n",
              "      <td>...</td>\n",
              "      <td>0.361287</td>\n",
              "      <td>-0.495855</td>\n",
              "      <td>1.635529</td>\n",
              "      <td>-0.772384</td>\n",
              "      <td>1.012281</td>\n",
              "      <td>2.350589</td>\n",
              "      <td>-0.735705</td>\n",
              "      <td>2.450419</td>\n",
              "      <td>0</td>\n",
              "      <td>page000_line001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.312774</td>\n",
              "      <td>-0.413435</td>\n",
              "      <td>2.063291</td>\n",
              "      <td>0.887190</td>\n",
              "      <td>0.801703</td>\n",
              "      <td>-0.023718</td>\n",
              "      <td>-2.104139</td>\n",
              "      <td>0.721972</td>\n",
              "      <td>0.649561</td>\n",
              "      <td>-2.637098</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.471062</td>\n",
              "      <td>0.093955</td>\n",
              "      <td>0.671852</td>\n",
              "      <td>0.130571</td>\n",
              "      <td>-0.747895</td>\n",
              "      <td>2.493425</td>\n",
              "      <td>-1.339399</td>\n",
              "      <td>1.875247</td>\n",
              "      <td>0</td>\n",
              "      <td>page000_line005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.088423</td>\n",
              "      <td>-0.558079</td>\n",
              "      <td>2.144183</td>\n",
              "      <td>0.348551</td>\n",
              "      <td>-0.823501</td>\n",
              "      <td>-0.331861</td>\n",
              "      <td>-1.095646</td>\n",
              "      <td>0.077632</td>\n",
              "      <td>0.161654</td>\n",
              "      <td>-2.837906</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.645933</td>\n",
              "      <td>-0.706350</td>\n",
              "      <td>0.919395</td>\n",
              "      <td>1.023801</td>\n",
              "      <td>-0.501715</td>\n",
              "      <td>1.016948</td>\n",
              "      <td>-1.168648</td>\n",
              "      <td>1.912641</td>\n",
              "      <td>0</td>\n",
              "      <td>page000_line004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.352457</td>\n",
              "      <td>-1.241885</td>\n",
              "      <td>1.946865</td>\n",
              "      <td>0.645203</td>\n",
              "      <td>-0.915543</td>\n",
              "      <td>-0.268871</td>\n",
              "      <td>-1.386410</td>\n",
              "      <td>-0.908995</td>\n",
              "      <td>0.262660</td>\n",
              "      <td>-2.861198</td>\n",
              "      <td>...</td>\n",
              "      <td>0.164378</td>\n",
              "      <td>0.277399</td>\n",
              "      <td>2.058115</td>\n",
              "      <td>0.161064</td>\n",
              "      <td>0.208770</td>\n",
              "      <td>3.003321</td>\n",
              "      <td>-1.318584</td>\n",
              "      <td>2.281312</td>\n",
              "      <td>0</td>\n",
              "      <td>page000_line006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.507467</td>\n",
              "      <td>-1.915475</td>\n",
              "      <td>2.334567</td>\n",
              "      <td>0.967679</td>\n",
              "      <td>0.755115</td>\n",
              "      <td>0.768464</td>\n",
              "      <td>-1.766531</td>\n",
              "      <td>-0.953910</td>\n",
              "      <td>0.261470</td>\n",
              "      <td>-2.457000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.438582</td>\n",
              "      <td>-0.710739</td>\n",
              "      <td>1.944403</td>\n",
              "      <td>-0.137118</td>\n",
              "      <td>-0.349195</td>\n",
              "      <td>2.496340</td>\n",
              "      <td>-0.891258</td>\n",
              "      <td>2.711566</td>\n",
              "      <td>0</td>\n",
              "      <td>page000_line007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.369867</td>\n",
              "      <td>-1.144850</td>\n",
              "      <td>2.374497</td>\n",
              "      <td>1.486444</td>\n",
              "      <td>0.057034</td>\n",
              "      <td>0.659323</td>\n",
              "      <td>-0.906150</td>\n",
              "      <td>-0.305979</td>\n",
              "      <td>-0.087208</td>\n",
              "      <td>-2.945641</td>\n",
              "      <td>...</td>\n",
              "      <td>0.621893</td>\n",
              "      <td>-1.044549</td>\n",
              "      <td>1.939120</td>\n",
              "      <td>0.076557</td>\n",
              "      <td>0.389761</td>\n",
              "      <td>1.469566</td>\n",
              "      <td>-0.691275</td>\n",
              "      <td>1.780019</td>\n",
              "      <td>0</td>\n",
              "      <td>page000_line008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.611749</td>\n",
              "      <td>-2.095418</td>\n",
              "      <td>0.496747</td>\n",
              "      <td>1.899151</td>\n",
              "      <td>-0.842998</td>\n",
              "      <td>0.447551</td>\n",
              "      <td>-1.261050</td>\n",
              "      <td>-2.167131</td>\n",
              "      <td>1.413064</td>\n",
              "      <td>-2.242526</td>\n",
              "      <td>...</td>\n",
              "      <td>0.244677</td>\n",
              "      <td>-0.928682</td>\n",
              "      <td>1.154003</td>\n",
              "      <td>-0.196702</td>\n",
              "      <td>-1.030584</td>\n",
              "      <td>1.451702</td>\n",
              "      <td>-0.573324</td>\n",
              "      <td>0.096913</td>\n",
              "      <td>1</td>\n",
              "      <td>page000_line003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-2.290432</td>\n",
              "      <td>-1.823981</td>\n",
              "      <td>-0.245025</td>\n",
              "      <td>1.480978</td>\n",
              "      <td>-0.356717</td>\n",
              "      <td>0.568426</td>\n",
              "      <td>-0.646507</td>\n",
              "      <td>-2.733148</td>\n",
              "      <td>2.006800</td>\n",
              "      <td>-2.515923</td>\n",
              "      <td>...</td>\n",
              "      <td>0.518083</td>\n",
              "      <td>0.408829</td>\n",
              "      <td>0.237417</td>\n",
              "      <td>0.417480</td>\n",
              "      <td>0.410241</td>\n",
              "      <td>1.516244</td>\n",
              "      <td>-0.792029</td>\n",
              "      <td>-1.057558</td>\n",
              "      <td>1</td>\n",
              "      <td>page000_line002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.207571</td>\n",
              "      <td>-1.161908</td>\n",
              "      <td>-0.629806</td>\n",
              "      <td>1.927256</td>\n",
              "      <td>0.069100</td>\n",
              "      <td>0.012873</td>\n",
              "      <td>-0.593543</td>\n",
              "      <td>-1.862664</td>\n",
              "      <td>1.482231</td>\n",
              "      <td>-1.305336</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.328434</td>\n",
              "      <td>-0.731346</td>\n",
              "      <td>0.970486</td>\n",
              "      <td>1.150844</td>\n",
              "      <td>-0.227760</td>\n",
              "      <td>0.252524</td>\n",
              "      <td>0.596436</td>\n",
              "      <td>-0.253897</td>\n",
              "      <td>1</td>\n",
              "      <td>page000_line000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-1.589233</td>\n",
              "      <td>-1.054851</td>\n",
              "      <td>-0.275232</td>\n",
              "      <td>2.352102</td>\n",
              "      <td>-1.657410</td>\n",
              "      <td>0.068928</td>\n",
              "      <td>-0.326524</td>\n",
              "      <td>-2.286921</td>\n",
              "      <td>1.303765</td>\n",
              "      <td>-1.600224</td>\n",
              "      <td>...</td>\n",
              "      <td>0.040765</td>\n",
              "      <td>-0.186851</td>\n",
              "      <td>1.600801</td>\n",
              "      <td>-1.122975</td>\n",
              "      <td>-0.408834</td>\n",
              "      <td>3.436998</td>\n",
              "      <td>-1.169829</td>\n",
              "      <td>0.025704</td>\n",
              "      <td>1</td>\n",
              "      <td>page000_line001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-0.566000</td>\n",
              "      <td>-1.090448</td>\n",
              "      <td>0.432487</td>\n",
              "      <td>1.193386</td>\n",
              "      <td>-0.284967</td>\n",
              "      <td>0.979698</td>\n",
              "      <td>-1.883320</td>\n",
              "      <td>-2.088283</td>\n",
              "      <td>1.133648</td>\n",
              "      <td>-1.532070</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.282095</td>\n",
              "      <td>-0.349165</td>\n",
              "      <td>0.040628</td>\n",
              "      <td>0.709523</td>\n",
              "      <td>-0.784128</td>\n",
              "      <td>1.829252</td>\n",
              "      <td>-1.324068</td>\n",
              "      <td>0.003215</td>\n",
              "      <td>1</td>\n",
              "      <td>page000_line005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.757621</td>\n",
              "      <td>-0.894421</td>\n",
              "      <td>0.013984</td>\n",
              "      <td>2.179670</td>\n",
              "      <td>-1.608992</td>\n",
              "      <td>0.379539</td>\n",
              "      <td>-1.496733</td>\n",
              "      <td>-1.766940</td>\n",
              "      <td>1.191479</td>\n",
              "      <td>-2.852113</td>\n",
              "      <td>...</td>\n",
              "      <td>0.270399</td>\n",
              "      <td>-1.446855</td>\n",
              "      <td>0.904377</td>\n",
              "      <td>0.191518</td>\n",
              "      <td>-1.545192</td>\n",
              "      <td>2.216811</td>\n",
              "      <td>-1.141569</td>\n",
              "      <td>-1.106837</td>\n",
              "      <td>1</td>\n",
              "      <td>page000_line004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-1.511285</td>\n",
              "      <td>-0.159393</td>\n",
              "      <td>-1.285892</td>\n",
              "      <td>0.883206</td>\n",
              "      <td>-0.240112</td>\n",
              "      <td>-0.082843</td>\n",
              "      <td>-1.698460</td>\n",
              "      <td>-0.617277</td>\n",
              "      <td>0.631346</td>\n",
              "      <td>-0.851741</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.025800</td>\n",
              "      <td>-0.099167</td>\n",
              "      <td>0.538432</td>\n",
              "      <td>1.420944</td>\n",
              "      <td>-0.220729</td>\n",
              "      <td>1.039717</td>\n",
              "      <td>-0.968723</td>\n",
              "      <td>1.182505</td>\n",
              "      <td>3</td>\n",
              "      <td>page000_line003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-0.915069</td>\n",
              "      <td>0.126906</td>\n",
              "      <td>-1.253779</td>\n",
              "      <td>1.961727</td>\n",
              "      <td>-0.480075</td>\n",
              "      <td>0.358586</td>\n",
              "      <td>-1.083527</td>\n",
              "      <td>-0.397470</td>\n",
              "      <td>0.726015</td>\n",
              "      <td>-0.928387</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.101263</td>\n",
              "      <td>1.035422</td>\n",
              "      <td>1.443239</td>\n",
              "      <td>1.378848</td>\n",
              "      <td>0.203002</td>\n",
              "      <td>2.551162</td>\n",
              "      <td>-1.204188</td>\n",
              "      <td>1.095948</td>\n",
              "      <td>3</td>\n",
              "      <td>page000_line002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-1.399246</td>\n",
              "      <td>-0.449594</td>\n",
              "      <td>-0.050102</td>\n",
              "      <td>0.851918</td>\n",
              "      <td>-0.061686</td>\n",
              "      <td>0.489559</td>\n",
              "      <td>-1.947546</td>\n",
              "      <td>-0.186119</td>\n",
              "      <td>0.788533</td>\n",
              "      <td>-0.059928</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.674960</td>\n",
              "      <td>-0.008328</td>\n",
              "      <td>1.219678</td>\n",
              "      <td>0.704170</td>\n",
              "      <td>0.378878</td>\n",
              "      <td>1.588672</td>\n",
              "      <td>-0.762329</td>\n",
              "      <td>1.949395</td>\n",
              "      <td>3</td>\n",
              "      <td>page000_line001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>-0.400874</td>\n",
              "      <td>-0.573764</td>\n",
              "      <td>0.262399</td>\n",
              "      <td>1.218095</td>\n",
              "      <td>-1.354946</td>\n",
              "      <td>-0.158789</td>\n",
              "      <td>-1.226880</td>\n",
              "      <td>-1.198591</td>\n",
              "      <td>1.332944</td>\n",
              "      <td>-0.620245</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.091506</td>\n",
              "      <td>-0.495805</td>\n",
              "      <td>1.265438</td>\n",
              "      <td>-0.169847</td>\n",
              "      <td>1.055912</td>\n",
              "      <td>0.814413</td>\n",
              "      <td>-0.812493</td>\n",
              "      <td>1.728397</td>\n",
              "      <td>3</td>\n",
              "      <td>page000_line011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-0.533533</td>\n",
              "      <td>-0.670471</td>\n",
              "      <td>0.355615</td>\n",
              "      <td>0.896869</td>\n",
              "      <td>-0.754374</td>\n",
              "      <td>-0.275247</td>\n",
              "      <td>-0.353749</td>\n",
              "      <td>-0.542393</td>\n",
              "      <td>1.092196</td>\n",
              "      <td>-0.064769</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.027692</td>\n",
              "      <td>0.260945</td>\n",
              "      <td>0.967058</td>\n",
              "      <td>0.834612</td>\n",
              "      <td>0.744693</td>\n",
              "      <td>1.368777</td>\n",
              "      <td>-0.804311</td>\n",
              "      <td>0.008971</td>\n",
              "      <td>3</td>\n",
              "      <td>page000_line004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.068758</td>\n",
              "      <td>0.346009</td>\n",
              "      <td>-0.542015</td>\n",
              "      <td>1.277306</td>\n",
              "      <td>-0.596175</td>\n",
              "      <td>-0.407558</td>\n",
              "      <td>-0.964712</td>\n",
              "      <td>-0.631917</td>\n",
              "      <td>0.919562</td>\n",
              "      <td>-0.919415</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.815364</td>\n",
              "      <td>1.021727</td>\n",
              "      <td>0.367840</td>\n",
              "      <td>1.065763</td>\n",
              "      <td>0.284883</td>\n",
              "      <td>1.136353</td>\n",
              "      <td>-0.157914</td>\n",
              "      <td>0.340986</td>\n",
              "      <td>3</td>\n",
              "      <td>page000_line010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>-0.444731</td>\n",
              "      <td>0.605384</td>\n",
              "      <td>-0.279393</td>\n",
              "      <td>0.143534</td>\n",
              "      <td>0.397796</td>\n",
              "      <td>1.124081</td>\n",
              "      <td>-2.198709</td>\n",
              "      <td>-1.187628</td>\n",
              "      <td>-0.474654</td>\n",
              "      <td>-0.966479</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.146562</td>\n",
              "      <td>0.336720</td>\n",
              "      <td>0.784339</td>\n",
              "      <td>1.202369</td>\n",
              "      <td>-0.798215</td>\n",
              "      <td>1.212639</td>\n",
              "      <td>0.039807</td>\n",
              "      <td>0.586837</td>\n",
              "      <td>3</td>\n",
              "      <td>page000_line006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-0.397368</td>\n",
              "      <td>-0.024730</td>\n",
              "      <td>0.542317</td>\n",
              "      <td>0.416974</td>\n",
              "      <td>-0.672300</td>\n",
              "      <td>-0.102507</td>\n",
              "      <td>-1.310768</td>\n",
              "      <td>-1.528256</td>\n",
              "      <td>1.811763</td>\n",
              "      <td>-0.126442</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.013625</td>\n",
              "      <td>-0.614783</td>\n",
              "      <td>1.282822</td>\n",
              "      <td>0.886146</td>\n",
              "      <td>0.687368</td>\n",
              "      <td>-0.209796</td>\n",
              "      <td>-0.947312</td>\n",
              "      <td>1.506792</td>\n",
              "      <td>3</td>\n",
              "      <td>page000_line012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.548182</td>\n",
              "      <td>-0.110832</td>\n",
              "      <td>-0.298195</td>\n",
              "      <td>1.482604</td>\n",
              "      <td>0.476659</td>\n",
              "      <td>0.750116</td>\n",
              "      <td>-1.455401</td>\n",
              "      <td>-0.521254</td>\n",
              "      <td>-0.555038</td>\n",
              "      <td>-1.956491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.474841</td>\n",
              "      <td>1.053458</td>\n",
              "      <td>1.735331</td>\n",
              "      <td>0.864692</td>\n",
              "      <td>-1.156795</td>\n",
              "      <td>1.644365</td>\n",
              "      <td>-0.368903</td>\n",
              "      <td>1.727635</td>\n",
              "      <td>3</td>\n",
              "      <td>page000_line007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>-0.899175</td>\n",
              "      <td>-0.069753</td>\n",
              "      <td>0.300784</td>\n",
              "      <td>1.329214</td>\n",
              "      <td>0.137482</td>\n",
              "      <td>0.115308</td>\n",
              "      <td>-1.185902</td>\n",
              "      <td>0.520195</td>\n",
              "      <td>0.858706</td>\n",
              "      <td>-0.186683</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.164044</td>\n",
              "      <td>0.219707</td>\n",
              "      <td>0.772808</td>\n",
              "      <td>0.317163</td>\n",
              "      <td>0.655635</td>\n",
              "      <td>0.852677</td>\n",
              "      <td>-0.745911</td>\n",
              "      <td>2.183578</td>\n",
              "      <td>3</td>\n",
              "      <td>page000_line009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.284822</td>\n",
              "      <td>0.144479</td>\n",
              "      <td>1.242482</td>\n",
              "      <td>0.102223</td>\n",
              "      <td>0.683352</td>\n",
              "      <td>-0.399493</td>\n",
              "      <td>-2.077096</td>\n",
              "      <td>-0.811740</td>\n",
              "      <td>-0.200744</td>\n",
              "      <td>0.034794</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042854</td>\n",
              "      <td>-0.243000</td>\n",
              "      <td>0.752491</td>\n",
              "      <td>0.674273</td>\n",
              "      <td>-1.771868</td>\n",
              "      <td>1.580923</td>\n",
              "      <td>-1.103293</td>\n",
              "      <td>0.902760</td>\n",
              "      <td>4</td>\n",
              "      <td>page000_line017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>-1.417261</td>\n",
              "      <td>-0.195526</td>\n",
              "      <td>1.855916</td>\n",
              "      <td>-0.288126</td>\n",
              "      <td>-0.700317</td>\n",
              "      <td>0.378725</td>\n",
              "      <td>-1.840963</td>\n",
              "      <td>0.380007</td>\n",
              "      <td>0.541137</td>\n",
              "      <td>-1.394863</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.626281</td>\n",
              "      <td>-0.301799</td>\n",
              "      <td>1.171829</td>\n",
              "      <td>1.421664</td>\n",
              "      <td>-1.447193</td>\n",
              "      <td>1.612703</td>\n",
              "      <td>-0.498627</td>\n",
              "      <td>1.497717</td>\n",
              "      <td>4</td>\n",
              "      <td>page000_line002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.821136</td>\n",
              "      <td>-0.514354</td>\n",
              "      <td>1.380523</td>\n",
              "      <td>1.737670</td>\n",
              "      <td>0.180128</td>\n",
              "      <td>-0.046532</td>\n",
              "      <td>-1.691870</td>\n",
              "      <td>-1.303176</td>\n",
              "      <td>1.069632</td>\n",
              "      <td>-0.133193</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.534704</td>\n",
              "      <td>-0.607059</td>\n",
              "      <td>1.583575</td>\n",
              "      <td>0.309247</td>\n",
              "      <td>-0.134333</td>\n",
              "      <td>1.478819</td>\n",
              "      <td>-0.539329</td>\n",
              "      <td>2.961042</td>\n",
              "      <td>4</td>\n",
              "      <td>page000_line000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.760303</td>\n",
              "      <td>0.895791</td>\n",
              "      <td>1.491342</td>\n",
              "      <td>1.343078</td>\n",
              "      <td>-1.067421</td>\n",
              "      <td>-0.851370</td>\n",
              "      <td>-2.226929</td>\n",
              "      <td>-0.464046</td>\n",
              "      <td>0.225262</td>\n",
              "      <td>-1.644391</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.097913</td>\n",
              "      <td>-0.260226</td>\n",
              "      <td>0.071615</td>\n",
              "      <td>0.132198</td>\n",
              "      <td>-0.743547</td>\n",
              "      <td>2.387686</td>\n",
              "      <td>-2.363768</td>\n",
              "      <td>0.895487</td>\n",
              "      <td>4</td>\n",
              "      <td>page000_line015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>-0.041007</td>\n",
              "      <td>1.633261</td>\n",
              "      <td>1.741746</td>\n",
              "      <td>0.625358</td>\n",
              "      <td>-2.341788</td>\n",
              "      <td>0.233289</td>\n",
              "      <td>-0.732800</td>\n",
              "      <td>0.654997</td>\n",
              "      <td>0.318321</td>\n",
              "      <td>-2.387836</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.583906</td>\n",
              "      <td>-1.380787</td>\n",
              "      <td>0.505839</td>\n",
              "      <td>1.876584</td>\n",
              "      <td>-1.684255</td>\n",
              "      <td>1.480990</td>\n",
              "      <td>-0.773467</td>\n",
              "      <td>0.373090</td>\n",
              "      <td>4</td>\n",
              "      <td>page000_line010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>-1.236749</td>\n",
              "      <td>0.548504</td>\n",
              "      <td>1.412555</td>\n",
              "      <td>1.065041</td>\n",
              "      <td>-1.589259</td>\n",
              "      <td>1.144025</td>\n",
              "      <td>-1.113644</td>\n",
              "      <td>0.296600</td>\n",
              "      <td>0.547062</td>\n",
              "      <td>-1.320060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.442539</td>\n",
              "      <td>-0.172453</td>\n",
              "      <td>0.856218</td>\n",
              "      <td>1.816082</td>\n",
              "      <td>-0.560511</td>\n",
              "      <td>2.593247</td>\n",
              "      <td>-0.520242</td>\n",
              "      <td>0.937336</td>\n",
              "      <td>4</td>\n",
              "      <td>page000_line007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>-0.675129</td>\n",
              "      <td>-0.100372</td>\n",
              "      <td>0.126636</td>\n",
              "      <td>1.903031</td>\n",
              "      <td>-0.932906</td>\n",
              "      <td>-0.029992</td>\n",
              "      <td>-1.508575</td>\n",
              "      <td>-0.105283</td>\n",
              "      <td>0.430275</td>\n",
              "      <td>0.556498</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.010932</td>\n",
              "      <td>-0.733464</td>\n",
              "      <td>1.022323</td>\n",
              "      <td>0.607367</td>\n",
              "      <td>0.387326</td>\n",
              "      <td>-0.199046</td>\n",
              "      <td>-0.843895</td>\n",
              "      <td>1.147886</td>\n",
              "      <td>4</td>\n",
              "      <td>page000_line018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.822720</td>\n",
              "      <td>0.914817</td>\n",
              "      <td>1.206195</td>\n",
              "      <td>-0.679650</td>\n",
              "      <td>-0.894523</td>\n",
              "      <td>0.185949</td>\n",
              "      <td>-1.684727</td>\n",
              "      <td>0.270091</td>\n",
              "      <td>0.664255</td>\n",
              "      <td>-1.572916</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.540149</td>\n",
              "      <td>0.325710</td>\n",
              "      <td>0.972612</td>\n",
              "      <td>0.808860</td>\n",
              "      <td>-1.446238</td>\n",
              "      <td>2.323844</td>\n",
              "      <td>-1.479796</td>\n",
              "      <td>1.605714</td>\n",
              "      <td>4</td>\n",
              "      <td>page000_line019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>-0.458307</td>\n",
              "      <td>-0.958887</td>\n",
              "      <td>0.033891</td>\n",
              "      <td>0.733709</td>\n",
              "      <td>-1.697282</td>\n",
              "      <td>0.062691</td>\n",
              "      <td>-0.451608</td>\n",
              "      <td>-0.958972</td>\n",
              "      <td>0.942517</td>\n",
              "      <td>-0.618566</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.634955</td>\n",
              "      <td>0.610513</td>\n",
              "      <td>1.195423</td>\n",
              "      <td>-0.118988</td>\n",
              "      <td>0.832401</td>\n",
              "      <td>1.701328</td>\n",
              "      <td>-0.965071</td>\n",
              "      <td>0.606653</td>\n",
              "      <td>5</td>\n",
              "      <td>page000_line003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>-0.445179</td>\n",
              "      <td>0.306864</td>\n",
              "      <td>0.132252</td>\n",
              "      <td>0.909049</td>\n",
              "      <td>0.891211</td>\n",
              "      <td>1.804006</td>\n",
              "      <td>-0.754798</td>\n",
              "      <td>-1.965100</td>\n",
              "      <td>0.157875</td>\n",
              "      <td>-0.436323</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.707230</td>\n",
              "      <td>1.010410</td>\n",
              "      <td>0.389437</td>\n",
              "      <td>0.302703</td>\n",
              "      <td>0.415911</td>\n",
              "      <td>2.397123</td>\n",
              "      <td>0.484518</td>\n",
              "      <td>0.141263</td>\n",
              "      <td>5</td>\n",
              "      <td>page000_line002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>-0.252033</td>\n",
              "      <td>-0.476010</td>\n",
              "      <td>0.220876</td>\n",
              "      <td>0.839237</td>\n",
              "      <td>-1.177432</td>\n",
              "      <td>0.260475</td>\n",
              "      <td>-0.280225</td>\n",
              "      <td>-0.906387</td>\n",
              "      <td>0.332400</td>\n",
              "      <td>-1.462990</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.287458</td>\n",
              "      <td>1.036865</td>\n",
              "      <td>1.163799</td>\n",
              "      <td>-0.082156</td>\n",
              "      <td>-0.498177</td>\n",
              "      <td>2.336817</td>\n",
              "      <td>-0.725767</td>\n",
              "      <td>0.363254</td>\n",
              "      <td>5</td>\n",
              "      <td>page000_line000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>-0.677300</td>\n",
              "      <td>-1.044457</td>\n",
              "      <td>-0.132667</td>\n",
              "      <td>0.260955</td>\n",
              "      <td>-1.494067</td>\n",
              "      <td>-0.060972</td>\n",
              "      <td>-0.560856</td>\n",
              "      <td>-0.633262</td>\n",
              "      <td>0.928054</td>\n",
              "      <td>-0.655661</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.441678</td>\n",
              "      <td>0.718351</td>\n",
              "      <td>1.001258</td>\n",
              "      <td>0.492759</td>\n",
              "      <td>0.786731</td>\n",
              "      <td>1.663528</td>\n",
              "      <td>-0.647642</td>\n",
              "      <td>0.667600</td>\n",
              "      <td>5</td>\n",
              "      <td>page000_line001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>-0.309948</td>\n",
              "      <td>-0.487609</td>\n",
              "      <td>-0.666604</td>\n",
              "      <td>-0.209792</td>\n",
              "      <td>-0.239032</td>\n",
              "      <td>0.296499</td>\n",
              "      <td>-0.499096</td>\n",
              "      <td>-1.200930</td>\n",
              "      <td>0.313259</td>\n",
              "      <td>-0.516922</td>\n",
              "      <td>...</td>\n",
              "      <td>0.722910</td>\n",
              "      <td>0.663737</td>\n",
              "      <td>0.804323</td>\n",
              "      <td>0.604769</td>\n",
              "      <td>-0.081573</td>\n",
              "      <td>2.726238</td>\n",
              "      <td>-0.843379</td>\n",
              "      <td>-0.493157</td>\n",
              "      <td>5</td>\n",
              "      <td>page000_line005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>-1.014642</td>\n",
              "      <td>-0.620240</td>\n",
              "      <td>-0.015325</td>\n",
              "      <td>-0.020156</td>\n",
              "      <td>-0.255930</td>\n",
              "      <td>0.195686</td>\n",
              "      <td>-0.450148</td>\n",
              "      <td>0.205388</td>\n",
              "      <td>0.008288</td>\n",
              "      <td>-0.246765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.685066</td>\n",
              "      <td>0.696252</td>\n",
              "      <td>1.672011</td>\n",
              "      <td>-0.140407</td>\n",
              "      <td>-0.659373</td>\n",
              "      <td>1.700073</td>\n",
              "      <td>-0.392945</td>\n",
              "      <td>0.668212</td>\n",
              "      <td>5</td>\n",
              "      <td>page000_line004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.016063</td>\n",
              "      <td>-0.432868</td>\n",
              "      <td>0.193906</td>\n",
              "      <td>0.723087</td>\n",
              "      <td>-1.509290</td>\n",
              "      <td>0.137060</td>\n",
              "      <td>-0.258605</td>\n",
              "      <td>-0.686176</td>\n",
              "      <td>0.678195</td>\n",
              "      <td>-0.838486</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.594982</td>\n",
              "      <td>0.161270</td>\n",
              "      <td>1.042325</td>\n",
              "      <td>0.256729</td>\n",
              "      <td>0.359362</td>\n",
              "      <td>1.790579</td>\n",
              "      <td>-1.126071</td>\n",
              "      <td>0.215241</td>\n",
              "      <td>5</td>\n",
              "      <td>page000_line006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>-0.930825</td>\n",
              "      <td>-0.975236</td>\n",
              "      <td>0.020694</td>\n",
              "      <td>-0.367364</td>\n",
              "      <td>-1.166840</td>\n",
              "      <td>0.080084</td>\n",
              "      <td>-0.683109</td>\n",
              "      <td>-0.879427</td>\n",
              "      <td>0.645276</td>\n",
              "      <td>-0.609716</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.961264</td>\n",
              "      <td>0.433916</td>\n",
              "      <td>1.019151</td>\n",
              "      <td>0.424877</td>\n",
              "      <td>0.402371</td>\n",
              "      <td>0.975544</td>\n",
              "      <td>-0.754261</td>\n",
              "      <td>0.599763</td>\n",
              "      <td>5</td>\n",
              "      <td>page000_line007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>-0.381054</td>\n",
              "      <td>0.377363</td>\n",
              "      <td>-0.349268</td>\n",
              "      <td>1.053214</td>\n",
              "      <td>-0.778858</td>\n",
              "      <td>0.223258</td>\n",
              "      <td>0.133051</td>\n",
              "      <td>-0.763046</td>\n",
              "      <td>0.515453</td>\n",
              "      <td>-1.888904</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.357223</td>\n",
              "      <td>0.837642</td>\n",
              "      <td>1.390144</td>\n",
              "      <td>0.551295</td>\n",
              "      <td>-0.113882</td>\n",
              "      <td>2.524674</td>\n",
              "      <td>-0.827479</td>\n",
              "      <td>0.618074</td>\n",
              "      <td>5</td>\n",
              "      <td>page000_line009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>-0.482022</td>\n",
              "      <td>-0.530190</td>\n",
              "      <td>0.555034</td>\n",
              "      <td>0.061592</td>\n",
              "      <td>-1.501323</td>\n",
              "      <td>0.552592</td>\n",
              "      <td>-0.453617</td>\n",
              "      <td>-0.881997</td>\n",
              "      <td>1.265358</td>\n",
              "      <td>-0.469314</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.759997</td>\n",
              "      <td>-0.130000</td>\n",
              "      <td>1.045778</td>\n",
              "      <td>0.133436</td>\n",
              "      <td>0.532937</td>\n",
              "      <td>1.433050</td>\n",
              "      <td>-0.866951</td>\n",
              "      <td>0.660781</td>\n",
              "      <td>5</td>\n",
              "      <td>page000_line008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>-0.425163</td>\n",
              "      <td>-0.889256</td>\n",
              "      <td>0.680910</td>\n",
              "      <td>1.174501</td>\n",
              "      <td>-0.299338</td>\n",
              "      <td>1.439548</td>\n",
              "      <td>-1.017437</td>\n",
              "      <td>-2.315849</td>\n",
              "      <td>1.217635</td>\n",
              "      <td>-2.012322</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.548484</td>\n",
              "      <td>-0.967192</td>\n",
              "      <td>0.089741</td>\n",
              "      <td>0.390196</td>\n",
              "      <td>-0.447207</td>\n",
              "      <td>1.349188</td>\n",
              "      <td>-0.345251</td>\n",
              "      <td>-0.153885</td>\n",
              "      <td>6</td>\n",
              "      <td>page000_line003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>-0.371337</td>\n",
              "      <td>-1.743062</td>\n",
              "      <td>0.156865</td>\n",
              "      <td>1.695572</td>\n",
              "      <td>-0.686044</td>\n",
              "      <td>0.506810</td>\n",
              "      <td>-1.419559</td>\n",
              "      <td>-2.573834</td>\n",
              "      <td>2.023610</td>\n",
              "      <td>-1.558440</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.066427</td>\n",
              "      <td>-1.449065</td>\n",
              "      <td>1.377814</td>\n",
              "      <td>0.322283</td>\n",
              "      <td>-1.037573</td>\n",
              "      <td>1.489391</td>\n",
              "      <td>-0.015439</td>\n",
              "      <td>0.281922</td>\n",
              "      <td>6</td>\n",
              "      <td>page000_line002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>-1.375505</td>\n",
              "      <td>-1.034224</td>\n",
              "      <td>0.728940</td>\n",
              "      <td>1.947940</td>\n",
              "      <td>-1.999517</td>\n",
              "      <td>0.405978</td>\n",
              "      <td>-1.565957</td>\n",
              "      <td>-2.758316</td>\n",
              "      <td>1.679069</td>\n",
              "      <td>-2.602715</td>\n",
              "      <td>...</td>\n",
              "      <td>0.782819</td>\n",
              "      <td>-1.618669</td>\n",
              "      <td>1.490047</td>\n",
              "      <td>-0.033443</td>\n",
              "      <td>-1.110051</td>\n",
              "      <td>2.042918</td>\n",
              "      <td>-1.068701</td>\n",
              "      <td>0.377701</td>\n",
              "      <td>6</td>\n",
              "      <td>page000_line000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>-1.546735</td>\n",
              "      <td>-0.665076</td>\n",
              "      <td>0.014008</td>\n",
              "      <td>2.013012</td>\n",
              "      <td>-0.570232</td>\n",
              "      <td>0.899402</td>\n",
              "      <td>-0.864737</td>\n",
              "      <td>-2.181496</td>\n",
              "      <td>1.139154</td>\n",
              "      <td>-2.252067</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.292332</td>\n",
              "      <td>-0.215581</td>\n",
              "      <td>0.287592</td>\n",
              "      <td>0.188674</td>\n",
              "      <td>-0.013113</td>\n",
              "      <td>2.173856</td>\n",
              "      <td>-0.742428</td>\n",
              "      <td>-0.962788</td>\n",
              "      <td>6</td>\n",
              "      <td>page000_line001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47 rows × 642 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2         3         4         5         6  \\\n",
              "0   0.900881 -1.535855  1.216326  0.263924  0.861893  0.184795 -1.468211   \n",
              "1   1.134265 -1.362282  2.273987  0.284600 -0.652768 -0.222237 -0.832183   \n",
              "2   0.593472 -0.976235  0.744769  0.308163 -0.685127 -0.755348 -2.012943   \n",
              "3   1.280957 -1.285501  1.829224  0.499230 -0.052572  0.709289 -1.074080   \n",
              "4   1.312774 -0.413435  2.063291  0.887190  0.801703 -0.023718 -2.104139   \n",
              "5  -0.088423 -0.558079  2.144183  0.348551 -0.823501 -0.331861 -1.095646   \n",
              "6   1.352457 -1.241885  1.946865  0.645203 -0.915543 -0.268871 -1.386410   \n",
              "7   1.507467 -1.915475  2.334567  0.967679  0.755115  0.768464 -1.766531   \n",
              "8   1.369867 -1.144850  2.374497  1.486444  0.057034  0.659323 -0.906150   \n",
              "9  -0.611749 -2.095418  0.496747  1.899151 -0.842998  0.447551 -1.261050   \n",
              "10 -2.290432 -1.823981 -0.245025  1.480978 -0.356717  0.568426 -0.646507   \n",
              "11  0.207571 -1.161908 -0.629806  1.927256  0.069100  0.012873 -0.593543   \n",
              "12 -1.589233 -1.054851 -0.275232  2.352102 -1.657410  0.068928 -0.326524   \n",
              "13 -0.566000 -1.090448  0.432487  1.193386 -0.284967  0.979698 -1.883320   \n",
              "14 -0.757621 -0.894421  0.013984  2.179670 -1.608992  0.379539 -1.496733   \n",
              "15 -1.511285 -0.159393 -1.285892  0.883206 -0.240112 -0.082843 -1.698460   \n",
              "16 -0.915069  0.126906 -1.253779  1.961727 -0.480075  0.358586 -1.083527   \n",
              "17 -1.399246 -0.449594 -0.050102  0.851918 -0.061686  0.489559 -1.947546   \n",
              "18 -0.400874 -0.573764  0.262399  1.218095 -1.354946 -0.158789 -1.226880   \n",
              "19 -0.533533 -0.670471  0.355615  0.896869 -0.754374 -0.275247 -0.353749   \n",
              "20  0.068758  0.346009 -0.542015  1.277306 -0.596175 -0.407558 -0.964712   \n",
              "21 -0.444731  0.605384 -0.279393  0.143534  0.397796  1.124081 -2.198709   \n",
              "22 -0.397368 -0.024730  0.542317  0.416974 -0.672300 -0.102507 -1.310768   \n",
              "23  0.548182 -0.110832 -0.298195  1.482604  0.476659  0.750116 -1.455401   \n",
              "24 -0.899175 -0.069753  0.300784  1.329214  0.137482  0.115308 -1.185902   \n",
              "25  0.284822  0.144479  1.242482  0.102223  0.683352 -0.399493 -2.077096   \n",
              "26 -1.417261 -0.195526  1.855916 -0.288126 -0.700317  0.378725 -1.840963   \n",
              "27  0.821136 -0.514354  1.380523  1.737670  0.180128 -0.046532 -1.691870   \n",
              "28  0.760303  0.895791  1.491342  1.343078 -1.067421 -0.851370 -2.226929   \n",
              "29 -0.041007  1.633261  1.741746  0.625358 -2.341788  0.233289 -0.732800   \n",
              "30 -1.236749  0.548504  1.412555  1.065041 -1.589259  1.144025 -1.113644   \n",
              "31 -0.675129 -0.100372  0.126636  1.903031 -0.932906 -0.029992 -1.508575   \n",
              "32  0.822720  0.914817  1.206195 -0.679650 -0.894523  0.185949 -1.684727   \n",
              "33 -0.458307 -0.958887  0.033891  0.733709 -1.697282  0.062691 -0.451608   \n",
              "34 -0.445179  0.306864  0.132252  0.909049  0.891211  1.804006 -0.754798   \n",
              "35 -0.252033 -0.476010  0.220876  0.839237 -1.177432  0.260475 -0.280225   \n",
              "36 -0.677300 -1.044457 -0.132667  0.260955 -1.494067 -0.060972 -0.560856   \n",
              "37 -0.309948 -0.487609 -0.666604 -0.209792 -0.239032  0.296499 -0.499096   \n",
              "38 -1.014642 -0.620240 -0.015325 -0.020156 -0.255930  0.195686 -0.450148   \n",
              "39  0.016063 -0.432868  0.193906  0.723087 -1.509290  0.137060 -0.258605   \n",
              "40 -0.930825 -0.975236  0.020694 -0.367364 -1.166840  0.080084 -0.683109   \n",
              "41 -0.381054  0.377363 -0.349268  1.053214 -0.778858  0.223258  0.133051   \n",
              "42 -0.482022 -0.530190  0.555034  0.061592 -1.501323  0.552592 -0.453617   \n",
              "43 -0.425163 -0.889256  0.680910  1.174501 -0.299338  1.439548 -1.017437   \n",
              "44 -0.371337 -1.743062  0.156865  1.695572 -0.686044  0.506810 -1.419559   \n",
              "45 -1.375505 -1.034224  0.728940  1.947940 -1.999517  0.405978 -1.565957   \n",
              "46 -1.546735 -0.665076  0.014008  2.013012 -0.570232  0.899402 -0.864737   \n",
              "\n",
              "           7         8         9  ...       632       633       634       635  \\\n",
              "0  -0.903002  0.471242 -1.091495  ...  0.058538 -1.304109  1.541442 -0.424794   \n",
              "1  -1.145109  0.296855 -2.368747  ...  0.157107 -1.092878  1.892547 -0.487107   \n",
              "2   0.673236 -0.896982 -1.988740  ... -0.753516 -0.608883  1.339883  0.432048   \n",
              "3  -1.166486  0.981797 -1.591591  ...  0.361287 -0.495855  1.635529 -0.772384   \n",
              "4   0.721972  0.649561 -2.637098  ... -0.471062  0.093955  0.671852  0.130571   \n",
              "5   0.077632  0.161654 -2.837906  ... -0.645933 -0.706350  0.919395  1.023801   \n",
              "6  -0.908995  0.262660 -2.861198  ...  0.164378  0.277399  2.058115  0.161064   \n",
              "7  -0.953910  0.261470 -2.457000  ...  0.438582 -0.710739  1.944403 -0.137118   \n",
              "8  -0.305979 -0.087208 -2.945641  ...  0.621893 -1.044549  1.939120  0.076557   \n",
              "9  -2.167131  1.413064 -2.242526  ...  0.244677 -0.928682  1.154003 -0.196702   \n",
              "10 -2.733148  2.006800 -2.515923  ...  0.518083  0.408829  0.237417  0.417480   \n",
              "11 -1.862664  1.482231 -1.305336  ... -0.328434 -0.731346  0.970486  1.150844   \n",
              "12 -2.286921  1.303765 -1.600224  ...  0.040765 -0.186851  1.600801 -1.122975   \n",
              "13 -2.088283  1.133648 -1.532070  ... -0.282095 -0.349165  0.040628  0.709523   \n",
              "14 -1.766940  1.191479 -2.852113  ...  0.270399 -1.446855  0.904377  0.191518   \n",
              "15 -0.617277  0.631346 -0.851741  ... -1.025800 -0.099167  0.538432  1.420944   \n",
              "16 -0.397470  0.726015 -0.928387  ... -0.101263  1.035422  1.443239  1.378848   \n",
              "17 -0.186119  0.788533 -0.059928  ... -0.674960 -0.008328  1.219678  0.704170   \n",
              "18 -1.198591  1.332944 -0.620245  ... -1.091506 -0.495805  1.265438 -0.169847   \n",
              "19 -0.542393  1.092196 -0.064769  ... -1.027692  0.260945  0.967058  0.834612   \n",
              "20 -0.631917  0.919562 -0.919415  ... -0.815364  1.021727  0.367840  1.065763   \n",
              "21 -1.187628 -0.474654 -0.966479  ... -1.146562  0.336720  0.784339  1.202369   \n",
              "22 -1.528256  1.811763 -0.126442  ... -1.013625 -0.614783  1.282822  0.886146   \n",
              "23 -0.521254 -0.555038 -1.956491  ... -0.474841  1.053458  1.735331  0.864692   \n",
              "24  0.520195  0.858706 -0.186683  ... -1.164044  0.219707  0.772808  0.317163   \n",
              "25 -0.811740 -0.200744  0.034794  ...  0.042854 -0.243000  0.752491  0.674273   \n",
              "26  0.380007  0.541137 -1.394863  ... -0.626281 -0.301799  1.171829  1.421664   \n",
              "27 -1.303176  1.069632 -0.133193  ... -0.534704 -0.607059  1.583575  0.309247   \n",
              "28 -0.464046  0.225262 -1.644391  ... -0.097913 -0.260226  0.071615  0.132198   \n",
              "29  0.654997  0.318321 -2.387836  ... -0.583906 -1.380787  0.505839  1.876584   \n",
              "30  0.296600  0.547062 -1.320060  ... -0.442539 -0.172453  0.856218  1.816082   \n",
              "31 -0.105283  0.430275  0.556498  ... -1.010932 -0.733464  1.022323  0.607367   \n",
              "32  0.270091  0.664255 -1.572916  ... -0.540149  0.325710  0.972612  0.808860   \n",
              "33 -0.958972  0.942517 -0.618566  ... -0.634955  0.610513  1.195423 -0.118988   \n",
              "34 -1.965100  0.157875 -0.436323  ... -0.707230  1.010410  0.389437  0.302703   \n",
              "35 -0.906387  0.332400 -1.462990  ... -0.287458  1.036865  1.163799 -0.082156   \n",
              "36 -0.633262  0.928054 -0.655661  ... -0.441678  0.718351  1.001258  0.492759   \n",
              "37 -1.200930  0.313259 -0.516922  ...  0.722910  0.663737  0.804323  0.604769   \n",
              "38  0.205388  0.008288 -0.246765  ...  0.685066  0.696252  1.672011 -0.140407   \n",
              "39 -0.686176  0.678195 -0.838486  ... -0.594982  0.161270  1.042325  0.256729   \n",
              "40 -0.879427  0.645276 -0.609716  ... -0.961264  0.433916  1.019151  0.424877   \n",
              "41 -0.763046  0.515453 -1.888904  ... -0.357223  0.837642  1.390144  0.551295   \n",
              "42 -0.881997  1.265358 -0.469314  ... -0.759997 -0.130000  1.045778  0.133436   \n",
              "43 -2.315849  1.217635 -2.012322  ... -0.548484 -0.967192  0.089741  0.390196   \n",
              "44 -2.573834  2.023610 -1.558440  ... -0.066427 -1.449065  1.377814  0.322283   \n",
              "45 -2.758316  1.679069 -2.602715  ...  0.782819 -1.618669  1.490047 -0.033443   \n",
              "46 -2.181496  1.139154 -2.252067  ... -0.292332 -0.215581  0.287592  0.188674   \n",
              "\n",
              "         636       637       638       639  name             form  \n",
              "0  -0.802706  1.041371 -0.328758  3.136823     0  page000_line003  \n",
              "1   0.093969  2.060857 -1.213497  2.975895     0  page000_line002  \n",
              "2   0.636367  1.714106  0.504608  1.266553     0  page000_line000  \n",
              "3   1.012281  2.350589 -0.735705  2.450419     0  page000_line001  \n",
              "4  -0.747895  2.493425 -1.339399  1.875247     0  page000_line005  \n",
              "5  -0.501715  1.016948 -1.168648  1.912641     0  page000_line004  \n",
              "6   0.208770  3.003321 -1.318584  2.281312     0  page000_line006  \n",
              "7  -0.349195  2.496340 -0.891258  2.711566     0  page000_line007  \n",
              "8   0.389761  1.469566 -0.691275  1.780019     0  page000_line008  \n",
              "9  -1.030584  1.451702 -0.573324  0.096913     1  page000_line003  \n",
              "10  0.410241  1.516244 -0.792029 -1.057558     1  page000_line002  \n",
              "11 -0.227760  0.252524  0.596436 -0.253897     1  page000_line000  \n",
              "12 -0.408834  3.436998 -1.169829  0.025704     1  page000_line001  \n",
              "13 -0.784128  1.829252 -1.324068  0.003215     1  page000_line005  \n",
              "14 -1.545192  2.216811 -1.141569 -1.106837     1  page000_line004  \n",
              "15 -0.220729  1.039717 -0.968723  1.182505     3  page000_line003  \n",
              "16  0.203002  2.551162 -1.204188  1.095948     3  page000_line002  \n",
              "17  0.378878  1.588672 -0.762329  1.949395     3  page000_line001  \n",
              "18  1.055912  0.814413 -0.812493  1.728397     3  page000_line011  \n",
              "19  0.744693  1.368777 -0.804311  0.008971     3  page000_line004  \n",
              "20  0.284883  1.136353 -0.157914  0.340986     3  page000_line010  \n",
              "21 -0.798215  1.212639  0.039807  0.586837     3  page000_line006  \n",
              "22  0.687368 -0.209796 -0.947312  1.506792     3  page000_line012  \n",
              "23 -1.156795  1.644365 -0.368903  1.727635     3  page000_line007  \n",
              "24  0.655635  0.852677 -0.745911  2.183578     3  page000_line009  \n",
              "25 -1.771868  1.580923 -1.103293  0.902760     4  page000_line017  \n",
              "26 -1.447193  1.612703 -0.498627  1.497717     4  page000_line002  \n",
              "27 -0.134333  1.478819 -0.539329  2.961042     4  page000_line000  \n",
              "28 -0.743547  2.387686 -2.363768  0.895487     4  page000_line015  \n",
              "29 -1.684255  1.480990 -0.773467  0.373090     4  page000_line010  \n",
              "30 -0.560511  2.593247 -0.520242  0.937336     4  page000_line007  \n",
              "31  0.387326 -0.199046 -0.843895  1.147886     4  page000_line018  \n",
              "32 -1.446238  2.323844 -1.479796  1.605714     4  page000_line019  \n",
              "33  0.832401  1.701328 -0.965071  0.606653     5  page000_line003  \n",
              "34  0.415911  2.397123  0.484518  0.141263     5  page000_line002  \n",
              "35 -0.498177  2.336817 -0.725767  0.363254     5  page000_line000  \n",
              "36  0.786731  1.663528 -0.647642  0.667600     5  page000_line001  \n",
              "37 -0.081573  2.726238 -0.843379 -0.493157     5  page000_line005  \n",
              "38 -0.659373  1.700073 -0.392945  0.668212     5  page000_line004  \n",
              "39  0.359362  1.790579 -1.126071  0.215241     5  page000_line006  \n",
              "40  0.402371  0.975544 -0.754261  0.599763     5  page000_line007  \n",
              "41 -0.113882  2.524674 -0.827479  0.618074     5  page000_line009  \n",
              "42  0.532937  1.433050 -0.866951  0.660781     5  page000_line008  \n",
              "43 -0.447207  1.349188 -0.345251 -0.153885     6  page000_line003  \n",
              "44 -1.037573  1.489391 -0.015439  0.281922     6  page000_line002  \n",
              "45 -1.110051  2.042918 -1.068701  0.377701     6  page000_line000  \n",
              "46 -0.013113  2.173856 -0.742428 -0.962788     6  page000_line001  \n",
              "\n",
              "[47 rows x 642 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_features = feature_extraction(real_world_data['name'], real_world_data['images_path'])\n",
        "all_features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d640991",
      "metadata": {},
      "source": [
        "# Feature Extraction for Training Set (class-wise fixed images_per_subwrite sizes and bootstrapping, but dynamic sub_profile_per_writer)\n",
        "- 4 Sentence-Level Images per Sub-writer Profile for English, creating 3 Sub-writer Profiles.\n",
        "- 4 Sentence-Level Images per Sub-writer Profile for German/French, creating 12 Sub-writer Profiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec8a8a4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sub_writers_bootstrap(train_df, feature_store, images_per_subwriter=4, fold_seed=42):\n",
        "  \n",
        "    writer_names_in_fold = train_df['name'].unique()\n",
        "    feature_df = feature_store[feature_store['name'].isin(writer_names_in_fold)]\n",
        "\n",
        "    feature_columns = [col for col in feature_df.columns if col not in ['name', 'form']]\n",
        "    aggregated_data = []\n",
        "    \n",
        "    unique_writers = feature_df['name'].unique()\n",
        "    \n",
        "    for writer_id in unique_writers:\n",
        "        writer_df = feature_df[feature_df['name'] == writer_id]\n",
        "        num_images = len(writer_df)\n",
        "        \n",
        "        if num_images == 0:\n",
        "            continue\n",
        "\n",
        "\n",
        "        # try:\n",
        "        #     language = train_df.loc[train_df['name'] == writer_id, 'NativeLanguage'].iloc[0]\n",
        "        # except IndexError:\n",
        "        #     print(f\"Warning: Could not find language for writer_id {writer_id}. Skipping.\")\n",
        "        #     continue\n",
        "\n",
        "\n",
        "        # if language == 'English':\n",
        "        #     current_num_profiles_per_writer = 3  # Create fewer profiles for the low-data class\n",
        "        # else:  # For German and French\n",
        "        #     current_num_profiles_per_writer = 12 # Create more profiles for the high-data classes\n",
        "        current_num_profiles_per_writer = 12\n",
        "\n",
        "\n",
        "        if num_images <= images_per_subwriter:\n",
        "            feature_chunk = writer_df[feature_columns]\n",
        "            mean_features = feature_chunk.mean(axis=0)\n",
        "            median_features = feature_chunk.median(axis=0)\n",
        "            std_features = feature_chunk.std(axis=0).fillna(0)\n",
        "            skew_features = feature_chunk.skew(axis=0).fillna(0)\n",
        "            \n",
        "            new_row = {}\n",
        "            for col in feature_columns:\n",
        "                new_row[f'{col}|mean'] = mean_features[col]\n",
        "                new_row[f'{col}|median'] = median_features[col]\n",
        "                new_row[f'{col}|std'] = std_features[col]\n",
        "                new_row[f'{col}|skew'] = skew_features[col]\n",
        "                \n",
        "            new_row['original_writer_id'] = writer_id\n",
        "            new_row['sub_writer_id'] = f\"{writer_id}-agg-0\"\n",
        "            aggregated_data.append(new_row)\n",
        "            continue\n",
        "\n",
        "        writer_profiles = []\n",
        "        max_attempts = current_num_profiles_per_writer * 5\n",
        "        \n",
        "        for i in range(max_attempts):\n",
        "\n",
        "            sample_chunk = writer_df.sample(\n",
        "                n=images_per_subwriter, \n",
        "                replace=True, \n",
        "                random_state=fold_seed + hash(writer_id) % 100000 + i\n",
        "            )\n",
        "            feature_chunk = sample_chunk[feature_columns]\n",
        "            \n",
        "            mean_features = feature_chunk.mean(axis=0)\n",
        "            median_features = feature_chunk.median(axis=0)\n",
        "            std_features = feature_chunk.std(axis=0).fillna(0)\n",
        "            skew_features = feature_chunk.skew(axis=0).fillna(0)\n",
        "            \n",
        "            profile_dict = {}\n",
        "            for col in feature_columns:\n",
        "                profile_dict[f'{col}|mean'] = mean_features[col]\n",
        "                profile_dict[f'{col}|median'] = median_features[col]\n",
        "                profile_dict[f'{col}|std'] = std_features[col]\n",
        "                profile_dict[f'{col}|skew'] = skew_features[col]\n",
        "                \n",
        "            writer_profiles.append(profile_dict)\n",
        "            \n",
        "\n",
        "            temp_df = pd.DataFrame(writer_profiles).drop_duplicates()\n",
        "            if len(temp_df) >= current_num_profiles_per_writer:\n",
        "                break\n",
        "        \n",
        "        if writer_profiles:\n",
        "            profiles_df = pd.DataFrame(writer_profiles)\n",
        "            unique_profiles_df = profiles_df.drop_duplicates().reset_index(drop=True)\n",
        "            final_profiles_df = unique_profiles_df.head(current_num_profiles_per_writer)\n",
        "\n",
        "            for i, row in final_profiles_df.iterrows():\n",
        "                profile_data = row.to_dict()\n",
        "                profile_data['original_writer_id'] = writer_id\n",
        "                profile_data['sub_writer_id'] = f\"{writer_id}-boot-{i}\"\n",
        "                aggregated_data.append(profile_data)\n",
        "            \n",
        "    final_df = pd.DataFrame(aggregated_data)\n",
        "    \n",
        "    if final_df.empty:\n",
        "        return pd.DataFrame(), pd.Series(dtype='int')\n",
        "\n",
        "\n",
        "    new_feature_columns = []\n",
        "    for col in feature_columns:\n",
        "        new_feature_columns.append(f'{col}|mean')\n",
        "        new_feature_columns.append(f'{col}|median')\n",
        "        new_feature_columns.append(f'{col}|std')\n",
        "        new_feature_columns.append(f'{col}|skew')\n",
        "\n",
        "    cols = ['sub_writer_id', 'original_writer_id'] + new_feature_columns\n",
        "    final_df = final_df[cols]\n",
        "    \n",
        "    final_df = pd.merge(final_df, train_df[['name', 'NativeLanguage']], how='inner', left_on='original_writer_id', right_on='name')\n",
        "    \n",
        "    X_train = final_df.drop(columns=['sub_writer_id', 'original_writer_id','name','NativeLanguage'])\n",
        "    y_train = final_df['NativeLanguage']\n",
        "    y_train = np.vectorize(convert_y)(y_train)\n",
        "    # display(X_train)\n",
        "    return X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d7a593",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>632</th>\n",
              "      <th>633</th>\n",
              "      <th>634</th>\n",
              "      <th>635</th>\n",
              "      <th>636</th>\n",
              "      <th>637</th>\n",
              "      <th>638</th>\n",
              "      <th>639</th>\n",
              "      <th>name</th>\n",
              "      <th>form</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.372276</td>\n",
              "      <td>0.224989</td>\n",
              "      <td>-0.467460</td>\n",
              "      <td>1.820759</td>\n",
              "      <td>-0.586967</td>\n",
              "      <td>1.776678</td>\n",
              "      <td>-3.153311</td>\n",
              "      <td>-2.495186</td>\n",
              "      <td>0.968704</td>\n",
              "      <td>-1.006844</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.981443</td>\n",
              "      <td>-0.273160</td>\n",
              "      <td>1.014988</td>\n",
              "      <td>1.218125</td>\n",
              "      <td>-0.981978</td>\n",
              "      <td>3.083691</td>\n",
              "      <td>-1.024849</td>\n",
              "      <td>2.180169</td>\n",
              "      <td>10000</td>\n",
              "      <td>z01-000-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.033635</td>\n",
              "      <td>-0.905358</td>\n",
              "      <td>0.258783</td>\n",
              "      <td>1.923517</td>\n",
              "      <td>-0.866238</td>\n",
              "      <td>0.205671</td>\n",
              "      <td>-1.162825</td>\n",
              "      <td>-0.941368</td>\n",
              "      <td>1.491512</td>\n",
              "      <td>-0.259629</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.438199</td>\n",
              "      <td>-1.047727</td>\n",
              "      <td>1.526454</td>\n",
              "      <td>-0.711613</td>\n",
              "      <td>-0.884340</td>\n",
              "      <td>0.576500</td>\n",
              "      <td>-1.261368</td>\n",
              "      <td>1.769279</td>\n",
              "      <td>10000</td>\n",
              "      <td>z01-000-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.025888</td>\n",
              "      <td>-0.592650</td>\n",
              "      <td>0.585571</td>\n",
              "      <td>2.040271</td>\n",
              "      <td>-0.155405</td>\n",
              "      <td>-0.120354</td>\n",
              "      <td>-1.829877</td>\n",
              "      <td>-1.252309</td>\n",
              "      <td>1.205214</td>\n",
              "      <td>-0.259600</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.126850</td>\n",
              "      <td>-1.122187</td>\n",
              "      <td>0.977126</td>\n",
              "      <td>0.345049</td>\n",
              "      <td>-0.814934</td>\n",
              "      <td>0.962746</td>\n",
              "      <td>-0.548778</td>\n",
              "      <td>2.673030</td>\n",
              "      <td>10000</td>\n",
              "      <td>z01-000-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.510987</td>\n",
              "      <td>-0.666809</td>\n",
              "      <td>-1.368710</td>\n",
              "      <td>1.987004</td>\n",
              "      <td>-0.221620</td>\n",
              "      <td>0.672618</td>\n",
              "      <td>-3.057467</td>\n",
              "      <td>-1.380301</td>\n",
              "      <td>1.458408</td>\n",
              "      <td>-1.007992</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.292161</td>\n",
              "      <td>-1.257141</td>\n",
              "      <td>-0.041370</td>\n",
              "      <td>1.655186</td>\n",
              "      <td>-0.791135</td>\n",
              "      <td>2.099786</td>\n",
              "      <td>-1.133589</td>\n",
              "      <td>1.716038</td>\n",
              "      <td>10000</td>\n",
              "      <td>z01-000-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.917990</td>\n",
              "      <td>-0.359039</td>\n",
              "      <td>0.085779</td>\n",
              "      <td>1.985653</td>\n",
              "      <td>-1.203340</td>\n",
              "      <td>0.940839</td>\n",
              "      <td>-2.236159</td>\n",
              "      <td>-2.180054</td>\n",
              "      <td>1.759380</td>\n",
              "      <td>-1.052856</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.828048</td>\n",
              "      <td>-1.400792</td>\n",
              "      <td>1.134104</td>\n",
              "      <td>0.957654</td>\n",
              "      <td>-0.926594</td>\n",
              "      <td>2.193790</td>\n",
              "      <td>-1.190055</td>\n",
              "      <td>2.018496</td>\n",
              "      <td>10000</td>\n",
              "      <td>z01-000-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2578</th>\n",
              "      <td>-1.022801</td>\n",
              "      <td>-0.549992</td>\n",
              "      <td>0.474362</td>\n",
              "      <td>1.346962</td>\n",
              "      <td>-1.411951</td>\n",
              "      <td>0.314682</td>\n",
              "      <td>-1.732456</td>\n",
              "      <td>-1.602569</td>\n",
              "      <td>1.862565</td>\n",
              "      <td>-0.729485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.690082</td>\n",
              "      <td>-0.635586</td>\n",
              "      <td>0.944297</td>\n",
              "      <td>0.949022</td>\n",
              "      <td>0.114406</td>\n",
              "      <td>1.693765</td>\n",
              "      <td>-0.702968</td>\n",
              "      <td>1.598468</td>\n",
              "      <td>10220</td>\n",
              "      <td>r09-711z-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2579</th>\n",
              "      <td>-1.119037</td>\n",
              "      <td>-0.319230</td>\n",
              "      <td>-0.844590</td>\n",
              "      <td>1.900380</td>\n",
              "      <td>-1.320712</td>\n",
              "      <td>1.383125</td>\n",
              "      <td>-2.748960</td>\n",
              "      <td>-2.618426</td>\n",
              "      <td>1.685810</td>\n",
              "      <td>-0.819477</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.340733</td>\n",
              "      <td>-0.220537</td>\n",
              "      <td>0.707243</td>\n",
              "      <td>0.795958</td>\n",
              "      <td>-0.042035</td>\n",
              "      <td>2.540886</td>\n",
              "      <td>-0.501349</td>\n",
              "      <td>1.707833</td>\n",
              "      <td>10220</td>\n",
              "      <td>r09-711z-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2580</th>\n",
              "      <td>-1.351192</td>\n",
              "      <td>-0.087385</td>\n",
              "      <td>-0.508317</td>\n",
              "      <td>1.825388</td>\n",
              "      <td>-1.012136</td>\n",
              "      <td>1.089012</td>\n",
              "      <td>-1.863513</td>\n",
              "      <td>-2.312963</td>\n",
              "      <td>1.416140</td>\n",
              "      <td>-0.808480</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.678303</td>\n",
              "      <td>-0.495727</td>\n",
              "      <td>-0.093825</td>\n",
              "      <td>0.974745</td>\n",
              "      <td>-0.141147</td>\n",
              "      <td>1.324965</td>\n",
              "      <td>-0.455692</td>\n",
              "      <td>1.934971</td>\n",
              "      <td>10220</td>\n",
              "      <td>r09-711z-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2581</th>\n",
              "      <td>-0.900473</td>\n",
              "      <td>-0.872832</td>\n",
              "      <td>0.237764</td>\n",
              "      <td>1.850838</td>\n",
              "      <td>-1.448905</td>\n",
              "      <td>0.488510</td>\n",
              "      <td>-1.619385</td>\n",
              "      <td>-1.727785</td>\n",
              "      <td>1.462484</td>\n",
              "      <td>-0.302451</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.790186</td>\n",
              "      <td>-0.189288</td>\n",
              "      <td>0.962848</td>\n",
              "      <td>0.774071</td>\n",
              "      <td>0.080401</td>\n",
              "      <td>1.018999</td>\n",
              "      <td>-0.850802</td>\n",
              "      <td>1.617383</td>\n",
              "      <td>10220</td>\n",
              "      <td>r09-711z-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2582</th>\n",
              "      <td>-0.206973</td>\n",
              "      <td>-0.056896</td>\n",
              "      <td>-0.012916</td>\n",
              "      <td>1.660316</td>\n",
              "      <td>-0.647499</td>\n",
              "      <td>-0.048645</td>\n",
              "      <td>-1.323026</td>\n",
              "      <td>-2.533231</td>\n",
              "      <td>0.040028</td>\n",
              "      <td>-0.951741</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.481616</td>\n",
              "      <td>-0.457706</td>\n",
              "      <td>-0.801752</td>\n",
              "      <td>0.859052</td>\n",
              "      <td>-0.368953</td>\n",
              "      <td>0.627240</td>\n",
              "      <td>0.038439</td>\n",
              "      <td>1.256306</td>\n",
              "      <td>10220</td>\n",
              "      <td>r09-711z-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2583 rows × 642 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "0    -0.372276  0.224989 -0.467460  1.820759 -0.586967  1.776678 -3.153311   \n",
              "1    -0.033635 -0.905358  0.258783  1.923517 -0.866238  0.205671 -1.162825   \n",
              "2     0.025888 -0.592650  0.585571  2.040271 -0.155405 -0.120354 -1.829877   \n",
              "3    -1.510987 -0.666809 -1.368710  1.987004 -0.221620  0.672618 -3.057467   \n",
              "4    -0.917990 -0.359039  0.085779  1.985653 -1.203340  0.940839 -2.236159   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2578 -1.022801 -0.549992  0.474362  1.346962 -1.411951  0.314682 -1.732456   \n",
              "2579 -1.119037 -0.319230 -0.844590  1.900380 -1.320712  1.383125 -2.748960   \n",
              "2580 -1.351192 -0.087385 -0.508317  1.825388 -1.012136  1.089012 -1.863513   \n",
              "2581 -0.900473 -0.872832  0.237764  1.850838 -1.448905  0.488510 -1.619385   \n",
              "2582 -0.206973 -0.056896 -0.012916  1.660316 -0.647499 -0.048645 -1.323026   \n",
              "\n",
              "             7         8         9  ...       632       633       634  \\\n",
              "0    -2.495186  0.968704 -1.006844  ... -0.981443 -0.273160  1.014988   \n",
              "1    -0.941368  1.491512 -0.259629  ... -0.438199 -1.047727  1.526454   \n",
              "2    -1.252309  1.205214 -0.259600  ... -1.126850 -1.122187  0.977126   \n",
              "3    -1.380301  1.458408 -1.007992  ... -1.292161 -1.257141 -0.041370   \n",
              "4    -2.180054  1.759380 -1.052856  ... -0.828048 -1.400792  1.134104   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2578 -1.602569  1.862565 -0.729485  ... -0.690082 -0.635586  0.944297   \n",
              "2579 -2.618426  1.685810 -0.819477  ... -0.340733 -0.220537  0.707243   \n",
              "2580 -2.312963  1.416140 -0.808480  ... -0.678303 -0.495727 -0.093825   \n",
              "2581 -1.727785  1.462484 -0.302451  ... -0.790186 -0.189288  0.962848   \n",
              "2582 -2.533231  0.040028 -0.951741  ... -1.481616 -0.457706 -0.801752   \n",
              "\n",
              "           635       636       637       638       639   name         form  \n",
              "0     1.218125 -0.981978  3.083691 -1.024849  2.180169  10000   z01-000-03  \n",
              "1    -0.711613 -0.884340  0.576500 -1.261368  1.769279  10000   z01-000-02  \n",
              "2     0.345049 -0.814934  0.962746 -0.548778  2.673030  10000   z01-000-01  \n",
              "3     1.655186 -0.791135  2.099786 -1.133589  1.716038  10000   z01-000-05  \n",
              "4     0.957654 -0.926594  2.193790 -1.190055  2.018496  10000   z01-000-04  \n",
              "...        ...       ...       ...       ...       ...    ...          ...  \n",
              "2578  0.949022  0.114406  1.693765 -0.702968  1.598468  10220  r09-711z-01  \n",
              "2579  0.795958 -0.042035  2.540886 -0.501349  1.707833  10220  r09-711z-05  \n",
              "2580  0.974745 -0.141147  1.324965 -0.455692  1.934971  10220  r09-711z-04  \n",
              "2581  0.774071  0.080401  1.018999 -0.850802  1.617383  10220  r09-711z-06  \n",
              "2582  0.859052 -0.368953  0.627240  0.038439  1.256306  10220  r09-711z-07  \n",
              "\n",
              "[2583 rows x 642 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "feature_store = pd.read_csv('./Final-Data/German-French-IAM-X-y-Writer-Feature-Vectors.csv', index_col=[0])\n",
        "display(feature_store)\n",
        "writers_info = pd.read_csv('./Final-Data/new-writers-info.csv')\n",
        "\n",
        "writers_info = writers_info.loc[(writers_info['NativeLanguage'] != 'Swiss German') & (writers_info['NativeLanguage'] != 'English')]\n",
        "all_writers_info = feature_store[['name']].drop_duplicates().reset_index(drop=True)\n",
        "all_writers_info = pd.merge(all_writers_info, writers_info[['name', 'NativeLanguage']], how='inner', on='name')\n",
        "all_labels = all_writers_info['NativeLanguage']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e01b9fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train_all"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71d6368a",
      "metadata": {},
      "source": [
        "## X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d95d4177",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_writer_level_profile(test_df, feature_store):\n",
        "\n",
        "  writer_names_in_fold = test_df['name'].unique()\n",
        "  # print(writer_names_in_fold)\n",
        "  test_features_df = feature_store[feature_store['name'].isin(writer_names_in_fold)]\n",
        "  \n",
        "  writer_level_feature_df = test_features_df.groupby(['name'], as_index=False)[test_features_df.columns[:-2]].agg(['mean', 'median', 'std', 'skew']).fillna(0)\n",
        "  writer_level_feature_df.columns = writer_level_feature_df.columns.map(lambda x: '|'.join(map(str, x)))\n",
        "  \n",
        "  final_test_df = pd.merge(writer_level_feature_df, test_df[['name', 'NativeLanguage']], how='inner', left_on='name|', right_on='name')\n",
        "  display(final_test_df['name'])\n",
        "  X_test = final_test_df.drop(columns=['name','name|','NativeLanguage'])\n",
        "  y_test = final_test_df['NativeLanguage']\n",
        "  y_test = np.vectorize(convert_y)(y_test)\n",
        "  \n",
        "  return X_test, y_test\n",
        "  \n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "253f7d27",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b466bf69",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:22,203] A new study created in memory with name: no-name-53abb30d-077b-4c29-87c6-d9976fb4bcb5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Augmented training set created with 420 samples.\n",
            "\n",
            "Starting Optuna hyperparameter search for 100 trials...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.843441:   1%|          | 1/100 [00:01<02:13,  1.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:23,546] Trial 0 finished with value: 0.8434408602150538 and parameters: {'feature_selection__max_features': 246, 'classification__n_estimators': 285, 'classification__learning_rate': 0.002094091794418931, 'classification__max_depth': 11, 'classification__subsample': 0.7624849782725179, 'classification__colsample_bytree': 0.9404515764546294, 'classification__lambda': 2.4432691743587585, 'classification__alpha': 1.3359416863890423, 'classification__min_child_weight': 7}. Best is trial 0 with value: 0.8434408602150538.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.843441:   2%|▏         | 2/100 [00:02<01:39,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:24,330] Trial 1 finished with value: 0.8193548387096774 and parameters: {'feature_selection__max_features': 301, 'classification__n_estimators': 53, 'classification__learning_rate': 0.002415688486505027, 'classification__max_depth': 5, 'classification__subsample': 0.8426056833176782, 'classification__colsample_bytree': 0.710309746608899, 'classification__lambda': 1.2294253152481083, 'classification__alpha': 8.351939529449224, 'classification__min_child_weight': 6}. Best is trial 0 with value: 0.8434408602150538.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 2. Best value: 0.866763:   3%|▎         | 3/100 [00:07<04:48,  2.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:29,634] Trial 2 finished with value: 0.86676279740447 and parameters: {'feature_selection__max_features': 783, 'classification__n_estimators': 553, 'classification__learning_rate': 0.0054611054847358235, 'classification__max_depth': 14, 'classification__subsample': 0.8199091814895401, 'classification__colsample_bytree': 0.9891485069763671, 'classification__lambda': 1.7816561000202804, 'classification__alpha': 7.010212609961707, 'classification__min_child_weight': 3}. Best is trial 2 with value: 0.86676279740447.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 3. Best value: 0.879241:   4%|▍         | 4/100 [00:10<04:39,  2.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:32,449] Trial 3 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 377, 'classification__n_estimators': 619, 'classification__learning_rate': 0.0050642833524613875, 'classification__max_depth': 5, 'classification__subsample': 0.9959552880005603, 'classification__colsample_bytree': 0.7090418427657689, 'classification__lambda': 0.42198069098902474, 'classification__alpha': 0.17953572752343858, 'classification__min_child_weight': 5}. Best is trial 3 with value: 0.8792409430707303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 3. Best value: 0.879241:   5%|▌         | 5/100 [00:11<03:34,  2.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:33,555] Trial 4 finished with value: 0.8309373202990225 and parameters: {'feature_selection__max_features': 148, 'classification__n_estimators': 169, 'classification__learning_rate': 0.005341158120942712, 'classification__max_depth': 5, 'classification__subsample': 0.9133472514491885, 'classification__colsample_bytree': 0.7189233501633198, 'classification__lambda': 18.669189891016746, 'classification__alpha': 0.31011526338666995, 'classification__min_child_weight': 1}. Best is trial 3 with value: 0.8792409430707303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 3. Best value: 0.879241:   6%|▌         | 6/100 [00:12<02:55,  1.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:34,644] Trial 5 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 270, 'classification__n_estimators': 91, 'classification__learning_rate': 0.0015997927032212749, 'classification__max_depth': 15, 'classification__subsample': 0.6411591360223262, 'classification__colsample_bytree': 0.813884521806084, 'classification__lambda': 4.762966456179558, 'classification__alpha': 4.372090336746582, 'classification__min_child_weight': 1}. Best is trial 3 with value: 0.8792409430707303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 3. Best value: 0.879241:   7%|▋         | 7/100 [00:16<03:56,  2.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:38,591] Trial 6 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 498, 'classification__n_estimators': 760, 'classification__learning_rate': 0.004559847487450698, 'classification__max_depth': 8, 'classification__subsample': 0.770704166222195, 'classification__colsample_bytree': 0.9706011916187032, 'classification__lambda': 0.9100178129768467, 'classification__alpha': 2.413063729815824, 'classification__min_child_weight': 5}. Best is trial 3 with value: 0.8792409430707303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 3. Best value: 0.879241:   8%|▊         | 8/100 [00:18<03:33,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:40,444] Trial 7 finished with value: 0.86676279740447 and parameters: {'feature_selection__max_features': 260, 'classification__n_estimators': 248, 'classification__learning_rate': 0.00225903714279551, 'classification__max_depth': 5, 'classification__subsample': 0.7386034119319971, 'classification__colsample_bytree': 0.8927996136057774, 'classification__lambda': 0.1296087812281298, 'classification__alpha': 2.1920365866497824, 'classification__min_child_weight': 1}. Best is trial 3 with value: 0.8792409430707303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 3. Best value: 0.879241:   9%|▉         | 9/100 [00:20<03:23,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:42,500] Trial 8 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 100, 'classification__n_estimators': 465, 'classification__learning_rate': 0.0024900700020634783, 'classification__max_depth': 9, 'classification__subsample': 0.8544264113076677, 'classification__colsample_bytree': 0.9146154514193008, 'classification__lambda': 2.85377535015538, 'classification__alpha': 0.8526721565592258, 'classification__min_child_weight': 1}. Best is trial 3 with value: 0.8792409430707303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 3. Best value: 0.879241:  10%|█         | 10/100 [00:21<02:53,  1.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:43,712] Trial 9 finished with value: 0.7776470588235294 and parameters: {'feature_selection__max_features': 279, 'classification__n_estimators': 325, 'classification__learning_rate': 0.0014239268473025014, 'classification__max_depth': 12, 'classification__subsample': 0.9919559223216027, 'classification__colsample_bytree': 0.6249518354751119, 'classification__lambda': 29.775733537652652, 'classification__alpha': 10.479836243514422, 'classification__min_child_weight': 7}. Best is trial 3 with value: 0.8792409430707303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  11%|█         | 11/100 [00:24<03:13,  2.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:46,456] Trial 10 finished with value: 0.8921078921078921 and parameters: {'feature_selection__max_features': 926, 'classification__n_estimators': 962, 'classification__learning_rate': 0.009783048898976479, 'classification__max_depth': 3, 'classification__subsample': 0.9830732034811086, 'classification__colsample_bytree': 0.6120513877963497, 'classification__lambda': 0.21445981569148262, 'classification__alpha': 0.1023839796293193, 'classification__min_child_weight': 10}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  12%|█▏        | 12/100 [00:26<03:25,  2.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:49,152] Trial 11 finished with value: 0.8681318681318682 and parameters: {'feature_selection__max_features': 934, 'classification__n_estimators': 932, 'classification__learning_rate': 0.00971506840771984, 'classification__max_depth': 3, 'classification__subsample': 0.9962395420951144, 'classification__colsample_bytree': 0.6055514571336053, 'classification__lambda': 0.2317464985578106, 'classification__alpha': 0.12327660620426506, 'classification__min_child_weight': 10}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  13%|█▎        | 13/100 [00:29<03:28,  2.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:51,689] Trial 12 finished with value: 0.8921078921078921 and parameters: {'feature_selection__max_features': 577, 'classification__n_estimators': 987, 'classification__learning_rate': 0.009436643614108947, 'classification__max_depth': 3, 'classification__subsample': 0.9237465642745386, 'classification__colsample_bytree': 0.6785092690805544, 'classification__lambda': 0.45797153922873585, 'classification__alpha': 0.10069944940504078, 'classification__min_child_weight': 10}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  14%|█▍        | 14/100 [00:32<03:34,  2.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:54,409] Trial 13 finished with value: 0.8558352402745995 and parameters: {'feature_selection__max_features': 721, 'classification__n_estimators': 999, 'classification__learning_rate': 0.009730740418204679, 'classification__max_depth': 3, 'classification__subsample': 0.9088508198334481, 'classification__colsample_bytree': 0.6638362667837858, 'classification__lambda': 0.4962675709825933, 'classification__alpha': 0.4067682062222592, 'classification__min_child_weight': 10}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  15%|█▌        | 15/100 [00:35<03:52,  2.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 19:59:57,705] Trial 14 finished with value: 0.8558352402745995 and parameters: {'feature_selection__max_features': 668, 'classification__n_estimators': 836, 'classification__learning_rate': 0.0073419295990346115, 'classification__max_depth': 7, 'classification__subsample': 0.929280809502774, 'classification__colsample_bytree': 0.7787761828356117, 'classification__lambda': 0.10542180965352142, 'classification__alpha': 0.10183955638793676, 'classification__min_child_weight': 9}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  16%|█▌        | 16/100 [00:38<03:58,  2.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:00,771] Trial 15 finished with value: 0.86676279740447 and parameters: {'feature_selection__max_features': 977, 'classification__n_estimators': 709, 'classification__learning_rate': 0.0036513776788645045, 'classification__max_depth': 3, 'classification__subsample': 0.9489172734106882, 'classification__colsample_bytree': 0.6582450259653363, 'classification__lambda': 0.31170441543932303, 'classification__alpha': 0.3516480444400085, 'classification__min_child_weight': 8}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  17%|█▋        | 17/100 [00:42<04:23,  3.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:04,745] Trial 16 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 580, 'classification__n_estimators': 866, 'classification__learning_rate': 0.0010181548815689275, 'classification__max_depth': 7, 'classification__subsample': 0.869416194813267, 'classification__colsample_bytree': 0.7749115497087788, 'classification__lambda': 0.186379892118361, 'classification__alpha': 0.6821965945208323, 'classification__min_child_weight': 9}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  18%|█▊        | 18/100 [00:45<04:10,  3.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:07,523] Trial 17 finished with value: 0.8558352402745995 and parameters: {'feature_selection__max_features': 875, 'classification__n_estimators': 994, 'classification__learning_rate': 0.007187841499591318, 'classification__max_depth': 4, 'classification__subsample': 0.6512771968394623, 'classification__colsample_bytree': 0.6605412839706367, 'classification__lambda': 0.6729774106602195, 'classification__alpha': 0.14703223843128338, 'classification__min_child_weight': 9}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  19%|█▉        | 19/100 [00:47<03:55,  2.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:10,095] Trial 18 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 520, 'classification__n_estimators': 729, 'classification__learning_rate': 0.007254384885278161, 'classification__max_depth': 11, 'classification__subsample': 0.9577971269928822, 'classification__colsample_bytree': 0.7372426511219747, 'classification__lambda': 8.29149787733862, 'classification__alpha': 0.22889283769770313, 'classification__min_child_weight': 10}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  20%|██        | 20/100 [00:51<03:58,  2.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:13,253] Trial 19 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 813, 'classification__n_estimators': 867, 'classification__learning_rate': 0.0037398820560352805, 'classification__max_depth': 7, 'classification__subsample': 0.700032481616304, 'classification__colsample_bytree': 0.6037659001003521, 'classification__lambda': 0.2640144411698884, 'classification__alpha': 0.7092103554497743, 'classification__min_child_weight': 8}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  21%|██        | 21/100 [00:54<04:08,  3.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:16,782] Trial 20 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 628, 'classification__n_estimators': 450, 'classification__learning_rate': 0.008316490748640527, 'classification__max_depth': 9, 'classification__subsample': 0.8916827322651125, 'classification__colsample_bytree': 0.6751709933790688, 'classification__lambda': 0.6264039278208281, 'classification__alpha': 0.23044774246739486, 'classification__min_child_weight': 3}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  22%|██▏       | 22/100 [00:57<04:07,  3.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:20,021] Trial 21 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 432, 'classification__n_estimators': 631, 'classification__learning_rate': 0.0057851384177933585, 'classification__max_depth': 4, 'classification__subsample': 0.965884331651108, 'classification__colsample_bytree': 0.8399469621958013, 'classification__lambda': 0.4159186640326891, 'classification__alpha': 0.15791856337146787, 'classification__min_child_weight': 4}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  23%|██▎       | 23/100 [01:01<04:06,  3.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:23,283] Trial 22 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 405, 'classification__n_estimators': 799, 'classification__learning_rate': 0.006482178981707777, 'classification__max_depth': 6, 'classification__subsample': 0.9954845448428008, 'classification__colsample_bytree': 0.6925526423397127, 'classification__lambda': 0.17473935301131358, 'classification__alpha': 0.10249661831123165, 'classification__min_child_weight': 5}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  24%|██▍       | 24/100 [01:03<03:51,  3.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:25,971] Trial 23 finished with value: 0.86676279740447 and parameters: {'feature_selection__max_features': 382, 'classification__n_estimators': 652, 'classification__learning_rate': 0.004198438848886491, 'classification__max_depth': 4, 'classification__subsample': 0.9461393148727044, 'classification__colsample_bytree': 0.7376052245100932, 'classification__lambda': 0.3448415935094919, 'classification__alpha': 0.1913763555977557, 'classification__min_child_weight': 6}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  25%|██▌       | 25/100 [01:06<03:37,  2.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:28,510] Trial 24 finished with value: 0.8558352402745995 and parameters: {'feature_selection__max_features': 530, 'classification__n_estimators': 932, 'classification__learning_rate': 0.009969352996738718, 'classification__max_depth': 3, 'classification__subsample': 0.8867676638639044, 'classification__colsample_bytree': 0.6473374443464599, 'classification__lambda': 1.1637463168905167, 'classification__alpha': 0.4216555591892749, 'classification__min_child_weight': 8}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  26%|██▌       | 26/100 [01:08<03:11,  2.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:30,387] Trial 25 finished with value: 0.86676279740447 and parameters: {'feature_selection__max_features': 166, 'classification__n_estimators': 573, 'classification__learning_rate': 0.0029742377806949104, 'classification__max_depth': 6, 'classification__subsample': 0.970749705037449, 'classification__colsample_bytree': 0.6306063196069165, 'classification__lambda': 0.7090373961111521, 'classification__alpha': 0.2322620558998293, 'classification__min_child_weight': 4}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  27%|██▋       | 27/100 [01:11<03:32,  2.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:34,033] Trial 26 finished with value: 0.8921078921078921 and parameters: {'feature_selection__max_features': 717, 'classification__n_estimators': 933, 'classification__learning_rate': 0.00843798804524563, 'classification__max_depth': 4, 'classification__subsample': 0.9290259681890038, 'classification__colsample_bytree': 0.7522486567076673, 'classification__lambda': 0.15868324205363213, 'classification__alpha': 0.15734118856313187, 'classification__min_child_weight': 7}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  28%|██▊       | 28/100 [01:14<03:34,  2.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:37,193] Trial 27 finished with value: 0.8441558441558441 and parameters: {'feature_selection__max_features': 745, 'classification__n_estimators': 928, 'classification__learning_rate': 0.008645009488742222, 'classification__max_depth': 4, 'classification__subsample': 0.8134798167837985, 'classification__colsample_bytree': 0.7518032335422992, 'classification__lambda': 0.15080070469262882, 'classification__alpha': 0.10563179592059671, 'classification__min_child_weight': 9}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  29%|██▉       | 29/100 [01:18<03:40,  3.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:40,608] Trial 28 finished with value: 0.86676279740447 and parameters: {'feature_selection__max_features': 886, 'classification__n_estimators': 899, 'classification__learning_rate': 0.00809477923589174, 'classification__max_depth': 6, 'classification__subsample': 0.9256289168849569, 'classification__colsample_bytree': 0.8481486299844246, 'classification__lambda': 0.2593745522375896, 'classification__alpha': 18.283863288435555, 'classification__min_child_weight': 7}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  30%|███       | 30/100 [01:21<03:37,  3.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:43,682] Trial 29 finished with value: 0.8434408602150538 and parameters: {'feature_selection__max_features': 661, 'classification__n_estimators': 797, 'classification__learning_rate': 0.006078896220950763, 'classification__max_depth': 10, 'classification__subsample': 0.8893756086506291, 'classification__colsample_bytree': 0.6881635890557157, 'classification__lambda': 0.10702141206544027, 'classification__alpha': 1.015082661316737, 'classification__min_child_weight': 10}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  31%|███       | 31/100 [01:25<03:48,  3.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:47,501] Trial 30 finished with value: 0.8675268817204301 and parameters: {'feature_selection__max_features': 840, 'classification__n_estimators': 968, 'classification__learning_rate': 0.006801634971874375, 'classification__max_depth': 3, 'classification__subsample': 0.8346465043112979, 'classification__colsample_bytree': 0.7934158599831349, 'classification__lambda': 0.19239252194192677, 'classification__alpha': 0.5128877920607329, 'classification__min_child_weight': 7}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  32%|███▏      | 32/100 [01:28<03:36,  3.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:50,388] Trial 31 finished with value: 0.86676279740447 and parameters: {'feature_selection__max_features': 714, 'classification__n_estimators': 391, 'classification__learning_rate': 0.00486861806356369, 'classification__max_depth': 5, 'classification__subsample': 0.9701860165027383, 'classification__colsample_bytree': 0.6989684618635663, 'classification__lambda': 0.43908663528078645, 'classification__alpha': 0.16490201353537393, 'classification__min_child_weight': 6}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  33%|███▎      | 33/100 [01:32<03:47,  3.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:54,280] Trial 32 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 995, 'classification__n_estimators': 662, 'classification__learning_rate': 0.008463011586776767, 'classification__max_depth': 4, 'classification__subsample': 0.9221389266522766, 'classification__colsample_bytree': 0.7124625469966311, 'classification__lambda': 0.35271343678236017, 'classification__alpha': 0.28787356050197827, 'classification__min_child_weight': 4}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  34%|███▍      | 34/100 [01:34<03:25,  3.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:00:56,698] Trial 33 finished with value: 0.8558352402745995 and parameters: {'feature_selection__max_features': 353, 'classification__n_estimators': 832, 'classification__learning_rate': 0.00847089026111953, 'classification__max_depth': 5, 'classification__subsample': 0.981378539374165, 'classification__colsample_bytree': 0.6337155183256257, 'classification__lambda': 1.9543124199315698, 'classification__alpha': 0.14196273517303462, 'classification__min_child_weight': 8}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  35%|███▌      | 35/100 [01:39<03:57,  3.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:01,635] Trial 34 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 450, 'classification__n_estimators': 902, 'classification__learning_rate': 0.005291476594867651, 'classification__max_depth': 5, 'classification__subsample': 0.9401423868447104, 'classification__colsample_bytree': 0.7526046456891917, 'classification__lambda': 1.1313416180985998, 'classification__alpha': 0.19870805401580302, 'classification__min_child_weight': 3}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  36%|███▌      | 36/100 [01:40<03:03,  2.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:02,683] Trial 35 finished with value: 0.8558352402745995 and parameters: {'feature_selection__max_features': 16, 'classification__n_estimators': 779, 'classification__learning_rate': 0.006106727828331507, 'classification__max_depth': 3, 'classification__subsample': 0.7784736078843655, 'classification__colsample_bytree': 0.67837152019898, 'classification__lambda': 0.5322661778029206, 'classification__alpha': 0.13549708325989143, 'classification__min_child_weight': 5}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  37%|███▋      | 37/100 [01:43<02:57,  2.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:05,397] Trial 36 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 606, 'classification__n_estimators': 575, 'classification__learning_rate': 0.009970237662910829, 'classification__max_depth': 4, 'classification__subsample': 0.9108359040443731, 'classification__colsample_bytree': 0.7136950784449952, 'classification__lambda': 0.8632904643180634, 'classification__alpha': 1.6289129395805941, 'classification__min_child_weight': 6}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  38%|███▊      | 38/100 [01:45<02:53,  2.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:08,156] Trial 37 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 767, 'classification__n_estimators': 510, 'classification__learning_rate': 0.0030530101671684055, 'classification__max_depth': 8, 'classification__subsample': 0.6023420375716907, 'classification__colsample_bytree': 0.7333629661373833, 'classification__lambda': 0.14904569876805832, 'classification__alpha': 0.31127750335688686, 'classification__min_child_weight': 7}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  39%|███▉      | 39/100 [01:47<02:22,  2.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:09,403] Trial 38 finished with value: 0.8434408602150538 and parameters: {'feature_selection__max_features': 550, 'classification__n_estimators': 171, 'classification__learning_rate': 0.00476431255288501, 'classification__max_depth': 6, 'classification__subsample': 0.8608995426628593, 'classification__colsample_bytree': 0.808957652942143, 'classification__lambda': 2.7075012112589634, 'classification__alpha': 4.717632477817914, 'classification__min_child_weight': 9}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  40%|████      | 40/100 [01:49<02:27,  2.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:12,117] Trial 39 finished with value: 0.8434408602150538 and parameters: {'feature_selection__max_features': 483, 'classification__n_estimators': 978, 'classification__learning_rate': 0.00763890867821657, 'classification__max_depth': 5, 'classification__subsample': 0.9528998981711904, 'classification__colsample_bytree': 0.6416410336278381, 'classification__lambda': 4.3618957451545874, 'classification__alpha': 0.25879018097645384, 'classification__min_child_weight': 10}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  41%|████      | 41/100 [01:53<02:40,  2.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:15,493] Trial 40 finished with value: 0.879862700228833 and parameters: {'feature_selection__max_features': 213, 'classification__n_estimators': 726, 'classification__learning_rate': 0.00405555839595601, 'classification__max_depth': 14, 'classification__subsample': 0.9989297118691245, 'classification__colsample_bytree': 0.7618342492452674, 'classification__lambda': 0.2187273857683282, 'classification__alpha': 0.5399520101516824, 'classification__min_child_weight': 2}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  42%|████▏     | 42/100 [01:56<02:46,  2.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:18,709] Trial 41 finished with value: 0.8675268817204301 and parameters: {'feature_selection__max_features': 199, 'classification__n_estimators': 716, 'classification__learning_rate': 0.004093776676221551, 'classification__max_depth': 14, 'classification__subsample': 0.9987283045842239, 'classification__colsample_bytree': 0.7713015728238514, 'classification__lambda': 0.22871936411408422, 'classification__alpha': 0.5509571096409508, 'classification__min_child_weight': 2}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  43%|████▎     | 43/100 [02:02<03:30,  3.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:24,313] Trial 42 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 338, 'classification__n_estimators': 867, 'classification__learning_rate': 0.0026498154404903033, 'classification__max_depth': 13, 'classification__subsample': 0.9768479289493537, 'classification__colsample_bytree': 0.7206866194974277, 'classification__lambda': 0.3087085155765634, 'classification__alpha': 0.19507887948858105, 'classification__min_child_weight': 2}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  44%|████▍     | 44/100 [02:06<03:31,  3.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:28,276] Trial 43 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 227, 'classification__n_estimators': 951, 'classification__learning_rate': 0.005272608996720561, 'classification__max_depth': 15, 'classification__subsample': 0.979526838697442, 'classification__colsample_bytree': 0.824861046466698, 'classification__lambda': 0.12052447177461298, 'classification__alpha': 0.12392904228494207, 'classification__min_child_weight': 2}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  45%|████▌     | 45/100 [02:08<03:09,  3.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:30,959] Trial 44 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 301, 'classification__n_estimators': 693, 'classification__learning_rate': 0.0034786045780668324, 'classification__max_depth': 10, 'classification__subsample': 0.9335991417443812, 'classification__colsample_bytree': 0.6130119221561654, 'classification__lambda': 0.21851191692476263, 'classification__alpha': 0.1643116564781882, 'classification__min_child_weight': 5}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  46%|████▌     | 46/100 [02:10<02:33,  2.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:32,393] Trial 45 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 84, 'classification__n_estimators': 599, 'classification__learning_rate': 0.00900293145903232, 'classification__max_depth': 13, 'classification__subsample': 0.9557042039608781, 'classification__colsample_bytree': 0.8702932907975679, 'classification__lambda': 1.5368734016664174, 'classification__alpha': 0.3980480196751787, 'classification__min_child_weight': 4}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  47%|████▋     | 47/100 [02:12<02:22,  2.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:34,730] Trial 46 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 696, 'classification__n_estimators': 535, 'classification__learning_rate': 0.006653852837538544, 'classification__max_depth': 3, 'classification__subsample': 0.9010827397496638, 'classification__colsample_bytree': 0.7630938821870945, 'classification__lambda': 0.14871513353571414, 'classification__alpha': 1.2095505529939328, 'classification__min_child_weight': 10}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  48%|████▊     | 48/100 [02:16<02:44,  3.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:39,006] Trial 47 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 951, 'classification__n_estimators': 759, 'classification__learning_rate': 0.001972941203655838, 'classification__max_depth': 4, 'classification__subsample': 0.997733203948384, 'classification__colsample_bytree': 0.7897709321462977, 'classification__lambda': 0.41775881932713843, 'classification__alpha': 0.10029780747585992, 'classification__min_child_weight': 9}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  49%|████▉     | 49/100 [02:29<05:05,  5.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:51,566] Trial 48 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 912, 'classification__n_estimators': 825, 'classification__learning_rate': 0.004233688476898686, 'classification__max_depth': 11, 'classification__subsample': 0.8755037215654831, 'classification__colsample_bytree': 0.9659745753236068, 'classification__lambda': 0.28022460480730255, 'classification__alpha': 0.1283280809497902, 'classification__min_child_weight': 1}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  50%|█████     | 50/100 [02:32<04:12,  5.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:54,407] Trial 49 finished with value: 0.8441558441558441 and parameters: {'feature_selection__max_features': 574, 'classification__n_estimators': 907, 'classification__learning_rate': 0.009181412245903905, 'classification__max_depth': 8, 'classification__subsample': 0.8396187187449057, 'classification__colsample_bytree': 0.6691983456770807, 'classification__lambda': 0.5750922911032944, 'classification__alpha': 2.7895799197450146, 'classification__min_child_weight': 8}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  51%|█████     | 51/100 [02:37<04:08,  5.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:01:59,545] Trial 50 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 820, 'classification__n_estimators': 992, 'classification__learning_rate': 0.0034257296645893273, 'classification__max_depth': 12, 'classification__subsample': 0.9819616694675, 'classification__colsample_bytree': 0.6990837423391459, 'classification__lambda': 0.10120726729197314, 'classification__alpha': 0.30967068738847847, 'classification__min_child_weight': 7}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  52%|█████▏    | 52/100 [02:40<03:41,  4.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:03,091] Trial 51 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 625, 'classification__n_estimators': 432, 'classification__learning_rate': 0.00802041735441688, 'classification__max_depth': 9, 'classification__subsample': 0.9008570247656695, 'classification__colsample_bytree': 0.6784633218437481, 'classification__lambda': 0.809111791428356, 'classification__alpha': 0.21863283047780588, 'classification__min_child_weight': 3}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  53%|█████▎    | 53/100 [02:44<03:17,  4.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:06,362] Trial 52 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 651, 'classification__n_estimators': 293, 'classification__learning_rate': 0.007472129044599183, 'classification__max_depth': 10, 'classification__subsample': 0.9570032816165356, 'classification__colsample_bytree': 0.7226699423084264, 'classification__lambda': 0.18953454145840332, 'classification__alpha': 0.17116731810649002, 'classification__min_child_weight': 3}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  54%|█████▍    | 54/100 [02:46<02:41,  3.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:08,226] Trial 53 finished with value: 0.86676279740447 and parameters: {'feature_selection__max_features': 471, 'classification__n_estimators': 371, 'classification__learning_rate': 0.009164527449068533, 'classification__max_depth': 3, 'classification__subsample': 0.9381150323128814, 'classification__colsample_bytree': 0.65587961082588, 'classification__lambda': 0.6187100308933051, 'classification__alpha': 0.24844963834426678, 'classification__min_child_weight': 2}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  55%|█████▌    | 55/100 [02:50<02:49,  3.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:12,564] Trial 54 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 595, 'classification__n_estimators': 488, 'classification__learning_rate': 0.006880637506352015, 'classification__max_depth': 14, 'classification__subsample': 0.9189991524735747, 'classification__colsample_bytree': 0.751221611611207, 'classification__lambda': 0.356585284647227, 'classification__alpha': 0.1254415188245746, 'classification__min_child_weight': 3}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  56%|█████▌    | 56/100 [02:53<02:31,  3.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:15,269] Trial 55 finished with value: 0.8675268817204301 and parameters: {'feature_selection__max_features': 514, 'classification__n_estimators': 444, 'classification__learning_rate': 0.00791136536463661, 'classification__max_depth': 4, 'classification__subsample': 0.7291154798227326, 'classification__colsample_bytree': 0.6193017376822549, 'classification__lambda': 0.48722653561909923, 'classification__alpha': 0.5266068765434693, 'classification__min_child_weight': 2}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  57%|█████▋    | 57/100 [03:01<03:32,  4.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:23,685] Trial 56 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 772, 'classification__n_estimators': 616, 'classification__learning_rate': 0.005785192895350299, 'classification__max_depth': 9, 'classification__subsample': 0.9643149682225554, 'classification__colsample_bytree': 0.7367857796058201, 'classification__lambda': 0.23073061740212678, 'classification__alpha': 0.3544603386723837, 'classification__min_child_weight': 1}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  58%|█████▊    | 58/100 [03:02<02:43,  3.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:25,155] Trial 57 finished with value: 0.8558352402745995 and parameters: {'feature_selection__max_features': 116, 'classification__n_estimators': 867, 'classification__learning_rate': 0.009117348307950295, 'classification__max_depth': 3, 'classification__subsample': 0.8849593362983852, 'classification__colsample_bytree': 0.6760391537105115, 'classification__lambda': 11.857780583087004, 'classification__alpha': 0.18260526606708882, 'classification__min_child_weight': 4}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  59%|█████▉    | 59/100 [03:05<02:26,  3.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:27,997] Trial 58 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 419, 'classification__n_estimators': 670, 'classification__learning_rate': 0.006214096380204236, 'classification__max_depth': 5, 'classification__subsample': 0.9864910677110796, 'classification__colsample_bytree': 0.7014950343727542, 'classification__lambda': 0.13401278052323987, 'classification__alpha': 0.7738579891707792, 'classification__min_child_weight': 6}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  60%|██████    | 60/100 [03:10<02:34,  3.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:32,495] Trial 59 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 552, 'classification__n_estimators': 949, 'classification__learning_rate': 0.00101297688762118, 'classification__max_depth': 7, 'classification__subsample': 0.942775258610084, 'classification__colsample_bytree': 0.7820940526370338, 'classification__lambda': 0.3835475844163319, 'classification__alpha': 0.14981912159364694, 'classification__min_child_weight': 9}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  61%|██████    | 61/100 [03:13<02:25,  3.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:35,938] Trial 60 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 684, 'classification__n_estimators': 758, 'classification__learning_rate': 0.0011907268697313724, 'classification__max_depth': 12, 'classification__subsample': 0.7940110270741065, 'classification__colsample_bytree': 0.6503378582323716, 'classification__lambda': 0.17365425429096407, 'classification__alpha': 0.25715985902530214, 'classification__min_child_weight': 10}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  62%|██████▏   | 62/100 [03:16<02:08,  3.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:38,477] Trial 61 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 298, 'classification__n_estimators': 603, 'classification__learning_rate': 0.005069284370670077, 'classification__max_depth': 4, 'classification__subsample': 0.970179842044838, 'classification__colsample_bytree': 0.8369707452471725, 'classification__lambda': 0.289421981135623, 'classification__alpha': 0.11084730957564967, 'classification__min_child_weight': 4}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  63%|██████▎   | 63/100 [03:19<02:02,  3.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:41,677] Trial 62 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 413, 'classification__n_estimators': 633, 'classification__learning_rate': 0.0044269008177647414, 'classification__max_depth': 4, 'classification__subsample': 0.9617269432820603, 'classification__colsample_bytree': 0.8842311532852637, 'classification__lambda': 1.0196285530598859, 'classification__alpha': 0.15764748911427276, 'classification__min_child_weight': 5}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  64%|██████▍   | 64/100 [03:22<01:54,  3.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:44,512] Trial 63 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 336, 'classification__n_estimators': 546, 'classification__learning_rate': 0.005673223289478995, 'classification__max_depth': 6, 'classification__subsample': 0.9287641831958277, 'classification__colsample_bytree': 0.8141032195521591, 'classification__lambda': 0.7156100939001777, 'classification__alpha': 0.1188607360596084, 'classification__min_child_weight': 4}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  65%|██████▌   | 65/100 [03:25<01:49,  3.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:47,487] Trial 64 finished with value: 0.8916129032258064 and parameters: {'feature_selection__max_features': 444, 'classification__n_estimators': 691, 'classification__learning_rate': 0.007136907471083051, 'classification__max_depth': 3, 'classification__subsample': 0.9886340824982651, 'classification__colsample_bytree': 0.8513118546420915, 'classification__lambda': 0.32565503016265623, 'classification__alpha': 0.21318601939690396, 'classification__min_child_weight': 3}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  66%|██████▌   | 66/100 [03:29<01:57,  3.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:51,713] Trial 65 finished with value: 0.8916129032258064 and parameters: {'feature_selection__max_features': 629, 'classification__n_estimators': 735, 'classification__learning_rate': 0.007042501786900198, 'classification__max_depth': 3, 'classification__subsample': 0.9898785801973989, 'classification__colsample_bytree': 0.9278245702822401, 'classification__lambda': 0.4594829770622879, 'classification__alpha': 0.19189758342570815, 'classification__min_child_weight': 3}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  67%|██████▋   | 67/100 [03:32<01:50,  3.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:54,790] Trial 66 finished with value: 0.8916129032258064 and parameters: {'feature_selection__max_features': 374, 'classification__n_estimators': 743, 'classification__learning_rate': 0.006833913956429543, 'classification__max_depth': 3, 'classification__subsample': 0.9898661413084848, 'classification__colsample_bytree': 0.9333320704609258, 'classification__lambda': 0.48739817866297197, 'classification__alpha': 0.203815783634261, 'classification__min_child_weight': 3}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  68%|██████▊   | 68/100 [03:35<01:42,  3.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:02:57,720] Trial 67 finished with value: 0.8916129032258064 and parameters: {'feature_selection__max_features': 375, 'classification__n_estimators': 737, 'classification__learning_rate': 0.0070625459892493005, 'classification__max_depth': 3, 'classification__subsample': 0.9922904450609944, 'classification__colsample_bytree': 0.9135555059042324, 'classification__lambda': 0.47520108454101123, 'classification__alpha': 0.2110898285610086, 'classification__min_child_weight': 3}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  69%|██████▉   | 69/100 [03:38<01:39,  3.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:00,875] Trial 68 finished with value: 0.879862700228833 and parameters: {'feature_selection__max_features': 387, 'classification__n_estimators': 815, 'classification__learning_rate': 0.00717302349068861, 'classification__max_depth': 3, 'classification__subsample': 0.9876356876486913, 'classification__colsample_bytree': 0.917460721536466, 'classification__lambda': 0.4981508989821071, 'classification__alpha': 0.18498416845331359, 'classification__min_child_weight': 3}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.892108:  70%|███████   | 70/100 [03:41<01:34,  3.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:03,865] Trial 69 finished with value: 0.86676279740447 and parameters: {'feature_selection__max_features': 440, 'classification__n_estimators': 684, 'classification__learning_rate': 0.006410967977162433, 'classification__max_depth': 3, 'classification__subsample': 0.947263629060557, 'classification__colsample_bytree': 0.9555053477035443, 'classification__lambda': 1.4618069997035963, 'classification__alpha': 0.14462986360413255, 'classification__min_child_weight': 3}. Best is trial 10 with value: 0.8921078921078921.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  71%|███████   | 71/100 [03:45<01:36,  3.32s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:07,613] Trial 70 finished with value: 0.9038901601830663 and parameters: {'feature_selection__max_features': 474, 'classification__n_estimators': 889, 'classification__learning_rate': 0.007687286345702751, 'classification__max_depth': 3, 'classification__subsample': 0.9751891071539424, 'classification__colsample_bytree': 0.9173203185113273, 'classification__lambda': 0.3258234846982593, 'classification__alpha': 0.213022171617917, 'classification__min_child_weight': 3}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  72%|███████▏  | 72/100 [03:49<01:37,  3.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:11,534] Trial 71 finished with value: 0.879862700228833 and parameters: {'feature_selection__max_features': 468, 'classification__n_estimators': 897, 'classification__learning_rate': 0.007579515430075849, 'classification__max_depth': 3, 'classification__subsample': 0.9853588110817609, 'classification__colsample_bytree': 0.9951609177129225, 'classification__lambda': 0.3358078200650715, 'classification__alpha': 0.21140520813920752, 'classification__min_child_weight': 3}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  73%|███████▎  | 73/100 [03:52<01:29,  3.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:14,361] Trial 72 finished with value: 0.879862700228833 and parameters: {'feature_selection__max_features': 361, 'classification__n_estimators': 780, 'classification__learning_rate': 0.008632818307435697, 'classification__max_depth': 3, 'classification__subsample': 0.9673743584215377, 'classification__colsample_bytree': 0.9346020202045074, 'classification__lambda': 0.4420149568477977, 'classification__alpha': 0.28227526648934304, 'classification__min_child_weight': 3}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  74%|███████▍  | 74/100 [03:57<01:40,  3.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:19,578] Trial 73 finished with value: 0.8916129032258064 and parameters: {'feature_selection__max_features': 500, 'classification__n_estimators': 962, 'classification__learning_rate': 0.006970663939130419, 'classification__max_depth': 4, 'classification__subsample': 0.976538871881534, 'classification__colsample_bytree': 0.9121679833089299, 'classification__lambda': 0.2901410760285404, 'classification__alpha': 0.1008097880952349, 'classification__min_child_weight': 2}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  75%|███████▌  | 75/100 [04:01<01:37,  3.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:23,510] Trial 74 finished with value: 0.8916129032258064 and parameters: {'feature_selection__max_features': 543, 'classification__n_estimators': 849, 'classification__learning_rate': 0.008001586479011901, 'classification__max_depth': 3, 'classification__subsample': 0.9893520075565656, 'classification__colsample_bytree': 0.9342610841416991, 'classification__lambda': 0.764643428550489, 'classification__alpha': 0.3548343370273878, 'classification__min_child_weight': 4}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  76%|███████▌  | 76/100 [04:06<01:44,  4.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:28,972] Trial 75 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 734, 'classification__n_estimators': 927, 'classification__learning_rate': 0.00930765350162948, 'classification__max_depth': 4, 'classification__subsample': 0.9528922763430506, 'classification__colsample_bytree': 0.8985688893227717, 'classification__lambda': 0.2613485767472459, 'classification__alpha': 0.20179877104150148, 'classification__min_child_weight': 3}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  77%|███████▋  | 77/100 [04:10<01:35,  4.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:32,667] Trial 76 finished with value: 0.9038901601830663 and parameters: {'feature_selection__max_features': 575, 'classification__n_estimators': 746, 'classification__learning_rate': 0.00964490522085749, 'classification__max_depth': 3, 'classification__subsample': 0.9729874881986094, 'classification__colsample_bytree': 0.8663702810280347, 'classification__lambda': 0.38466766263381147, 'classification__alpha': 0.1418680748734033, 'classification__min_child_weight': 3}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  78%|███████▊  | 78/100 [04:13<01:23,  3.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:35,671] Trial 77 finished with value: 0.8803418803418803 and parameters: {'feature_selection__max_features': 587, 'classification__n_estimators': 891, 'classification__learning_rate': 0.00975289345725566, 'classification__max_depth': 4, 'classification__subsample': 0.9736755931788139, 'classification__colsample_bytree': 0.8650775236057157, 'classification__lambda': 0.3750214972339538, 'classification__alpha': 0.13723544355579473, 'classification__min_child_weight': 10}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  79%|███████▉  | 79/100 [04:18<01:27,  4.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:40,722] Trial 78 finished with value: 0.9038901601830663 and parameters: {'feature_selection__max_features': 648, 'classification__n_estimators': 993, 'classification__learning_rate': 0.008644153969943358, 'classification__max_depth': 3, 'classification__subsample': 0.9320538481940807, 'classification__colsample_bytree': 0.9540335024138052, 'classification__lambda': 0.16516277114150968, 'classification__alpha': 0.11885080972074089, 'classification__min_child_weight': 4}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  80%|████████  | 80/100 [04:23<01:30,  4.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:46,006] Trial 79 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 647, 'classification__n_estimators': 982, 'classification__learning_rate': 0.008702934320826356, 'classification__max_depth': 4, 'classification__subsample': 0.9143201647811866, 'classification__colsample_bytree': 0.9806670921750337, 'classification__lambda': 0.16372301660888178, 'classification__alpha': 0.11878172852987283, 'classification__min_child_weight': 4}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  81%|████████  | 81/100 [04:28<01:26,  4.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:50,595] Trial 80 finished with value: 0.8916129032258064 and parameters: {'feature_selection__max_features': 614, 'classification__n_estimators': 932, 'classification__learning_rate': 0.009985814868059042, 'classification__max_depth': 5, 'classification__subsample': 0.9253218640094767, 'classification__colsample_bytree': 0.9523872259855418, 'classification__lambda': 0.20137114856743682, 'classification__alpha': 0.1698645258372824, 'classification__min_child_weight': 4}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  82%|████████▏ | 82/100 [04:32<01:21,  4.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:55,087] Trial 81 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 680, 'classification__n_estimators': 801, 'classification__learning_rate': 0.0083990658439015, 'classification__max_depth': 3, 'classification__subsample': 0.9367713166067526, 'classification__colsample_bytree': 0.924558146751225, 'classification__lambda': 0.2380196616140455, 'classification__alpha': 0.14442256883647098, 'classification__min_child_weight': 3}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  83%|████████▎ | 83/100 [04:37<01:17,  4.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:03:59,758] Trial 82 finished with value: 0.8916129032258064 and parameters: {'feature_selection__max_features': 529, 'classification__n_estimators': 1000, 'classification__learning_rate': 0.007672857872458418, 'classification__max_depth': 3, 'classification__subsample': 0.9657798310017615, 'classification__colsample_bytree': 0.8967160056060428, 'classification__lambda': 0.11997664999642824, 'classification__alpha': 0.11373745710120109, 'classification__min_child_weight': 2}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  84%|████████▍ | 84/100 [04:41<01:10,  4.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:03,806] Trial 83 finished with value: 0.9038901601830663 and parameters: {'feature_selection__max_features': 560, 'classification__n_estimators': 872, 'classification__learning_rate': 0.009585635457493896, 'classification__max_depth': 3, 'classification__subsample': 0.9492268508642195, 'classification__colsample_bytree': 0.9483864788581606, 'classification__lambda': 0.6026320587403536, 'classification__alpha': 0.240238564732615, 'classification__min_child_weight': 3}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  85%|████████▌ | 85/100 [04:45<01:05,  4.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:07,959] Trial 84 finished with value: 0.9038901601830663 and parameters: {'feature_selection__max_features': 573, 'classification__n_estimators': 882, 'classification__learning_rate': 0.009414526885555, 'classification__max_depth': 4, 'classification__subsample': 0.9465609088858237, 'classification__colsample_bytree': 0.9546404146457792, 'classification__lambda': 0.5737567530093731, 'classification__alpha': 0.1352222757385271, 'classification__min_child_weight': 5}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  86%|████████▌ | 86/100 [04:49<00:59,  4.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:11,965] Trial 85 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 565, 'classification__n_estimators': 873, 'classification__learning_rate': 0.009441282623013511, 'classification__max_depth': 4, 'classification__subsample': 0.9019840814866508, 'classification__colsample_bytree': 0.9512529563920333, 'classification__lambda': 0.5771127157460262, 'classification__alpha': 0.13037421329170273, 'classification__min_child_weight': 5}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  87%|████████▋ | 87/100 [04:53<00:52,  4.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:15,586] Trial 86 finished with value: 0.8675268817204301 and parameters: {'feature_selection__max_features': 498, 'classification__n_estimators': 914, 'classification__learning_rate': 0.008743208973089304, 'classification__max_depth': 4, 'classification__subsample': 0.9465558359325639, 'classification__colsample_bytree': 0.9726943080328115, 'classification__lambda': 0.14534463086213922, 'classification__alpha': 0.11058834818930227, 'classification__min_child_weight': 5}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  88%|████████▊ | 88/100 [04:57<00:48,  4.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:19,490] Trial 87 finished with value: 0.8916129032258064 and parameters: {'feature_selection__max_features': 584, 'classification__n_estimators': 844, 'classification__learning_rate': 0.009497014231857207, 'classification__max_depth': 5, 'classification__subsample': 0.935771757106483, 'classification__colsample_bytree': 0.9449482899153466, 'classification__lambda': 0.38823734263028786, 'classification__alpha': 0.15920936104974837, 'classification__min_child_weight': 6}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  89%|████████▉ | 89/100 [05:02<00:47,  4.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:24,614] Trial 88 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 710, 'classification__n_estimators': 953, 'classification__learning_rate': 0.008398383852933147, 'classification__max_depth': 3, 'classification__subsample': 0.9560199926099994, 'classification__colsample_bytree': 0.9663096991070655, 'classification__lambda': 0.9371153836610849, 'classification__alpha': 7.6511558351353175, 'classification__min_child_weight': 4}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  90%|█████████ | 90/100 [05:05<00:38,  3.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:27,333] Trial 89 finished with value: 0.8434408602150538 and parameters: {'feature_selection__max_features': 451, 'classification__n_estimators': 888, 'classification__learning_rate': 0.008085552833557406, 'classification__max_depth': 5, 'classification__subsample': 0.9127668831458875, 'classification__colsample_bytree': 0.860397477636986, 'classification__lambda': 0.32839892406780463, 'classification__alpha': 0.43790455807351847, 'classification__min_child_weight': 9}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  91%|█████████ | 91/100 [05:09<00:35,  3.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:31,341] Trial 90 finished with value: 0.8675268817204301 and parameters: {'feature_selection__max_features': 639, 'classification__n_estimators': 970, 'classification__learning_rate': 0.008922488604931294, 'classification__max_depth': 4, 'classification__subsample': 0.6737377278000083, 'classification__colsample_bytree': 0.8874832607186421, 'classification__lambda': 0.26579253721599144, 'classification__alpha': 0.27476088421954814, 'classification__min_child_weight': 5}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  92%|█████████▏| 92/100 [05:13<00:32,  4.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:35,684] Trial 91 finished with value: 0.9038901601830663 and parameters: {'feature_selection__max_features': 608, 'classification__n_estimators': 939, 'classification__learning_rate': 0.009944888244842905, 'classification__max_depth': 3, 'classification__subsample': 0.9772165700613221, 'classification__colsample_bytree': 0.9038128732635313, 'classification__lambda': 0.6457384299478466, 'classification__alpha': 0.22778652271475214, 'classification__min_child_weight': 3}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  93%|█████████▎| 93/100 [05:16<00:27,  3.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:39,168] Trial 92 finished with value: 0.9038901601830663 and parameters: {'feature_selection__max_features': 566, 'classification__n_estimators': 947, 'classification__learning_rate': 0.009614541043783979, 'classification__max_depth': 3, 'classification__subsample': 0.9613701121685804, 'classification__colsample_bytree': 0.8778256015663614, 'classification__lambda': 0.20365054689777365, 'classification__alpha': 0.23611715860537486, 'classification__min_child_weight': 4}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  94%|█████████▍| 94/100 [05:20<00:23,  3.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:43,099] Trial 93 finished with value: 0.8921078921078921 and parameters: {'feature_selection__max_features': 605, 'classification__n_estimators': 938, 'classification__learning_rate': 0.009963666601978968, 'classification__max_depth': 3, 'classification__subsample': 0.9300573705205807, 'classification__colsample_bytree': 0.9079022307485545, 'classification__lambda': 0.1936941995632777, 'classification__alpha': 0.24516823750396485, 'classification__min_child_weight': 4}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  95%|█████████▌| 95/100 [05:24<00:18,  3.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:46,304] Trial 94 finished with value: 0.8550891316848763 and parameters: {'feature_selection__max_features': 551, 'classification__n_estimators': 915, 'classification__learning_rate': 0.00952628224804805, 'classification__max_depth': 3, 'classification__subsample': 0.9468694430930252, 'classification__colsample_bytree': 0.8738191083776509, 'classification__lambda': 27.817169722376658, 'classification__alpha': 0.16922312536719686, 'classification__min_child_weight': 10}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  96%|█████████▌| 96/100 [05:28<00:15,  3.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:50,741] Trial 95 finished with value: 0.86676279740447 and parameters: {'feature_selection__max_features': 664, 'classification__n_estimators': 999, 'classification__learning_rate': 0.008950404606238152, 'classification__max_depth': 4, 'classification__subsample': 0.9573015710470641, 'classification__colsample_bytree': 0.9442494240454125, 'classification__lambda': 0.16814205593504086, 'classification__alpha': 12.774254448317825, 'classification__min_child_weight': 5}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  97%|█████████▋| 97/100 [05:32<00:11,  3.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:04:54,659] Trial 96 finished with value: 0.879862700228833 and parameters: {'feature_selection__max_features': 523, 'classification__n_estimators': 971, 'classification__learning_rate': 0.008179171271043378, 'classification__max_depth': 3, 'classification__subsample': 0.9747040268099595, 'classification__colsample_bytree': 0.9049590171742621, 'classification__lambda': 0.6518518573140776, 'classification__alpha': 0.1326448355621412, 'classification__min_child_weight': 4}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  98%|█████████▊| 98/100 [05:38<00:09,  4.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:05:00,928] Trial 97 finished with value: 0.8792409430707303 and parameters: {'feature_selection__max_features': 873, 'classification__n_estimators': 945, 'classification__learning_rate': 0.009225500307215168, 'classification__max_depth': 4, 'classification__subsample': 0.9627822558907899, 'classification__colsample_bytree': 0.8817968287341198, 'classification__lambda': 0.5518559126137278, 'classification__alpha': 0.30767861867081225, 'classification__min_child_weight': 2}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389:  99%|█████████▉| 99/100 [05:42<00:04,  4.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:05:04,546] Trial 98 finished with value: 0.8916129032258064 and parameters: {'feature_selection__max_features': 571, 'classification__n_estimators': 885, 'classification__learning_rate': 0.007733289376826899, 'classification__max_depth': 3, 'classification__subsample': 0.920050490992471, 'classification__colsample_bytree': 0.9785780088423556, 'classification__lambda': 0.1316435946049217, 'classification__alpha': 0.23715274973978467, 'classification__min_child_weight': 6}. Best is trial 70 with value: 0.9038901601830663.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 70. Best value: 0.90389: 100%|██████████| 100/100 [05:47<00:00,  3.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-23 20:05:09,233] Trial 99 finished with value: 0.8916129032258064 and parameters: {'feature_selection__max_features': 608, 'classification__n_estimators': 849, 'classification__learning_rate': 0.009593376172171918, 'classification__max_depth': 4, 'classification__subsample': 0.9439713087517513, 'classification__colsample_bytree': 0.9885313038249787, 'classification__lambda': 0.21645764920391006, 'classification__alpha': 0.15280784462944463, 'classification__min_child_weight': 4}. Best is trial 70 with value: 0.9038901601830663.\n",
            "\n",
            "--- Optuna Search Complete ---\n",
            "Best validation F1-score: 0.9038901601830663\n",
            "\n",
            "--- Final Best Hyperparameters for Production Model ---\n",
            "{'feature_selection__max_features': 474, 'classification__n_estimators': 889, 'classification__learning_rate': 0.007687286345702751, 'classification__max_depth': 3, 'classification__subsample': 0.9751891071539424, 'classification__colsample_bytree': 0.9173203185113273, 'classification__lambda': 0.3258234846982593, 'classification__alpha': 0.213022171617917, 'classification__min_child_weight': 3}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import optuna\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# --- Configuration ---\n",
        "N_TRIALS = 100  \n",
        "VALIDATION_SET_SIZE = 0.2 # Use 20% of the data for validation in each trial.\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "def final_objective(trial, X_train_full, y_train_full):\n",
        "    params = {\n",
        "        'feature_selection__max_features': trial.suggest_int('feature_selection__max_features', 10, 1000),\n",
        "        'classification__n_estimators': trial.suggest_int('classification__n_estimators', 50, 1000),\n",
        "        'classification__learning_rate': trial.suggest_float('classification__learning_rate', 1e-3, 0.01, log=True),\n",
        "        'classification__max_depth': trial.suggest_int('classification__max_depth', 3, 15),\n",
        "        'classification__subsample': trial.suggest_float('classification__subsample', 0.6, 1.0),\n",
        "        'classification__colsample_bytree': trial.suggest_float('classification__colsample_bytree', 0.6, 1.0),\n",
        "        'classification__lambda': trial.suggest_float('classification__lambda', 0.1, 30.0, log=True),\n",
        "        'classification__alpha': trial.suggest_float('classification__alpha', 0.1, 20.0, log=True),\n",
        "        'classification__min_child_weight': trial.suggest_int('classification__min_child_weight', 1, 10)\n",
        "    }\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('feature_selection', SelectFromModel(RandomForestClassifier(random_state=42))),\n",
        "        ('classification', XGBClassifier(random_state=42, eval_metric='mlogloss')) # use_label_encoder=False is good practice\n",
        "    ])\n",
        "    pipeline.set_params(**params)\n",
        "\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=VALIDATION_SET_SIZE, random_state=42)\n",
        "    train_idx, val_idx = next(sss.split(X_train_full, y_train_full))\n",
        "\n",
        "    X_train, X_val = X_train_full.iloc[train_idx], X_train_full.iloc[val_idx]\n",
        "    y_train, y_val = y_train_full[train_idx], y_train_full[val_idx]\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    predictions = pipeline.predict(X_val)\n",
        "    score = f1_score(y_val, predictions, average='macro')\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    X_train_full, y_train_full = create_sub_writers_bootstrap(\n",
        "        train_df=all_writers_info,\n",
        "        feature_store=feature_store,\n",
        "        images_per_subwriter=4,\n",
        "        fold_seed=42 \n",
        "    )\n",
        "    print(f\"Augmented training set created with {len(X_train_full)} samples.\")\n",
        "\n",
        "    print(f\"\\nStarting Optuna hyperparameter search for {N_TRIALS} trials...\")\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    \n",
        "    objective_with_data = lambda trial: final_objective(trial, X_train_full, y_train_full)\n",
        "    \n",
        "    study.optimize(objective_with_data, n_trials=N_TRIALS, show_progress_bar=True)\n",
        "\n",
        "    final_best_params = study.best_params\n",
        "    print(\"\\n--- Optuna Search Complete ---\")\n",
        "    print(f\"Best validation F1-score: {study.best_value}\")\n",
        "    print(\"\\n--- Final Best Hyperparameters for Production Model ---\")\n",
        "    print(final_best_params)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af503fa0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;smote&#x27;, SMOTE(random_state=42)),\n",
              "                (&#x27;feature_selection&#x27;,\n",
              "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42),\n",
              "                                 max_features=474)),\n",
              "                (&#x27;classification&#x27;,\n",
              "                 XGBClassifier(alpha=0.213022171617917, base_score=None,\n",
              "                               booster=None, callbacks=None,\n",
              "                               colsample_bylevel=None, colsample_bynode=None,\n",
              "                               colsample_bytree=0.917...\n",
              "                               feature_types=None, feature_weights=None,\n",
              "                               gamma=None, grow_policy=None,\n",
              "                               importance_type=None,\n",
              "                               interaction_constraints=None,\n",
              "                               lambda=0.3258234846982593,\n",
              "                               learning_rate=0.007687286345702751, max_bin=None,\n",
              "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "                               max_delta_step=None, max_depth=3,\n",
              "                               max_leaves=None, min_child_weight=3, missing=nan,\n",
              "                               monotone_constraints=None, multi_strategy=None,\n",
              "                               n_estimators=889, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;smote&#x27;, SMOTE(random_state=42)),\n",
              "                (&#x27;feature_selection&#x27;,\n",
              "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42),\n",
              "                                 max_features=474)),\n",
              "                (&#x27;classification&#x27;,\n",
              "                 XGBClassifier(alpha=0.213022171617917, base_score=None,\n",
              "                               booster=None, callbacks=None,\n",
              "                               colsample_bylevel=None, colsample_bynode=None,\n",
              "                               colsample_bytree=0.917...\n",
              "                               feature_types=None, feature_weights=None,\n",
              "                               gamma=None, grow_policy=None,\n",
              "                               importance_type=None,\n",
              "                               interaction_constraints=None,\n",
              "                               lambda=0.3258234846982593,\n",
              "                               learning_rate=0.007687286345702751, max_bin=None,\n",
              "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "                               max_delta_step=None, max_depth=3,\n",
              "                               max_leaves=None, min_child_weight=3, missing=nan,\n",
              "                               monotone_constraints=None, multi_strategy=None,\n",
              "                               n_estimators=889, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SMOTE</div></div></label><div class=\"sk-toggleable__content \"><pre>SMOTE(random_state=42)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>feature_selection: SelectFromModel</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_selection.SelectFromModel.html\">?<span>Documentation for feature_selection: SelectFromModel</span></a></div></label><div class=\"sk-toggleable__content \"><pre>SelectFromModel(estimator=RandomForestClassifier(random_state=42),\n",
              "                max_features=474)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>estimator: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content \"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content \"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content \"><pre>XGBClassifier(alpha=0.213022171617917, base_score=None, booster=None,\n",
              "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9173203185113273, device=None,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=&#x27;mlogloss&#x27;, feature_types=None, feature_weights=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, lambda=0.3258234846982593,\n",
              "              learning_rate=0.007687286345702751, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=889, ...)</pre></div> </div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()), ('smote', SMOTE(random_state=42)),\n",
              "                ('feature_selection',\n",
              "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42),\n",
              "                                 max_features=474)),\n",
              "                ('classification',\n",
              "                 XGBClassifier(alpha=0.213022171617917, base_score=None,\n",
              "                               booster=None, callbacks=None,\n",
              "                               colsample_bylevel=None, colsample_bynode=None,\n",
              "                               colsample_bytree=0.917...\n",
              "                               feature_types=None, feature_weights=None,\n",
              "                               gamma=None, grow_policy=None,\n",
              "                               importance_type=None,\n",
              "                               interaction_constraints=None,\n",
              "                               lambda=0.3258234846982593,\n",
              "                               learning_rate=0.007687286345702751, max_bin=None,\n",
              "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "                               max_delta_step=None, max_depth=3,\n",
              "                               max_leaves=None, min_child_weight=3, missing=nan,\n",
              "                               monotone_constraints=None, multi_strategy=None,\n",
              "                               n_estimators=889, ...))])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "import optuna\n",
        "from optuna.distributions import FloatDistribution, IntDistribution\n",
        "# from sklearn.pipeline import Pipeline\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import joblib\n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('smote', SMOTE(random_state=42)),\n",
        "            ('feature_selection', SelectFromModel(RandomForestClassifier(random_state=42))),\n",
        "            ('classification', XGBClassifier(random_state=42, eval_metric='mlogloss'))\n",
        "        ])\n",
        "\n",
        "best_hyperparameters = final_best_params\n",
        "\n",
        "pipeline.set_params(**best_hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3491f44e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0\n",
              "1    1\n",
              "2    3\n",
              "3    4\n",
              "4    5\n",
              "5    6\n",
              "Name: name, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0|mean</th>\n",
              "      <th>0|median</th>\n",
              "      <th>0|std</th>\n",
              "      <th>0|skew</th>\n",
              "      <th>1|mean</th>\n",
              "      <th>1|median</th>\n",
              "      <th>1|std</th>\n",
              "      <th>1|skew</th>\n",
              "      <th>2|mean</th>\n",
              "      <th>2|median</th>\n",
              "      <th>...</th>\n",
              "      <th>637|std</th>\n",
              "      <th>637|skew</th>\n",
              "      <th>638|mean</th>\n",
              "      <th>638|median</th>\n",
              "      <th>638|std</th>\n",
              "      <th>638|skew</th>\n",
              "      <th>639|mean</th>\n",
              "      <th>639|median</th>\n",
              "      <th>639|std</th>\n",
              "      <th>639|skew</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.040413</td>\n",
              "      <td>1.280957</td>\n",
              "      <td>0.507247</td>\n",
              "      <td>-1.634625</td>\n",
              "      <td>-1.159289</td>\n",
              "      <td>-1.241885</td>\n",
              "      <td>0.464899</td>\n",
              "      <td>0.226526</td>\n",
              "      <td>1.880857</td>\n",
              "      <td>2.063291</td>\n",
              "      <td>...</td>\n",
              "      <td>0.694412</td>\n",
              "      <td>-0.121321</td>\n",
              "      <td>-0.798057</td>\n",
              "      <td>-0.891258</td>\n",
              "      <td>0.593199</td>\n",
              "      <td>1.456927</td>\n",
              "      <td>2.265608</td>\n",
              "      <td>2.281312</td>\n",
              "      <td>0.613156</td>\n",
              "      <td>-0.070073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.934578</td>\n",
              "      <td>-0.684685</td>\n",
              "      <td>0.876675</td>\n",
              "      <td>-0.531585</td>\n",
              "      <td>-1.353505</td>\n",
              "      <td>-1.126178</td>\n",
              "      <td>0.485313</td>\n",
              "      <td>-0.955035</td>\n",
              "      <td>-0.034474</td>\n",
              "      <td>-0.115520</td>\n",
              "      <td>...</td>\n",
              "      <td>1.043964</td>\n",
              "      <td>0.250822</td>\n",
              "      <td>-0.734064</td>\n",
              "      <td>-0.966799</td>\n",
              "      <td>0.707600</td>\n",
              "      <td>1.696434</td>\n",
              "      <td>-0.382077</td>\n",
              "      <td>-0.125341</td>\n",
              "      <td>0.555364</td>\n",
              "      <td>-0.791461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.588434</td>\n",
              "      <td>-0.489132</td>\n",
              "      <td>0.626406</td>\n",
              "      <td>0.217603</td>\n",
              "      <td>-0.098024</td>\n",
              "      <td>-0.090292</td>\n",
              "      <td>0.398646</td>\n",
              "      <td>0.237709</td>\n",
              "      <td>-0.224826</td>\n",
              "      <td>-0.164748</td>\n",
              "      <td>...</td>\n",
              "      <td>0.706273</td>\n",
              "      <td>-0.112840</td>\n",
              "      <td>-0.673228</td>\n",
              "      <td>-0.783320</td>\n",
              "      <td>0.388836</td>\n",
              "      <td>0.768802</td>\n",
              "      <td>1.231104</td>\n",
              "      <td>1.344649</td>\n",
              "      <td>0.723773</td>\n",
              "      <td>-0.476075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.085146</td>\n",
              "      <td>0.121908</td>\n",
              "      <td>0.921798</td>\n",
              "      <td>-0.473916</td>\n",
              "      <td>0.415825</td>\n",
              "      <td>0.346491</td>\n",
              "      <td>0.712960</td>\n",
              "      <td>0.447135</td>\n",
              "      <td>1.307174</td>\n",
              "      <td>1.396539</td>\n",
              "      <td>...</td>\n",
              "      <td>0.875910</td>\n",
              "      <td>-1.390163</td>\n",
              "      <td>-1.015302</td>\n",
              "      <td>-0.808681</td>\n",
              "      <td>0.640124</td>\n",
              "      <td>-1.573374</td>\n",
              "      <td>1.290129</td>\n",
              "      <td>1.042611</td>\n",
              "      <td>0.776999</td>\n",
              "      <td>1.529961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.493525</td>\n",
              "      <td>-0.451743</td>\n",
              "      <td>0.309951</td>\n",
              "      <td>-0.359937</td>\n",
              "      <td>-0.484127</td>\n",
              "      <td>-0.508899</td>\n",
              "      <td>0.491227</td>\n",
              "      <td>0.855808</td>\n",
              "      <td>-0.000721</td>\n",
              "      <td>0.027293</td>\n",
              "      <td>...</td>\n",
              "      <td>0.550214</td>\n",
              "      <td>-0.093284</td>\n",
              "      <td>-0.666505</td>\n",
              "      <td>-0.790870</td>\n",
              "      <td>0.448327</td>\n",
              "      <td>2.162568</td>\n",
              "      <td>0.404768</td>\n",
              "      <td>0.603208</td>\n",
              "      <td>0.371432</td>\n",
              "      <td>-1.817523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.929685</td>\n",
              "      <td>-0.900334</td>\n",
              "      <td>0.618008</td>\n",
              "      <td>-0.059490</td>\n",
              "      <td>-1.082905</td>\n",
              "      <td>-0.961740</td>\n",
              "      <td>0.465567</td>\n",
              "      <td>-1.370025</td>\n",
              "      <td>0.395181</td>\n",
              "      <td>0.418887</td>\n",
              "      <td>...</td>\n",
              "      <td>0.405486</td>\n",
              "      <td>-0.012981</td>\n",
              "      <td>-0.542955</td>\n",
              "      <td>-0.543840</td>\n",
              "      <td>0.459550</td>\n",
              "      <td>0.008677</td>\n",
              "      <td>-0.114262</td>\n",
              "      <td>0.064019</td>\n",
              "      <td>0.611162</td>\n",
              "      <td>-1.255014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 2560 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0|mean  0|median     0|std    0|skew    1|mean  1|median     1|std  \\\n",
              "0  1.040413  1.280957  0.507247 -1.634625 -1.159289 -1.241885  0.464899   \n",
              "1 -0.934578 -0.684685  0.876675 -0.531585 -1.353505 -1.126178  0.485313   \n",
              "2 -0.588434 -0.489132  0.626406  0.217603 -0.098024 -0.090292  0.398646   \n",
              "3 -0.085146  0.121908  0.921798 -0.473916  0.415825  0.346491  0.712960   \n",
              "4 -0.493525 -0.451743  0.309951 -0.359937 -0.484127 -0.508899  0.491227   \n",
              "5 -0.929685 -0.900334  0.618008 -0.059490 -1.082905 -0.961740  0.465567   \n",
              "\n",
              "     1|skew    2|mean  2|median  ...   637|std  637|skew  638|mean  \\\n",
              "0  0.226526  1.880857  2.063291  ...  0.694412 -0.121321 -0.798057   \n",
              "1 -0.955035 -0.034474 -0.115520  ...  1.043964  0.250822 -0.734064   \n",
              "2  0.237709 -0.224826 -0.164748  ...  0.706273 -0.112840 -0.673228   \n",
              "3  0.447135  1.307174  1.396539  ...  0.875910 -1.390163 -1.015302   \n",
              "4  0.855808 -0.000721  0.027293  ...  0.550214 -0.093284 -0.666505   \n",
              "5 -1.370025  0.395181  0.418887  ...  0.405486 -0.012981 -0.542955   \n",
              "\n",
              "   638|median   638|std  638|skew  639|mean  639|median   639|std  639|skew  \n",
              "0   -0.891258  0.593199  1.456927  2.265608    2.281312  0.613156 -0.070073  \n",
              "1   -0.966799  0.707600  1.696434 -0.382077   -0.125341  0.555364 -0.791461  \n",
              "2   -0.783320  0.388836  0.768802  1.231104    1.344649  0.723773 -0.476075  \n",
              "3   -0.808681  0.640124 -1.573374  1.290129    1.042611  0.776999  1.529961  \n",
              "4   -0.790870  0.448327  2.162568  0.404768    0.603208  0.371432 -1.817523  \n",
              "5   -0.543840  0.459550  0.008677 -0.114262    0.064019  0.611162 -1.255014  \n",
              "\n",
              "[6 rows x 2560 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 0 0 1 1 0]\n"
          ]
        }
      ],
      "source": [
        "X_test, y_test = create_writer_level_profile(real_world_data, all_features)\n",
        "display(X_test)\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99156986",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;smote&#x27;, SMOTE(random_state=42)),\n",
              "                (&#x27;feature_selection&#x27;,\n",
              "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42),\n",
              "                                 max_features=474)),\n",
              "                (&#x27;classification&#x27;,\n",
              "                 XGBClassifier(alpha=0.213022171617917, base_score=None,\n",
              "                               booster=None, callbacks=None,\n",
              "                               colsample_bylevel=None, colsample_bynode=None,\n",
              "                               colsample_bytree=0.917...\n",
              "                               feature_types=None, feature_weights=None,\n",
              "                               gamma=None, grow_policy=None,\n",
              "                               importance_type=None,\n",
              "                               interaction_constraints=None,\n",
              "                               lambda=0.3258234846982593,\n",
              "                               learning_rate=0.007687286345702751, max_bin=None,\n",
              "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "                               max_delta_step=None, max_depth=3,\n",
              "                               max_leaves=None, min_child_weight=3, missing=nan,\n",
              "                               monotone_constraints=None, multi_strategy=None,\n",
              "                               n_estimators=889, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;smote&#x27;, SMOTE(random_state=42)),\n",
              "                (&#x27;feature_selection&#x27;,\n",
              "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42),\n",
              "                                 max_features=474)),\n",
              "                (&#x27;classification&#x27;,\n",
              "                 XGBClassifier(alpha=0.213022171617917, base_score=None,\n",
              "                               booster=None, callbacks=None,\n",
              "                               colsample_bylevel=None, colsample_bynode=None,\n",
              "                               colsample_bytree=0.917...\n",
              "                               feature_types=None, feature_weights=None,\n",
              "                               gamma=None, grow_policy=None,\n",
              "                               importance_type=None,\n",
              "                               interaction_constraints=None,\n",
              "                               lambda=0.3258234846982593,\n",
              "                               learning_rate=0.007687286345702751, max_bin=None,\n",
              "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "                               max_delta_step=None, max_depth=3,\n",
              "                               max_leaves=None, min_child_weight=3, missing=nan,\n",
              "                               monotone_constraints=None, multi_strategy=None,\n",
              "                               n_estimators=889, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SMOTE</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(random_state=42)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>feature_selection: SelectFromModel</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_selection.SelectFromModel.html\">?<span>Documentation for feature_selection: SelectFromModel</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SelectFromModel(estimator=RandomForestClassifier(random_state=42),\n",
              "                max_features=474)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(alpha=0.213022171617917, base_score=None, booster=None,\n",
              "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9173203185113273, device=None,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=&#x27;mlogloss&#x27;, feature_types=None, feature_weights=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, lambda=0.3258234846982593,\n",
              "              learning_rate=0.007687286345702751, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=889, ...)</pre></div> </div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()), ('smote', SMOTE(random_state=42)),\n",
              "                ('feature_selection',\n",
              "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42),\n",
              "                                 max_features=474)),\n",
              "                ('classification',\n",
              "                 XGBClassifier(alpha=0.213022171617917, base_score=None,\n",
              "                               booster=None, callbacks=None,\n",
              "                               colsample_bylevel=None, colsample_bynode=None,\n",
              "                               colsample_bytree=0.917...\n",
              "                               feature_types=None, feature_weights=None,\n",
              "                               gamma=None, grow_policy=None,\n",
              "                               importance_type=None,\n",
              "                               interaction_constraints=None,\n",
              "                               lambda=0.3258234846982593,\n",
              "                               learning_rate=0.007687286345702751, max_bin=None,\n",
              "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "                               max_delta_step=None, max_depth=3,\n",
              "                               max_leaves=None, min_child_weight=3, missing=nan,\n",
              "                               monotone_constraints=None, multi_strategy=None,\n",
              "                               n_estimators=889, ...))])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.fit(X_train_full, y_train_full)\n",
        "\n",
        "\n",
        "# joblib.dump(pipeline, 'testo.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b9f19e3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 1, 0])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# loaded_pipeline = joblib.load('testo.joblib')\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e72c15d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.1505894 , 0.8494106 ],\n",
              "       [0.7568437 , 0.24315628],\n",
              "       [0.28022915, 0.71977085],\n",
              "       [0.17494231, 0.8250577 ],\n",
              "       [0.36758703, 0.63241297],\n",
              "       [0.54436284, 0.45563716]], dtype=float32)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dba1bebf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[[2 1]\n",
            " [0 3]]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAG2CAYAAAA9ev8TAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAALZ9JREFUeJzt3Ql0lEXW8PHbCZBAIGHf952IrDJ+iMMisuiRRYdxBlEQ1NeNRRFFXl4FRUFRcRdQRNCRkRlER0BAVFZBEARGR0ARFBAQGAYCwZDQz/OdW5gems00Xd39dPL/eeqQftJdXcSm++bWrSqf67quAAAAWJRgszMAAABFgAEAAKwjwAAAANYRYAAAAOsIMAAAgHUEGAAAwDoCDAAAYB0BBgAAsI4AAwAAWEeAAQAArCPAAAAAQSZOnChNmjSR1NRU01q3bi3z58+XUPg4iwQAAJxqzpw5kpiYKPXq1RMNE6ZPny5PPfWUrF+/Xi666CLJCwIMAADwm0qXLm2CjFtuueW37ywihfJ0L1jnOI7s3r1bSpQoIT6fL9bDAQCESH8/P3LkiFSuXFkSEiJTcZCVlSXZ2dnWxnv6501SUpJp5+P3++Xvf/+7ZGZmmqmSUJ4QMbBz507NHNFoNBotzpu+n0fCL7/84lYsn2htnMWLFz/j2qhRo875/P/85z/dlJQUNzEx0U1LS3PnzZsX0vjJYMSIZi5U0zfvksRi548egXiVM69srIcARIw/O0u+eXtM4P3ctuzsbNm7zy8/rqspqSXCy5BkHHGkRssfZOfOnaZoM9f5shcNGjSQDRs2yOHDh2XWrFnSr18/Wbp0qaSnp+fpOQkwYiQ3TaXBRWIKAQbyJ6dIcqyHAERcpKe5i5fwmRYOR04+PndVSF4UKVJE6tata75u2bKlfPHFF/L888/L5MmT8/R4AgwAADzM7zrid8Pvw0bt4PHjx/N8fwIMAAA8zBHXtHD7CMWIESPkqquukurVq5tC1hkzZsiSJUtk4cKFee6DAAMAAATZt2+f9O3bV/bs2SNpaWlm0y0NLjp16iR5RYABAICHOea/8PsIxeuvvx7mMxJgAADgaX7XNS3cPqKNs0gAAIB1ZDAAAPAwJwZFnjYQYAAA4GGOuOKPwwCDKRIAAGAdGQwAADzMYYoEAADY5mcVCQAAwElkMAAA8DDn1xZuH9FGgAEAgIf5LawiCffxF4IAAwAAD/O7J1u4fUQbNRgAAMA6MhgAAHiYQw0GAACwzRGf+MUXdh/RxhQJAACwjgwGAAAe5rgnW7h9RBsBBgAAHua3MEUS7uMvBFMkAADAOjIYAAB4mD9OMxgEGAAAeJjj+kwLt49oY4oEAABYRwYDAAAP8zNFAgAAbPNLgmnh9RF9BBgAAHiYa6EGQ/uINmowAACAdWQwAADwMD81GAAAwDa/m2BaeH1I1DFFAgAArCODAQCAhzniEyfMfIAj0U9hEGAAAOBh/jitwWCKBAAAWEcGAwCAfF/k6Uq0EWAAAOD5Ggxf2H1EG1MkAADAOjIYAAB4mGPhLBJWkQAAgCDUYAAAgIhkMJw4zGBQgwEAAKwjgwEAgIf5XZ9p4fYRbQQYAAB4mN9CkaefKRIAAJAfkMEAAMDDHDfBtPD6YBUJAAA4BVMkAAAAvyKDAQCAhzkWVoFoH9FGgAEAQL7faCtBoo0pEgAAYB0ZDAAA8v1ZJAkSbQQYAAB4mCM+08LtI9oIMAAA8DB/nGYwqMEAAADWkcEAACDfb7SVINFGgAEAgIc5rs+0cPuINqZIAACAdWQwAADwMMfCFEksNtoiwAAAIN+fppog0cYUCQAAsI4MBgAAHuYXn2nh9hFtBBgAAHiYwxQJAADASWQwAADwML+FKQ7tI9oIMAAA8DAnTqdICDAAAPAwP4edAQAAnEQGAwAAD3PFJ06YNRjaR7QRYAAA4GF+pkgAAABOIoMBAICHOXF6XDsBBgAAHua3cJpquI+/EEyRAAAA68hgAADgYQ5TJAAAwDZHEkwLt49oY4oEAABYRwYDAAAP87s+08LtI9oIMAAA8DCHGgwAAGCba+E0Ve0j2qjBAAAA1pHBAADAw/ziMy3cPqKNAAMAAA9z3PBrKLSPaGOKBAAAWEcGA/la0syDUmhlpiTuyha3SIL4GyVL1oAy4lQtEuuhAVY0r7Fb+l62URpV3i/lShyT+97pIks214r1sGCRY6HIM9zHx2UGY+/evTJkyBCpW7euJCcnS4UKFaRNmzYyceJEOXbsWKyHhziX+HWWZF+TJkcnVJXMxyvrYnBJGblbJMuJ9dAAK4oWPiHf/lxGnpz3+1gPBRHiiM9KK1AZjG3btplgomTJkjJ27Fi5+OKLJSkpSb766it59dVXpUqVKtK9e/eQ+83OzpYiRfgNFSLHxlQOuv3L0AqS2nu7JH53XPwXF43ZuABbVm6tbhrgNTHNYNx1111SqFAhWbt2rVx//fXSqFEjqV27tvTo0UPmzZsn3bp1M/c7dOiQ3HrrrVKuXDlJTU2VK664QjZu3BjoZ/To0dKsWTOZMmWK1KpVy2RClM/nk8mTJ8s111wjxYoVM/2vWrVKtm7dKu3bt5eUlBS57LLL5Pvvvw/0pV/r82smpXjx4tKqVSv5+OOPg8Zds2ZNExANGDBASpQoIdWrVzcBEbzPl+k3f7olYp68A4CQdvIMt0VbzN5l//3vf8tHH30kd999t/mgPxsNENQf//hH2bdvn8yfP1/WrVsnLVq0kI4dO8rBgwcD99Wg4d1335XZs2fLhg0bAtfHjBkjffv2NdcaNmwoN9xwg9x+++0yYsQIE9i4risDBw4M3P/o0aNy9dVXyyeffCLr16+Xrl27mkBnx44dQWN75pln5JJLLjH30UDpzjvvlC1btkTgJwVrHFeSJx+QE+nJ4tRMivVoACCkGoxwW4EJMDQg0A/3Bg0aBF0vW7asyRxoGz58uKxYsULWrFkjf//7380Her169eTpp5820yqzZs0KmhZ58803pXnz5tKkSZPA9f79+5vsSP369U1/P/zwg/Tp00e6dOliMhpa/7FkyZLA/Zs2bWoCkMaNG5vn0gClTp068sEHHwSNU4MQDSy0dkT71XEvXrz4nH/f48ePS0ZGRlBDdCW/sl8Sf8yWYw9WjPVQACDf81yeWIMJzTZcdNFF5kNZp0I0q1CmTJlA4KFt+/btQVMbNWrUMFMopzs12NBpD6W1Hqdey8rKCnzg63MNGzbMBB8axOhzbdq06YwMxqn9aqalYsWKJstyLuPGjZO0tLRAq1at2gX/jHBhwUXhNcfk6BNVxC3L4ikA8cPRIk03zFaQijz1N3/9YD59WkFrMFTRokUDH/iVKlUKyjLk0gAg17mmWQoXLnzGlMvZrjnOyVUFGlwsWrTIZEl0jDqOXr16mQzJufrN7Se3j7PRKZmhQ4cGbmtAQ5ARBa4ryRMPSOFVRyVTg4uKwf/fAMDrXAurQLSPAhNgaEaiU6dO8tJLL8mgQYPOGSBovYUuZdViUC2ujLTPPvtMbr75Zrn22msDAY5Oq4RLV8doQ/QzF0WWHJXMhyuJWzRBfAdPmOtuSoJIkucSeEDIihbJkWqlDwduVy6ZIfUrHpCMX5Jk7+ESMR0b7OA01QvwyiuvmGWqWluhK0F02iEhIUG++OIL2bx5s7Rs2VKuvPJKad26tfTs2VPGjx9vail2795tVploEKCPtUnrLrRQVAs7NSvx0EMPnTczAW9Lmndy6qv48J+Crh+7t7zkdEqN0agAe9Ir75NXb54TuH1f11Xmzzkb6svo96+I4chQ0MU0wNDiSV2FoUs+dQph165d5rf89PR0M1WhRZT6If/hhx/KyJEjTcHm/v37Tb1D27ZtAzUVNk2YMMEsP9Xlq1q4qQWcFGTGr8Mf1o31EICIWvdDFWk5+o5YDwMR5MTpTp4+V5dyIOo0aNFizxaz7pXEFKZOkD/lvH9m4TWQX/izs+SrN0bK4cOHzR5Nkfqc6PHRACmcEt7mkTmZ2fKPzlMjNtazYRIaAABYx3o9AAA8zLGwiqRALVMFAAD5dxUJUyQAAMA6MhgAAHiYE6cZDAIMAAA8zInTAIMpEgAAYB0ZDAAAPMyJ0wwGAQYAAB7mWlhmGosdNQkwAADwMCdOMxjUYAAAAOvIYAAA4GFOnGYwCDAAAPAwJ04DDKZIAACAdWQwAADwMCdOMxgEGAAAeJjr+kwLt49oY4oEAABYRwYDAAAPc8QX9kZb4T7+QhBgAADgYU6c1mAwRQIAAKwjwAAAIA6KPN0wWyjGjRsnrVq1khIlSkj58uWlZ8+esmXLlpD6IMAAACAOpkicMFsoli5dKnfffbd8/vnnsmjRIsnJyZHOnTtLZmZmnvugBgMAAA9zY7BMdcGCBUG3p02bZjIZ69atk7Zt2+apDwIMAAAKiIyMjKDbSUlJpv2Ww4cPmz9Lly6d5+diigQAAA9zLUyP5GYwqlWrJmlpaYGmtRa/xXEcueeee6RNmzbSuHHjPI+bDAYAAB7mmiAj/D7Uzp07JTU1NXA9L9kLrcX4+uuvZcWKFSE9JwEGAAAFRGpqalCA8VsGDhwoc+fOlWXLlknVqlVDei4CDAAAPMwRn/kv3D5C4bquDBo0SN577z1ZsmSJ1KpVK+TnJMAAAMDD3BisItFpkRkzZsg//vEPsxfG3r17zXWt2yhatGie+qDIEwAABJk4caJZOdK+fXupVKlSoM2cOVPyigwGAAAe5rg+8UX5LBKdIgkXAQYAAB7muhZWkYQfL4SMKRIAAGAdGQwAADzMjUGRpw0EGAAAeJhLgAEAAPJDkacN1GAAAADryGAAAOBhbpyuIiHAAADA8wGGL+w+oo0pEgAAYB0ZDAAAPMxlFQkAALDN/bWF20e0MUUCAACsI4MBAICHuUyRAAAA69z4nCMhwAAAwMvc8DMY2ke0UYMBAACsI4MBAICHuezkCQAAbHPjtMiTKRIAAGAdGQwAALzM9YVfpMkyVQAAkB9qMJgiAQAA1pHBAADAy9x8vNHWBx98kOcOu3fvHs54AABAPlhFkqcAo2fPnnnqzOfzid/vD3dMAAAgzuUpwHAcJ/IjAQAA3jlvPZY1GFlZWZKcnGxvNAAAIF9MkYS8ikSnQMaMGSNVqlSR4sWLy7Zt28z1hx56SF5//fVIjBEAgILLtdS8HmA8/vjjMm3aNBk/frwUKVIkcL1x48YyZcoU2+MDAABxKOQA480335RXX31V+vTpI4mJiYHrTZs2lc2bN9seHwAABZzPUvN4DcZPP/0kdevWPWshaE5Ojq1xAQCAON4HI+QMRnp6uixfvvyM67NmzZLmzZvbGhcAAIhjIWcwHn74YenXr5/JZGjWYvbs2bJlyxYzdTJ37tzIjBIAgILKLSAZjB49esicOXPk448/lpSUFBNwbNq0yVzr1KlTZEYJAEBBP03VDbPFwz4Yv//972XRokX2RwMAAPKFC95oa+3atSZzkVuX0bJlS5vjAgAAEr/HtYccYOzatUt69+4tn332mZQsWdJcO3TokFx22WXyzjvvSNWqVSMxTgAACia3gNRg3HrrrWY5qmYvDh48aJp+rQWf+j0AAICQMxhLly6VlStXSoMGDQLX9OsXX3zR1GYAAACLbBRpxkORZ7Vq1c66oZaeUVK5cmVb4wIAACLic0+2cPvw/BTJU089JYMGDTJFnrn06yFDhsjTTz9te3wAABRsbnwedpanDEapUqXE5/tveiUzM1MuvfRSKVTo5MNPnDhhvh4wYID07NkzcqMFAABxIU8BxnPPPRf5kQAAgIJVg6FbgwMAgBhw43OZ6gVvtKWysrIkOzs76Fpqamq4YwIAAHEu5CJPrb8YOHCglC9f3pxFovUZpzYAAGBRnBZ5hhxgPPDAA/Lpp5/KxIkTJSkpSaZMmSKPPPKIWaKqJ6oCAACL4jTACHmKRE9N1UCiffv20r9/f7O5Vt26daVGjRry9ttvS58+fSIzUgAAEDdCzmDo1uC1a9cO1FvobXX55ZfLsmXL7I8QAICCzI3P49pDDjA0uNi+fbv5umHDhvK3v/0tkNnIPfwMAADY3ckz3Ob5AEOnRTZu3Gi+fvDBB+Xll1+W5ORkuffee+X++++PxBgBAECcCbkGQwOJXFdeeaVs3rxZ1q1bZ+owmjRpYnt8AAAUbG4B3AdDaXGnNgAAgJACjBdeeEHyavDgwXm+LwAAOD8tzwz7NFXxaIDx7LPP5qkzPRCNAAMAAOQpwMhdNQL7Unttk0K+wrEeBhARC3fPivUQgIjJOOJIqTei8ERuPj7sDAAAxIgbn0WeIS9TBQAA+C1kMAAA8DI3PjMYBBgAAHiYz8JOnHGxkycAAEBEAozly5fLjTfeKK1bt5affvrJXHvrrbdkxYoVF9IdAADIZ8e1hxxgvPvuu9KlSxcpWrSorF+/Xo4fP26uHz58WMaOHRuJMQIAUHC5BSTAeOyxx2TSpEny2muvSeHC/92/oU2bNvLll1/aHh8AAIhDIRd5btmyRdq2bXvG9bS0NDl06JCtcQEAAClARZ4VK1aUrVu3nnFd6y9q165ta1wAAODUnTzDbV4PMG677TYZMmSIrF692pw9snv3bnn77bdl2LBhcuedd0ZmlAAAFFRufNZghDxF8uCDD4rjONKxY0c5duyYmS5JSkoyAcagQYMiM0oAABBXQg4wNGsxcuRIuf/++81UydGjRyU9PV2KFy8emRECAFCA+eK0BuOCd/IsUqSICSwAAEAEuQVkq/AOHTqYLMa5fPrpp+GOCQAAxLmQA4xmzZoF3c7JyZENGzbI119/Lf369bM5NgAA4FqY4oiHDMazzz571uujR4829RgAAMCiOJ0isXbYmZ5NMnXqVFvdAQCAOGbtuPZVq1ZJcnKyre4AAEAcZzBCDjCuu+66oNuu68qePXtk7dq18tBDD9kcGwAABZ6voCxT1TNHTpWQkCANGjSQRx99VDp37mxzbAAAIE6FFGD4/X7p37+/XHzxxVKqVKnIjQoAAMS1kIo8ExMTTZaCU1MBAIgSNz7PIgl5FUnjxo1l27ZtkRkNAAA4aw1GuM3zAcZjjz1mDjabO3euKe7MyMgIagAAAHmuwdAizvvuu0+uvvpqc7t79+5BW4brahK9rXUaAADAohhkIKIWYDzyyCNyxx13yOLFiyM7IgAAUHD2wdAMhWrXrl0kxwMAAAraMtXznaIKAADs8xWEjbbq16//m0HGwYMHwx0TAAAoKFMkuXUYp+/kCQAAEFaA8ec//1nKly8fykMAAEAY8v0UCfUXAADEgBufUyQJoa4iAQAAsJbBcBwnr3cFAAAFPIMR8nHtAAAgenz5vQYDAADEgBufGYyQDzsDAAD4LWQwAADwMjc+MxgEGAAAeJgvTmswmCIBAADWkcEAAMDLXKZIAACAZT6mSAAAAE4igwEAgJe5TJEAAADb3PgMMJgiAQAA1pHBAADAw3y/tnD7iDYCDAAAvMyNzykSAgwAADzMxzJVAACAk8hgAADgZS5TJAAAIBJciTtMkQAAAOvIYAAA4GG+OC3yJMAAAMDL3PiswWCKBAAABFm2bJl069ZNKleuLD6fT95//30JFQEGAABxMEXiC7OFIjMzU5o2bSovv/zyBY+bKRIAALzMjf4UyVVXXWVaOMhgAAAA68hgAABQQFaRZGRkBF1PSkoyLRLIYAAAEA9TJG6YTUSqVasmaWlpgTZu3LiIDZsMBgAABaQGY+fOnZKamhq4HKnshSLAAACggEhNTQ0KMCKJAAMAAA/zxWAnz6NHj8rWrVsDt7dv3y4bNmyQ0qVLS/Xq1fPUBwEGAABe5kZ/meratWulQ4cOgdtDhw41f/br10+mTZuWpz4IMAAAQJD27duL64YX1RBgAADgYT7XNS3cPqKNAAMAAC9zOewMAADAIIMBAICH+WKwisQGAgwAALzMZYoEAADAIIMBAICHMUUCAADsc+NzioQAAwAAD/PFaQaDGgwAAGAdGQwAALzMZYoEAABEgC8GAUK4mCIBAADWkcEAAMDLXPdkC7ePKCPAAADAw3ysIgEAADiJDAYAAF7msooEAABY5nNOtnD7iDamSAAAgHUEGCGaNm2alCxZMtbDQIi63XxApq/+RuZs+6c8P/c7adDsWKyHBFgxZ3oZuaNjA7m2/sWm3dOtnnzxaYlYDwuRmCIJt0WZ5wOMm2++WXw+3xlt69atsR4a4kS77v+R/xm1W96eUFHu7lJftn2TLI/P2CZpZXJiPTQgbOUq5ciA/90tLy3YIi/O/1aatjkio/vXkh+2JMd6aLC8iiTcFm2eDzBU165dZc+ePUGtVq1aQffJzs6O2fjgbdf9zwFZMKO0fDSztOz4LlleGF5Vjv/iky69D8Z6aEDY/l/nDPldxyNSpXa2VK1zXPo/uFeSUxzZvK5YrIcG2/tghNuiLC4CjKSkJKlYsWJQ69ixowwcOFDuueceKVu2rHTp0sXc9+uvv5arrrpKihcvLhUqVJCbbrpJDhw4EOirffv2MnjwYHnggQekdOnSpq/Ro0cHPd+hQ4fk9ttvN49PTk6Wxo0by9y5c4Pus3DhQmnUqJF5ntwACN5TqLAj9Zocky+X/zdl7Lo+Wb+8hKS3ZJoE+YvfL7Lk/ZJy/FiCNLokM9bDQQEXFwHGuUyfPl2KFCkin332mUyaNMkEBldccYU0b95c1q5dKwsWLJCff/5Zrr/++jMel5KSIqtXr5bx48fLo48+KosWLTLfcxzHBCja51/+8hf55ptv5IknnpDExMTA448dOyZPP/20vPXWW7Js2TLZsWOHDBs27LxjPX78uGRkZAQ1RF5qab8kFhI5tD94wdR/DhSSUuVOxGxcgE3bNyVLj7oXyzU1m8oLD1aTh1/fLjXqH4/1sFDAp0jiYpmqZg80U5BLAwBVr149EyDkeuyxx0xwMXbs2MC1qVOnSrVq1eTbb7+V+vXrm2tNmjSRUaNGBfp46aWX5JNPPpFOnTrJxx9/LGvWrJFNmzYF7l+7du2g8eTk5JiApk6dOua2ZlI0SDmfcePGySOPPGLhpwEAwXRq5JVFW+TYkURZPrekPD2khjw1+zuCjPzCjc99MOIig9GhQwfZsGFDoL3wwgvmesuWLYPut3HjRlm8eLEJRnJbw4YNzfe+//77wP00wDhVpUqVZN++feZr7b9q1aqB4OJsihUrFgguTn/8uYwYMUIOHz4caDt37gzpZ4ALk3EwUfwnREqelq0oVfaE/Oe0rAYQrwoXcaVKrWyp1+QXGfC/e6RW+i/y/pRysR4WCri4eIfV6Yy6deue9fqpjh49Kt26dZMnn3zyjPtqEJCrcOHCQd/TVSk6NaKKFi36m+M52+Pd3yig0ToSbYiuEzkJ8t0/i0nzy4/IqgVp5prP50qzy4/KB9PKxHp4QETo21FOdlz8/oh8fBZJXAQYedWiRQt59913pWbNmlKo0IX91TS7sWvXrqApFcS32a+WlWHP7ZRvNxaTLeuLybW37ZfkYo589E7pWA8NCNvUsZWk1RUZUq5KjvxyNEEWv1dK/rmyuDw+479ZW8Q5l9NUY+7uu++W1157TXr37h1YJaL7ZbzzzjsyZcqUoELNc2nXrp20bdtW/vCHP8iECRNM5mTz5s0mS6GrRRB/ln5QStLK+KXv/XtNYee2fxWVkX1qyaEDwZkoIB4dOlBInhpcQw7uKyTFSvilVqMsE1y0bHc01kNDAZevAozKlSub1R/Dhw+Xzp07m5UbNWrUMIFBQkLe04WaBdFVIRqoZGZmmiBDV5Igfn3wRlnTgPxm6ATqufI7X5xOkfjc3yoeQEToMtW0tDRpLz2kkI/fpJE/Ldy9IdZDACIm44gjpepvM4X7qampEfucaN31USlUOLydWU/kZMmqBQ9HbKxnQxUQAACwLl9NkQAAkN/44nSKhAADAAAvc9yTLdw+oowAAwAAL3PZyRMAAMAggwEAgIf5LNRQaB/RRoABAICXufG5kydTJAAAwDoyGAAAeJiPZaoAAMA6l1UkAAAABhkMAAA8zOe6poXbR7QRYAAA4GXOry3cPqKMKRIAAGAdGQwAADzMxxQJAACwzo3PVSQEGAAAeJnLTp4AAAAGGQwAADzMx06eAADAOpcpEgAAAIMMBgAAHuZzTrZw+4g2AgwAALzMZYoEAADAIIMBAICXuWy0BQAALPPF6VbhTJEAAADryGAAAOBlbnwWeRJgAADgZa6IhLvMlBoMAABwKmowAAAAfkUGAwAAzy9TdcPvI8oIMAAA8DI3Pos8mSIBAADWkcEAAMDLHK3StNBHlBFgAADgYT5WkQAAAJxEBgMAAC9z47PIkwADAAAvc+MzwGCKBAAAWEcGAwAAL3PjM4NBgAEAgJc5LFMFAACW+VimCgAAcBIZDAAAvMylBgMAANjmuDrHEX4fUcYUCQAAsI4MBgAAXuYyRQIAAKxzLQQITJEAAIB8gAwGAABe5jJFAgAAbHM0OGAVCQAAABkMAAA8zXVOtnD7iDICDAAAvMylBgMAANjmUIMBAABgkMEAAMDLXKZIAACAba6FACH68QVTJAAAwD4yGAAAeJnLFAkAALDN0T0sHAt9RBdTJAAAwDoyGAAAeJnLFAkAALDNjc8AgykSAABgHRkMAAC8zInPrcIJMAAA8DDXdUwLt49oI8AAAMDLXDf8DAQ1GAAAID8ggwEAgJe5FmowWKYKAADO2IXTF2YNRQxqMJgiAQAA1pHBAADAy1ymSAAAgGWu44jri79lqkyRAAAA68hgAADgZS5TJAAAwDbHFfHFX4DBFAkAALCODAYAAF7mavYh3H0wmCIBAACncB1X3DCnSFwCDAAAEMQsMWUnTwAAkA+8/PLLUrNmTUlOTpZLL71U1qxZE9LjCTAAAPD6FIkTfgvFzJkzZejQoTJq1Cj58ssvpWnTptKlSxfZt29fnvsgwAAAwMtcx04LwYQJE+S2226T/v37S3p6ukyaNEmKFSsmU6dOzXMf1GDESG7BzQnJCXv/FMCrMo5Ef94XiJaMo05UCihPWPicMH3omDMygq4nJSWZdqrs7GxZt26djBgxInAtISFBrrzySlm1alWen5MAI0aOHDli/lwhH8Z6KEDElKof6xEA0Xk/T0tLs95vkSJFpGLFirJir53PieLFi0u1atWCrukUyOjRo4OuHThwQPx+v1SoUCHout7evHlznp+PACNGKleuLDt37pQSJUqIz+eL9XDyPY3a9R+W/sxTU1NjPRzAOl7j0aeZCw0u9P08EpKTk2X79u0mo2BrvKd/3pyevbCJACNGNN1UtWrVWA+jwNE3Xt58kZ/xGo+uSGQuTg8ytEVT2bJlJTExUX7++eeg63pbMyp5RZEnAAAImppp2bKlfPLJJ4FrjuOY261bt5a8IoMBAACC6BLVfv36ySWXXCK/+93v5LnnnpPMzEyzqiSvCDBQIOg8oxYzRXK+EYglXuOw6U9/+pPs379fHn74Ydm7d680a9ZMFixYcEbh5/n43FhsUA4AAPI1ajAAAIB1BBgAAMA6AgwAAGAdAQYAFHDTpk2TkiVLxnoYyGcIMOAJWqU8ZMgQqVu3rtlURiuV27RpIxMnTpRjx47FeniAVTfffLPZUfH0tnXr1lgPDbCGZaqIuW3btplgQn+DGjt2rFx88cVmqd1XX30lr776qlSpUkW6d+8ecr+6va5uGAN4UdeuXeWNN94IulauXLmg27yGEc/IYCDm7rrrLilUqJCsXbtWrr/+emnUqJHUrl1bevToIfPmzZNu3bqZ+x06dEhuvfVW8yasWyFfccUVsnHjxkA/emCPrtWeMmWK1KpVK7C9rv5mOHnyZLnmmmvMccPav54IqL8ttm/fXlJSUuSyyy6T77//PtCXfq3Pr5kUPSCoVatW8vHHHweNu2bNmiYgGjBggDlTpnr16iYgAvJCg2jddvnU1rFjRxk4cKDcc889ZrvmLl26mPt+/fXXctVVV5nXor4mb7rpJnMgVS59HQ8ePFgeeOABKV26tOnr9AOs9N/P7bffbh6v/zYaN24sc+fODbrPwoULzb8PfR4NgPbs2ROlnwbyIwIMxNS///1v+eijj+Tuu+82H/Rnk3s4zx//+EfZt2+fzJ8/3xwl3KJFC/OGfPDgwcB9NWh49913Zfbs2bJhw4bA9TFjxkjfvn3NtYYNG8oNN9xg3mz1OGINbHQ7GH1jz3X06FG5+uqrzda469evN2+2Gujs2LEjaGzPPPOM2elO76OB0p133ilbtmyJwE8KBcX06dNN1uKzzz6TSZMmmcBAg+nmzZub16pudqRnQmgwfvrj9N/Q6tWrZfz48fLoo4/KokWLAts8a4Ciff7lL3+Rb775Rp544glz3kQunYp8+umn5a233pJly5aZ1/qwYcOi/vdHPqIbbQGx8vnnn+tGb+7s2bODrpcpU8ZNSUkx7YEHHnCXL1/upqamullZWUH3q1Onjjt58mTz9ahRo9zChQu7+/btC7qP9v9///d/gdurVq0y115//fXAtb/+9a9ucnLyecd60UUXuS+++GLgdo0aNdwbb7wxcNtxHLd8+fLuxIkTQ/45oGDp16+fm5iYGHiNa+vVq5fbrl07t3nz5kH3HTNmjNu5c+egazt37jSv4S1btpjb+rjLL7886D6tWrVyhw8fbr5euHChm5CQELj/6d544w3T39atWwPXXn75ZbdChQrW/s4oeKjBgCetWbPG/NbVp08fOX78uJkK0axCmTJlgu73yy+/BE1t1KhR44x5bNWkSZPA17lb3Wqtx6nXsrKyzJHXOv2iz6UpZp2i0TTxiRMnzHOdnsE4tV/NtGhqWrMswG/p0KGDKWLOpdmH3r17m0OmTqWv/cWLF5tpi9Ppa79+/fpnvBZVpUqVAq9Fzdzp6c259z0bnT6sU6fOWR8PXAgCDMSUrhrRD+bTpxW0BkMVLVrU/Kkf+PqGt2TJkjP6OHV53bmmWQoXLnzGlMvZrmlQozQ1rOllTRnrGHUcvXr1MkV35+o3t5/cPoDz0deqvrbOdv1U+trX6bknn3zyjPvqv4m8vBZz/x2dz9kez0kSCAcBBmJKMxKdOnWSl156SQYNGnTOAEHrLXQpqxaDanFlpOlctS4lvPbaawNv8j/88EPEnxc422tf64r0da+v/wuh2Y1du3bJt99+e94sBmATRZ6IuVdeecVMQWix5MyZM2XTpk0mo6HFaJs3bzaFaFdeeaW0bt1aevbsaYpC9cN+5cqVMnLkSFP4Zlu9evUChaKaotaiUDITiAUtgNZCZp0++eKLL8y0iK720GOz/X5/nvpo166dtG3bVv7whz+YzNz27dtNsbQWjAKRQoCBmNN5X12FoUGErupo2rSpCTZefPFFM1WhK0A0Xfvhhx+aN0l9Y9Xfwv785z/Ljz/+GNLxwXk1YcIEKVWqlFm+qulpXS6ov0kC0Va5cmWTUdNgonPnzqZ2SJex6tRgQkLe38I1C6LLrTVQSU9PN0ta8xqgABeC49oBAIB1ZDAAAIB1BBgAAMA6AgwAAGAdAQYAALCOAAMAAFhHgAEAAKwjwAAAANYRYAAFmG6Hrruj5mrfvr3ZxCna9IwZ3UxNjyY/F/3++++/n+c+9bC6Zs2ahTUu3TFWn1d3dAUQGgIMwIMf+vqhpq1IkSLmQKxHH33UbKceabo9uu6caisoAFBwcdgZ4EFdu3aVN954wxxVr1uk63kUetqlbqV+Oj3hVQMRG0qXLm2lHwAggwF4UFJSklSsWFFq1Kghd955pzmn5YMPPgia1nj88cfNORUNGjQw13fu3CnXX3+9OaNCA4UePXoEnQCr504MHTrUfF9PsdWzKE4/KeD0KRINcIYPHy7VqlUzY9Jsyuuvv2767dChg7mPntmimQwdl9JD4caNGye1atUyx4Tr2TKzZs0Keh4NmvQ8Gf2+9nMhJ9XquLSPYsWKSe3ateWhhx6SnJycM+43efJkM369n/58Dh8+HPT9KVOmSKNGjSQ5OVkaNmxoDt8DED4CDCAO6AexZipyffLJJ+bEWT0Zc+7cueaDVQ9kK1GihCxfvtwcjlW8eHGTCcl93DPPPCPTpk2TqVOnyooVK8wJne+99955n7dv377y17/+VV544QVzyq1+WGu/+oGth2cpHceePXvk+eefN7c1uHjzzTdl0qRJ8q9//UvuvfdeufHGG2Xp0qWBQOi6664zh8hpbcOtt94qDz74YMg/E/276t/nm2++Mc/92muvybPPPht0n61bt8rf/vY3mTNnjjk5VA/Vu+uuuwLff/vtt+Xhhx82wZr+/caOHWsClenTp4c8HgCn0cPOAHhHv3793B49epivHcdxFy1a5CYlJbnDhg0LfL9ChQru8ePHA49566233AYNGpj759LvFy1a1F24cKG5XalSJXf8+PGB7+fk5LhVq1YNPJdq166dO2TIEPP1li1bNL1hnv9sFi9ebL7/n//8J3AtKyvLLVasmLty5cqg+95yyy1u7969zdcjRoxw09PTg74/fPjwM/o6nX7/vffeO+f3n3rqKbdly5aB26NGjXITExPdXbt2Ba7Nnz/fTUhIcPfs2WNu16lTx50xY0ZQP2PGjHFbt25tvt6+fbt53vXr15/zeQGcHTUYgAdpVkIzBZqZ0CmHG264wayKyKVHdp9ad7Fx40bz27r+Vn+qrKws+f777820gGYZLr300sD3ChUqJJdccskZ0yS5NLuQmJgo7dq1y/O4dQzHjh2TTp06BV3XLErz5s3N15opOHUcqnXr1hKqmTNnmsyK/v2OHj1qimBTU1OD7lO9enWpUqVK0PPoz1OzLvqz0sfecsstcttttwXuo/2kpaWFPB4AwQgwAA/SuoSJEyeaIELrLDQYOFVKSkrQbf2AbdmypUn5n65cuXIXPC0TKh2HmjdvXtAHu9IaDltWrVolffr0kUceecRMDWlA8M4775hpoFDHqlMrpwc8GlgBCA8BBuBBGkBoQWVetWjRwvxGX758+TN+i89VqVIlWb16tbRt2zbwm/q6devMY89GsyT6277WTmiR6elyMyhaPJorPT3dBBI7duw4Z+ZDCypzC1Zzff755xKKlStXmgLYkSNHBq79+OOPZ9xPx7F7924TpOU+T0JCgimMrVChgrm+bds2E6wAsIsiTyAf0A/IsmXLmpUjWuS5fft2s0/F4MGDZdeuXeY+Q4YMkSeeeMJsVrV582ZT7Hi+PSxq1qwp/fr1kwEDBpjH5PapRZNKP+B19YhO5+zfv99kBHTaYdiwYaawUwsldQriyy+/lBdffDFQOHnHHXfId999J/fff7+ZqpgxY4Yp1gxFvXr1TPCgWQt9Dp0qOVvBqq4M0b+DTiHpz0V/HrqSRFfoKM2AaFGqPv7bb7+Vr776yiwPnjBhQkjjAXAmAgwgH9AlmMuWLTM1B7pCQ7MEWlugNRi5GY377rtPbrrpJvOBq7UIGgxce+215+1Xp2l69eplghFdwqm1CpmZmeZ7OgWiH9C6AkSzAQMHDjTXdaMuXYmhH9w6Dl3JolMmumxV6Rh1BYoGLbqEVVeb6OqNUHTv3t0EMfqculunZjT0OU+nWSD9eVx99dXSuXNnadKkSdAyVF3BostUNajQjI1mXTTYyR0rgAvn00rPMB4PAABwBjIYAADAOgIMAABgHQEGAACwjgADAABYR4ABAACsI8AAAADWEWAAAADrCDAAAIB1BBgAAMA6AgwAAGAdAQYAALCOAAMAAIht/x/jQjVkB+cO5wAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(type(cm))\n",
        "print(cm)\n",
        "cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['German', 'French']).plot(cmap='viridis', values_format='d')\n",
        "cm_disp\n",
        "\n",
        "colorbar = cm_disp.im_.colorbar\n",
        "colorbar.set_ticks([0, 1, 2, 3])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a64832c3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Real-World-Pipeline-IAM-Only.pkl']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(pipeline ,'Real-World-Pipeline-IAM-Only.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d74767",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
