{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b87656f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/veeranonthuvasin/Desktop/MSc-Data-Science-Bristol/Dissertation/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "960d4cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>DayOfBirth</th>\n",
       "      <th>EducationalDegree</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NativeCountry</th>\n",
       "      <th>NativeLanguage</th>\n",
       "      <th>OtherLanguage</th>\n",
       "      <th>Profession</th>\n",
       "      <th>WritingType</th>\n",
       "      <th>Science</th>\n",
       "      <th>WrittenLanguage</th>\n",
       "      <th>ascii_path</th>\n",
       "      <th>images_path</th>\n",
       "      <th>stroke_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>French</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['./Data/Bristol-Corpus/Real-World-GrayScale-P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>German</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['./Data/Bristol-Corpus/Real-World-GrayScale-P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>German</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['./Data/Bristol-Corpus/Real-World-GrayScale-P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>French</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['./Data/Bristol-Corpus/Real-World-GrayScale-P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>French</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['./Data/Bristol-Corpus/Real-World-GrayScale-P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>German</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['./Data/Bristol-Corpus/Real-World-GrayScale-P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  DayOfBirth  EducationalDegree  Gender  NativeCountry NativeLanguage  \\\n",
       "0     0         NaN                NaN     NaN            NaN         French   \n",
       "1     1         NaN                NaN     NaN            NaN         German   \n",
       "2     3         NaN                NaN     NaN            NaN         German   \n",
       "3     4         NaN                NaN     NaN            NaN         French   \n",
       "4     5         NaN                NaN     NaN            NaN         French   \n",
       "5     6         NaN                NaN     NaN            NaN         German   \n",
       "\n",
       "   OtherLanguage  Profession  WritingType  Science  WrittenLanguage  \\\n",
       "0            NaN         NaN          NaN      NaN              NaN   \n",
       "1            NaN         NaN          NaN      NaN              NaN   \n",
       "2            NaN         NaN          NaN      NaN              NaN   \n",
       "3            NaN         NaN          NaN      NaN              NaN   \n",
       "4            NaN         NaN          NaN      NaN              NaN   \n",
       "5            NaN         NaN          NaN      NaN              NaN   \n",
       "\n",
       "   ascii_path                                        images_path  stroke_path  \n",
       "0         NaN  ['./Data/Bristol-Corpus/Real-World-GrayScale-P...          NaN  \n",
       "1         NaN  ['./Data/Bristol-Corpus/Real-World-GrayScale-P...          NaN  \n",
       "2         NaN  ['./Data/Bristol-Corpus/Real-World-GrayScale-P...          NaN  \n",
       "3         NaN  ['./Data/Bristol-Corpus/Real-World-GrayScale-P...          NaN  \n",
       "4         NaN  ['./Data/Bristol-Corpus/Real-World-GrayScale-P...          NaN  \n",
       "5         NaN  ['./Data/Bristol-Corpus/Real-World-GrayScale-P...          NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_world_data = pd.read_csv('../Data/Bristol-Corpus/Real-World-GrayScale-PSM3/real_world_df.csv')\n",
    "real_world_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8f4577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NativeLanguage\n",
       "French    3\n",
       "German    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_world_data['NativeLanguage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea509b",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "- Feature Extraction Functions\n",
    "- Change writer label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b804270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(writer_name, images_path):\n",
    "  model = timm.create_model(\n",
    "      'convnextv2_nano.fcmae_ft_in22k_in1k',\n",
    "      pretrained=True,\n",
    "      num_classes=0,  # remove classifier nn.Linear\n",
    "  )\n",
    "  model = model.eval()\n",
    "\n",
    "  data_config = timm.data.resolve_model_data_config(model)\n",
    "  transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "  all_features_data = []\n",
    "  writer_id_list = []\n",
    "  writer_forms_list = []\n",
    "  for name, i in tqdm(zip(writer_name,images_path)):\n",
    "      i = ast.literal_eval(i)\n",
    "      for j in i:\n",
    "        j = j.replace('./', '../')\n",
    "        image_list = glob.glob(j)\n",
    "        for k in image_list:\n",
    "          with Image.open(k) as img:\n",
    "            img = img.convert('RGB')\n",
    "            \n",
    "            with torch.no_grad():\n",
    "              output = model(transforms(img).unsqueeze(0))\n",
    "            # print(output)\n",
    "            # features = output.pooler_output.detach().numpy()\n",
    "            # print(features)\n",
    "            # last_hidden_states = outputs.last_hidden_state\n",
    "            # print(last_hidden_states.shape)\n",
    "            # features = last_hidden_states[:, 0, :]\n",
    "            # print(features)\n",
    "            # Store the results\n",
    "            image_form = os.path.splitext(os.path.basename(k))[0]\n",
    "            writer_forms_list.append(image_form)\n",
    "            writer_id_list.append(name)\n",
    "            all_features_data.append(output.detach().flatten().tolist())\n",
    "\n",
    "              \n",
    "\n",
    "\n",
    "  writer_features_df = pd.DataFrame(data=all_features_data)\n",
    "  writer_features_df['name'] = writer_id_list\n",
    "  writer_features_df['form'] = writer_forms_list\n",
    "  return writer_features_df\n",
    "\n",
    "def convert_y(y):\n",
    "  if y == 'German':\n",
    "    return 0\n",
    "  if y == 'French': \n",
    "    return 1\n",
    "  if y == 'English':\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f7d9e2",
   "metadata": {},
   "source": [
    "# Feature Extraction Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704f4066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:18,  3.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>632</th>\n",
       "      <th>633</th>\n",
       "      <th>634</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "      <th>name</th>\n",
       "      <th>form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.900881</td>\n",
       "      <td>-1.535855</td>\n",
       "      <td>1.216326</td>\n",
       "      <td>0.263924</td>\n",
       "      <td>0.861893</td>\n",
       "      <td>0.184795</td>\n",
       "      <td>-1.468211</td>\n",
       "      <td>-0.903002</td>\n",
       "      <td>0.471242</td>\n",
       "      <td>-1.091495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058538</td>\n",
       "      <td>-1.304109</td>\n",
       "      <td>1.541442</td>\n",
       "      <td>-0.424794</td>\n",
       "      <td>-0.802706</td>\n",
       "      <td>1.041371</td>\n",
       "      <td>-0.328758</td>\n",
       "      <td>3.136823</td>\n",
       "      <td>0</td>\n",
       "      <td>page000_line003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.134265</td>\n",
       "      <td>-1.362282</td>\n",
       "      <td>2.273987</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>-0.652768</td>\n",
       "      <td>-0.222237</td>\n",
       "      <td>-0.832183</td>\n",
       "      <td>-1.145109</td>\n",
       "      <td>0.296855</td>\n",
       "      <td>-2.368747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157107</td>\n",
       "      <td>-1.092878</td>\n",
       "      <td>1.892547</td>\n",
       "      <td>-0.487107</td>\n",
       "      <td>0.093969</td>\n",
       "      <td>2.060857</td>\n",
       "      <td>-1.213497</td>\n",
       "      <td>2.975895</td>\n",
       "      <td>0</td>\n",
       "      <td>page000_line002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.593472</td>\n",
       "      <td>-0.976235</td>\n",
       "      <td>0.744769</td>\n",
       "      <td>0.308163</td>\n",
       "      <td>-0.685127</td>\n",
       "      <td>-0.755348</td>\n",
       "      <td>-2.012943</td>\n",
       "      <td>0.673236</td>\n",
       "      <td>-0.896982</td>\n",
       "      <td>-1.988740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.753516</td>\n",
       "      <td>-0.608883</td>\n",
       "      <td>1.339883</td>\n",
       "      <td>0.432048</td>\n",
       "      <td>0.636367</td>\n",
       "      <td>1.714106</td>\n",
       "      <td>0.504608</td>\n",
       "      <td>1.266553</td>\n",
       "      <td>0</td>\n",
       "      <td>page000_line000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.280957</td>\n",
       "      <td>-1.285501</td>\n",
       "      <td>1.829224</td>\n",
       "      <td>0.499230</td>\n",
       "      <td>-0.052572</td>\n",
       "      <td>0.709289</td>\n",
       "      <td>-1.074080</td>\n",
       "      <td>-1.166486</td>\n",
       "      <td>0.981797</td>\n",
       "      <td>-1.591591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361287</td>\n",
       "      <td>-0.495855</td>\n",
       "      <td>1.635529</td>\n",
       "      <td>-0.772384</td>\n",
       "      <td>1.012281</td>\n",
       "      <td>2.350589</td>\n",
       "      <td>-0.735705</td>\n",
       "      <td>2.450419</td>\n",
       "      <td>0</td>\n",
       "      <td>page000_line001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.312774</td>\n",
       "      <td>-0.413435</td>\n",
       "      <td>2.063291</td>\n",
       "      <td>0.887190</td>\n",
       "      <td>0.801703</td>\n",
       "      <td>-0.023718</td>\n",
       "      <td>-2.104139</td>\n",
       "      <td>0.721972</td>\n",
       "      <td>0.649561</td>\n",
       "      <td>-2.637098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.471062</td>\n",
       "      <td>0.093955</td>\n",
       "      <td>0.671852</td>\n",
       "      <td>0.130571</td>\n",
       "      <td>-0.747895</td>\n",
       "      <td>2.493425</td>\n",
       "      <td>-1.339399</td>\n",
       "      <td>1.875247</td>\n",
       "      <td>0</td>\n",
       "      <td>page000_line005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.088423</td>\n",
       "      <td>-0.558079</td>\n",
       "      <td>2.144183</td>\n",
       "      <td>0.348551</td>\n",
       "      <td>-0.823501</td>\n",
       "      <td>-0.331861</td>\n",
       "      <td>-1.095646</td>\n",
       "      <td>0.077632</td>\n",
       "      <td>0.161654</td>\n",
       "      <td>-2.837906</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.645933</td>\n",
       "      <td>-0.706350</td>\n",
       "      <td>0.919395</td>\n",
       "      <td>1.023801</td>\n",
       "      <td>-0.501715</td>\n",
       "      <td>1.016948</td>\n",
       "      <td>-1.168648</td>\n",
       "      <td>1.912641</td>\n",
       "      <td>0</td>\n",
       "      <td>page000_line004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.352457</td>\n",
       "      <td>-1.241885</td>\n",
       "      <td>1.946865</td>\n",
       "      <td>0.645203</td>\n",
       "      <td>-0.915543</td>\n",
       "      <td>-0.268871</td>\n",
       "      <td>-1.386410</td>\n",
       "      <td>-0.908995</td>\n",
       "      <td>0.262660</td>\n",
       "      <td>-2.861198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164378</td>\n",
       "      <td>0.277399</td>\n",
       "      <td>2.058115</td>\n",
       "      <td>0.161064</td>\n",
       "      <td>0.208770</td>\n",
       "      <td>3.003321</td>\n",
       "      <td>-1.318584</td>\n",
       "      <td>2.281312</td>\n",
       "      <td>0</td>\n",
       "      <td>page000_line006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.507467</td>\n",
       "      <td>-1.915475</td>\n",
       "      <td>2.334567</td>\n",
       "      <td>0.967679</td>\n",
       "      <td>0.755115</td>\n",
       "      <td>0.768464</td>\n",
       "      <td>-1.766531</td>\n",
       "      <td>-0.953910</td>\n",
       "      <td>0.261470</td>\n",
       "      <td>-2.457000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438582</td>\n",
       "      <td>-0.710739</td>\n",
       "      <td>1.944403</td>\n",
       "      <td>-0.137118</td>\n",
       "      <td>-0.349195</td>\n",
       "      <td>2.496340</td>\n",
       "      <td>-0.891258</td>\n",
       "      <td>2.711566</td>\n",
       "      <td>0</td>\n",
       "      <td>page000_line007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.369867</td>\n",
       "      <td>-1.144850</td>\n",
       "      <td>2.374497</td>\n",
       "      <td>1.486444</td>\n",
       "      <td>0.057034</td>\n",
       "      <td>0.659323</td>\n",
       "      <td>-0.906150</td>\n",
       "      <td>-0.305979</td>\n",
       "      <td>-0.087208</td>\n",
       "      <td>-2.945641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621893</td>\n",
       "      <td>-1.044549</td>\n",
       "      <td>1.939120</td>\n",
       "      <td>0.076557</td>\n",
       "      <td>0.389761</td>\n",
       "      <td>1.469566</td>\n",
       "      <td>-0.691275</td>\n",
       "      <td>1.780019</td>\n",
       "      <td>0</td>\n",
       "      <td>page000_line008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.611749</td>\n",
       "      <td>-2.095418</td>\n",
       "      <td>0.496747</td>\n",
       "      <td>1.899151</td>\n",
       "      <td>-0.842998</td>\n",
       "      <td>0.447551</td>\n",
       "      <td>-1.261050</td>\n",
       "      <td>-2.167131</td>\n",
       "      <td>1.413064</td>\n",
       "      <td>-2.242526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244677</td>\n",
       "      <td>-0.928682</td>\n",
       "      <td>1.154003</td>\n",
       "      <td>-0.196702</td>\n",
       "      <td>-1.030584</td>\n",
       "      <td>1.451702</td>\n",
       "      <td>-0.573324</td>\n",
       "      <td>0.096913</td>\n",
       "      <td>1</td>\n",
       "      <td>page000_line003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-2.290432</td>\n",
       "      <td>-1.823981</td>\n",
       "      <td>-0.245025</td>\n",
       "      <td>1.480978</td>\n",
       "      <td>-0.356717</td>\n",
       "      <td>0.568426</td>\n",
       "      <td>-0.646507</td>\n",
       "      <td>-2.733148</td>\n",
       "      <td>2.006800</td>\n",
       "      <td>-2.515923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518083</td>\n",
       "      <td>0.408829</td>\n",
       "      <td>0.237417</td>\n",
       "      <td>0.417480</td>\n",
       "      <td>0.410241</td>\n",
       "      <td>1.516244</td>\n",
       "      <td>-0.792029</td>\n",
       "      <td>-1.057558</td>\n",
       "      <td>1</td>\n",
       "      <td>page000_line002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.207571</td>\n",
       "      <td>-1.161908</td>\n",
       "      <td>-0.629806</td>\n",
       "      <td>1.927256</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.012873</td>\n",
       "      <td>-0.593543</td>\n",
       "      <td>-1.862664</td>\n",
       "      <td>1.482231</td>\n",
       "      <td>-1.305336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328434</td>\n",
       "      <td>-0.731346</td>\n",
       "      <td>0.970486</td>\n",
       "      <td>1.150844</td>\n",
       "      <td>-0.227760</td>\n",
       "      <td>0.252524</td>\n",
       "      <td>0.596436</td>\n",
       "      <td>-0.253897</td>\n",
       "      <td>1</td>\n",
       "      <td>page000_line000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.589233</td>\n",
       "      <td>-1.054851</td>\n",
       "      <td>-0.275232</td>\n",
       "      <td>2.352102</td>\n",
       "      <td>-1.657410</td>\n",
       "      <td>0.068928</td>\n",
       "      <td>-0.326524</td>\n",
       "      <td>-2.286921</td>\n",
       "      <td>1.303765</td>\n",
       "      <td>-1.600224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040765</td>\n",
       "      <td>-0.186851</td>\n",
       "      <td>1.600801</td>\n",
       "      <td>-1.122975</td>\n",
       "      <td>-0.408834</td>\n",
       "      <td>3.436998</td>\n",
       "      <td>-1.169829</td>\n",
       "      <td>0.025704</td>\n",
       "      <td>1</td>\n",
       "      <td>page000_line001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.566000</td>\n",
       "      <td>-1.090448</td>\n",
       "      <td>0.432487</td>\n",
       "      <td>1.193386</td>\n",
       "      <td>-0.284967</td>\n",
       "      <td>0.979698</td>\n",
       "      <td>-1.883320</td>\n",
       "      <td>-2.088283</td>\n",
       "      <td>1.133648</td>\n",
       "      <td>-1.532070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282095</td>\n",
       "      <td>-0.349165</td>\n",
       "      <td>0.040628</td>\n",
       "      <td>0.709523</td>\n",
       "      <td>-0.784128</td>\n",
       "      <td>1.829252</td>\n",
       "      <td>-1.324068</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>1</td>\n",
       "      <td>page000_line005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.757621</td>\n",
       "      <td>-0.894421</td>\n",
       "      <td>0.013984</td>\n",
       "      <td>2.179670</td>\n",
       "      <td>-1.608992</td>\n",
       "      <td>0.379539</td>\n",
       "      <td>-1.496733</td>\n",
       "      <td>-1.766940</td>\n",
       "      <td>1.191479</td>\n",
       "      <td>-2.852113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270399</td>\n",
       "      <td>-1.446855</td>\n",
       "      <td>0.904377</td>\n",
       "      <td>0.191518</td>\n",
       "      <td>-1.545192</td>\n",
       "      <td>2.216811</td>\n",
       "      <td>-1.141569</td>\n",
       "      <td>-1.106837</td>\n",
       "      <td>1</td>\n",
       "      <td>page000_line004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.511285</td>\n",
       "      <td>-0.159393</td>\n",
       "      <td>-1.285892</td>\n",
       "      <td>0.883206</td>\n",
       "      <td>-0.240112</td>\n",
       "      <td>-0.082843</td>\n",
       "      <td>-1.698460</td>\n",
       "      <td>-0.617277</td>\n",
       "      <td>0.631346</td>\n",
       "      <td>-0.851741</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.025800</td>\n",
       "      <td>-0.099167</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>1.420944</td>\n",
       "      <td>-0.220729</td>\n",
       "      <td>1.039717</td>\n",
       "      <td>-0.968723</td>\n",
       "      <td>1.182505</td>\n",
       "      <td>3</td>\n",
       "      <td>page000_line003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.915069</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>-1.253779</td>\n",
       "      <td>1.961727</td>\n",
       "      <td>-0.480075</td>\n",
       "      <td>0.358586</td>\n",
       "      <td>-1.083527</td>\n",
       "      <td>-0.397470</td>\n",
       "      <td>0.726015</td>\n",
       "      <td>-0.928387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101263</td>\n",
       "      <td>1.035422</td>\n",
       "      <td>1.443239</td>\n",
       "      <td>1.378848</td>\n",
       "      <td>0.203002</td>\n",
       "      <td>2.551162</td>\n",
       "      <td>-1.204188</td>\n",
       "      <td>1.095948</td>\n",
       "      <td>3</td>\n",
       "      <td>page000_line002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.399246</td>\n",
       "      <td>-0.449594</td>\n",
       "      <td>-0.050102</td>\n",
       "      <td>0.851918</td>\n",
       "      <td>-0.061686</td>\n",
       "      <td>0.489559</td>\n",
       "      <td>-1.947546</td>\n",
       "      <td>-0.186119</td>\n",
       "      <td>0.788533</td>\n",
       "      <td>-0.059928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674960</td>\n",
       "      <td>-0.008328</td>\n",
       "      <td>1.219678</td>\n",
       "      <td>0.704170</td>\n",
       "      <td>0.378878</td>\n",
       "      <td>1.588672</td>\n",
       "      <td>-0.762329</td>\n",
       "      <td>1.949395</td>\n",
       "      <td>3</td>\n",
       "      <td>page000_line001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.400874</td>\n",
       "      <td>-0.573764</td>\n",
       "      <td>0.262399</td>\n",
       "      <td>1.218095</td>\n",
       "      <td>-1.354946</td>\n",
       "      <td>-0.158789</td>\n",
       "      <td>-1.226880</td>\n",
       "      <td>-1.198591</td>\n",
       "      <td>1.332944</td>\n",
       "      <td>-0.620245</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.091506</td>\n",
       "      <td>-0.495805</td>\n",
       "      <td>1.265438</td>\n",
       "      <td>-0.169847</td>\n",
       "      <td>1.055912</td>\n",
       "      <td>0.814413</td>\n",
       "      <td>-0.812493</td>\n",
       "      <td>1.728397</td>\n",
       "      <td>3</td>\n",
       "      <td>page000_line011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.533533</td>\n",
       "      <td>-0.670471</td>\n",
       "      <td>0.355615</td>\n",
       "      <td>0.896869</td>\n",
       "      <td>-0.754374</td>\n",
       "      <td>-0.275247</td>\n",
       "      <td>-0.353749</td>\n",
       "      <td>-0.542393</td>\n",
       "      <td>1.092196</td>\n",
       "      <td>-0.064769</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.027692</td>\n",
       "      <td>0.260945</td>\n",
       "      <td>0.967058</td>\n",
       "      <td>0.834612</td>\n",
       "      <td>0.744693</td>\n",
       "      <td>1.368777</td>\n",
       "      <td>-0.804311</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>3</td>\n",
       "      <td>page000_line004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.068758</td>\n",
       "      <td>0.346009</td>\n",
       "      <td>-0.542015</td>\n",
       "      <td>1.277306</td>\n",
       "      <td>-0.596175</td>\n",
       "      <td>-0.407558</td>\n",
       "      <td>-0.964712</td>\n",
       "      <td>-0.631917</td>\n",
       "      <td>0.919562</td>\n",
       "      <td>-0.919415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815364</td>\n",
       "      <td>1.021727</td>\n",
       "      <td>0.367840</td>\n",
       "      <td>1.065763</td>\n",
       "      <td>0.284883</td>\n",
       "      <td>1.136353</td>\n",
       "      <td>-0.157914</td>\n",
       "      <td>0.340986</td>\n",
       "      <td>3</td>\n",
       "      <td>page000_line010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.444731</td>\n",
       "      <td>0.605384</td>\n",
       "      <td>-0.279393</td>\n",
       "      <td>0.143534</td>\n",
       "      <td>0.397796</td>\n",
       "      <td>1.124081</td>\n",
       "      <td>-2.198709</td>\n",
       "      <td>-1.187628</td>\n",
       "      <td>-0.474654</td>\n",
       "      <td>-0.966479</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.146562</td>\n",
       "      <td>0.336720</td>\n",
       "      <td>0.784339</td>\n",
       "      <td>1.202369</td>\n",
       "      <td>-0.798215</td>\n",
       "      <td>1.212639</td>\n",
       "      <td>0.039807</td>\n",
       "      <td>0.586837</td>\n",
       "      <td>3</td>\n",
       "      <td>page000_line006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.397368</td>\n",
       "      <td>-0.024730</td>\n",
       "      <td>0.542317</td>\n",
       "      <td>0.416974</td>\n",
       "      <td>-0.672300</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>-1.310768</td>\n",
       "      <td>-1.528256</td>\n",
       "      <td>1.811763</td>\n",
       "      <td>-0.126442</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.013625</td>\n",
       "      <td>-0.614783</td>\n",
       "      <td>1.282822</td>\n",
       "      <td>0.886146</td>\n",
       "      <td>0.687368</td>\n",
       "      <td>-0.209796</td>\n",
       "      <td>-0.947312</td>\n",
       "      <td>1.506792</td>\n",
       "      <td>3</td>\n",
       "      <td>page000_line012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.548182</td>\n",
       "      <td>-0.110832</td>\n",
       "      <td>-0.298195</td>\n",
       "      <td>1.482604</td>\n",
       "      <td>0.476659</td>\n",
       "      <td>0.750116</td>\n",
       "      <td>-1.455401</td>\n",
       "      <td>-0.521254</td>\n",
       "      <td>-0.555038</td>\n",
       "      <td>-1.956491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474841</td>\n",
       "      <td>1.053458</td>\n",
       "      <td>1.735331</td>\n",
       "      <td>0.864692</td>\n",
       "      <td>-1.156795</td>\n",
       "      <td>1.644365</td>\n",
       "      <td>-0.368903</td>\n",
       "      <td>1.727635</td>\n",
       "      <td>3</td>\n",
       "      <td>page000_line007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.899175</td>\n",
       "      <td>-0.069753</td>\n",
       "      <td>0.300784</td>\n",
       "      <td>1.329214</td>\n",
       "      <td>0.137482</td>\n",
       "      <td>0.115308</td>\n",
       "      <td>-1.185902</td>\n",
       "      <td>0.520195</td>\n",
       "      <td>0.858706</td>\n",
       "      <td>-0.186683</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164044</td>\n",
       "      <td>0.219707</td>\n",
       "      <td>0.772808</td>\n",
       "      <td>0.317163</td>\n",
       "      <td>0.655635</td>\n",
       "      <td>0.852677</td>\n",
       "      <td>-0.745911</td>\n",
       "      <td>2.183578</td>\n",
       "      <td>3</td>\n",
       "      <td>page000_line009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.284822</td>\n",
       "      <td>0.144479</td>\n",
       "      <td>1.242482</td>\n",
       "      <td>0.102223</td>\n",
       "      <td>0.683352</td>\n",
       "      <td>-0.399493</td>\n",
       "      <td>-2.077096</td>\n",
       "      <td>-0.811740</td>\n",
       "      <td>-0.200744</td>\n",
       "      <td>0.034794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042854</td>\n",
       "      <td>-0.243000</td>\n",
       "      <td>0.752491</td>\n",
       "      <td>0.674273</td>\n",
       "      <td>-1.771868</td>\n",
       "      <td>1.580923</td>\n",
       "      <td>-1.103293</td>\n",
       "      <td>0.902760</td>\n",
       "      <td>4</td>\n",
       "      <td>page000_line017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.417261</td>\n",
       "      <td>-0.195526</td>\n",
       "      <td>1.855916</td>\n",
       "      <td>-0.288126</td>\n",
       "      <td>-0.700317</td>\n",
       "      <td>0.378725</td>\n",
       "      <td>-1.840963</td>\n",
       "      <td>0.380007</td>\n",
       "      <td>0.541137</td>\n",
       "      <td>-1.394863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626281</td>\n",
       "      <td>-0.301799</td>\n",
       "      <td>1.171829</td>\n",
       "      <td>1.421664</td>\n",
       "      <td>-1.447193</td>\n",
       "      <td>1.612703</td>\n",
       "      <td>-0.498627</td>\n",
       "      <td>1.497717</td>\n",
       "      <td>4</td>\n",
       "      <td>page000_line002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.821136</td>\n",
       "      <td>-0.514354</td>\n",
       "      <td>1.380523</td>\n",
       "      <td>1.737670</td>\n",
       "      <td>0.180128</td>\n",
       "      <td>-0.046532</td>\n",
       "      <td>-1.691870</td>\n",
       "      <td>-1.303176</td>\n",
       "      <td>1.069632</td>\n",
       "      <td>-0.133193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.534704</td>\n",
       "      <td>-0.607059</td>\n",
       "      <td>1.583575</td>\n",
       "      <td>0.309247</td>\n",
       "      <td>-0.134333</td>\n",
       "      <td>1.478819</td>\n",
       "      <td>-0.539329</td>\n",
       "      <td>2.961042</td>\n",
       "      <td>4</td>\n",
       "      <td>page000_line000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.760303</td>\n",
       "      <td>0.895791</td>\n",
       "      <td>1.491342</td>\n",
       "      <td>1.343078</td>\n",
       "      <td>-1.067421</td>\n",
       "      <td>-0.851370</td>\n",
       "      <td>-2.226929</td>\n",
       "      <td>-0.464046</td>\n",
       "      <td>0.225262</td>\n",
       "      <td>-1.644391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097913</td>\n",
       "      <td>-0.260226</td>\n",
       "      <td>0.071615</td>\n",
       "      <td>0.132198</td>\n",
       "      <td>-0.743547</td>\n",
       "      <td>2.387686</td>\n",
       "      <td>-2.363768</td>\n",
       "      <td>0.895487</td>\n",
       "      <td>4</td>\n",
       "      <td>page000_line015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.041007</td>\n",
       "      <td>1.633261</td>\n",
       "      <td>1.741746</td>\n",
       "      <td>0.625358</td>\n",
       "      <td>-2.341788</td>\n",
       "      <td>0.233289</td>\n",
       "      <td>-0.732800</td>\n",
       "      <td>0.654997</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>-2.387836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.583906</td>\n",
       "      <td>-1.380787</td>\n",
       "      <td>0.505839</td>\n",
       "      <td>1.876584</td>\n",
       "      <td>-1.684255</td>\n",
       "      <td>1.480990</td>\n",
       "      <td>-0.773467</td>\n",
       "      <td>0.373090</td>\n",
       "      <td>4</td>\n",
       "      <td>page000_line010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-1.236749</td>\n",
       "      <td>0.548504</td>\n",
       "      <td>1.412555</td>\n",
       "      <td>1.065041</td>\n",
       "      <td>-1.589259</td>\n",
       "      <td>1.144025</td>\n",
       "      <td>-1.113644</td>\n",
       "      <td>0.296600</td>\n",
       "      <td>0.547062</td>\n",
       "      <td>-1.320060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442539</td>\n",
       "      <td>-0.172453</td>\n",
       "      <td>0.856218</td>\n",
       "      <td>1.816082</td>\n",
       "      <td>-0.560511</td>\n",
       "      <td>2.593247</td>\n",
       "      <td>-0.520242</td>\n",
       "      <td>0.937336</td>\n",
       "      <td>4</td>\n",
       "      <td>page000_line007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.675129</td>\n",
       "      <td>-0.100372</td>\n",
       "      <td>0.126636</td>\n",
       "      <td>1.903031</td>\n",
       "      <td>-0.932906</td>\n",
       "      <td>-0.029992</td>\n",
       "      <td>-1.508575</td>\n",
       "      <td>-0.105283</td>\n",
       "      <td>0.430275</td>\n",
       "      <td>0.556498</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.010932</td>\n",
       "      <td>-0.733464</td>\n",
       "      <td>1.022323</td>\n",
       "      <td>0.607367</td>\n",
       "      <td>0.387326</td>\n",
       "      <td>-0.199046</td>\n",
       "      <td>-0.843895</td>\n",
       "      <td>1.147886</td>\n",
       "      <td>4</td>\n",
       "      <td>page000_line018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.822720</td>\n",
       "      <td>0.914817</td>\n",
       "      <td>1.206195</td>\n",
       "      <td>-0.679650</td>\n",
       "      <td>-0.894523</td>\n",
       "      <td>0.185949</td>\n",
       "      <td>-1.684727</td>\n",
       "      <td>0.270091</td>\n",
       "      <td>0.664255</td>\n",
       "      <td>-1.572916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.540149</td>\n",
       "      <td>0.325710</td>\n",
       "      <td>0.972612</td>\n",
       "      <td>0.808860</td>\n",
       "      <td>-1.446238</td>\n",
       "      <td>2.323844</td>\n",
       "      <td>-1.479796</td>\n",
       "      <td>1.605714</td>\n",
       "      <td>4</td>\n",
       "      <td>page000_line019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.458307</td>\n",
       "      <td>-0.958887</td>\n",
       "      <td>0.033891</td>\n",
       "      <td>0.733709</td>\n",
       "      <td>-1.697282</td>\n",
       "      <td>0.062691</td>\n",
       "      <td>-0.451608</td>\n",
       "      <td>-0.958972</td>\n",
       "      <td>0.942517</td>\n",
       "      <td>-0.618566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.634955</td>\n",
       "      <td>0.610513</td>\n",
       "      <td>1.195423</td>\n",
       "      <td>-0.118988</td>\n",
       "      <td>0.832401</td>\n",
       "      <td>1.701328</td>\n",
       "      <td>-0.965071</td>\n",
       "      <td>0.606653</td>\n",
       "      <td>5</td>\n",
       "      <td>page000_line003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.445179</td>\n",
       "      <td>0.306864</td>\n",
       "      <td>0.132252</td>\n",
       "      <td>0.909049</td>\n",
       "      <td>0.891211</td>\n",
       "      <td>1.804006</td>\n",
       "      <td>-0.754798</td>\n",
       "      <td>-1.965100</td>\n",
       "      <td>0.157875</td>\n",
       "      <td>-0.436323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.707230</td>\n",
       "      <td>1.010410</td>\n",
       "      <td>0.389437</td>\n",
       "      <td>0.302703</td>\n",
       "      <td>0.415911</td>\n",
       "      <td>2.397123</td>\n",
       "      <td>0.484518</td>\n",
       "      <td>0.141263</td>\n",
       "      <td>5</td>\n",
       "      <td>page000_line002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.252033</td>\n",
       "      <td>-0.476010</td>\n",
       "      <td>0.220876</td>\n",
       "      <td>0.839237</td>\n",
       "      <td>-1.177432</td>\n",
       "      <td>0.260475</td>\n",
       "      <td>-0.280225</td>\n",
       "      <td>-0.906387</td>\n",
       "      <td>0.332400</td>\n",
       "      <td>-1.462990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287458</td>\n",
       "      <td>1.036865</td>\n",
       "      <td>1.163799</td>\n",
       "      <td>-0.082156</td>\n",
       "      <td>-0.498177</td>\n",
       "      <td>2.336817</td>\n",
       "      <td>-0.725767</td>\n",
       "      <td>0.363254</td>\n",
       "      <td>5</td>\n",
       "      <td>page000_line000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.677300</td>\n",
       "      <td>-1.044457</td>\n",
       "      <td>-0.132667</td>\n",
       "      <td>0.260955</td>\n",
       "      <td>-1.494067</td>\n",
       "      <td>-0.060972</td>\n",
       "      <td>-0.560856</td>\n",
       "      <td>-0.633262</td>\n",
       "      <td>0.928054</td>\n",
       "      <td>-0.655661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.441678</td>\n",
       "      <td>0.718351</td>\n",
       "      <td>1.001258</td>\n",
       "      <td>0.492759</td>\n",
       "      <td>0.786731</td>\n",
       "      <td>1.663528</td>\n",
       "      <td>-0.647642</td>\n",
       "      <td>0.667600</td>\n",
       "      <td>5</td>\n",
       "      <td>page000_line001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.309948</td>\n",
       "      <td>-0.487609</td>\n",
       "      <td>-0.666604</td>\n",
       "      <td>-0.209792</td>\n",
       "      <td>-0.239032</td>\n",
       "      <td>0.296499</td>\n",
       "      <td>-0.499096</td>\n",
       "      <td>-1.200930</td>\n",
       "      <td>0.313259</td>\n",
       "      <td>-0.516922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722910</td>\n",
       "      <td>0.663737</td>\n",
       "      <td>0.804323</td>\n",
       "      <td>0.604769</td>\n",
       "      <td>-0.081573</td>\n",
       "      <td>2.726238</td>\n",
       "      <td>-0.843379</td>\n",
       "      <td>-0.493157</td>\n",
       "      <td>5</td>\n",
       "      <td>page000_line005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-1.014642</td>\n",
       "      <td>-0.620240</td>\n",
       "      <td>-0.015325</td>\n",
       "      <td>-0.020156</td>\n",
       "      <td>-0.255930</td>\n",
       "      <td>0.195686</td>\n",
       "      <td>-0.450148</td>\n",
       "      <td>0.205388</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>-0.246765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685066</td>\n",
       "      <td>0.696252</td>\n",
       "      <td>1.672011</td>\n",
       "      <td>-0.140407</td>\n",
       "      <td>-0.659373</td>\n",
       "      <td>1.700073</td>\n",
       "      <td>-0.392945</td>\n",
       "      <td>0.668212</td>\n",
       "      <td>5</td>\n",
       "      <td>page000_line004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.016063</td>\n",
       "      <td>-0.432868</td>\n",
       "      <td>0.193906</td>\n",
       "      <td>0.723087</td>\n",
       "      <td>-1.509290</td>\n",
       "      <td>0.137060</td>\n",
       "      <td>-0.258605</td>\n",
       "      <td>-0.686176</td>\n",
       "      <td>0.678195</td>\n",
       "      <td>-0.838486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.594982</td>\n",
       "      <td>0.161270</td>\n",
       "      <td>1.042325</td>\n",
       "      <td>0.256729</td>\n",
       "      <td>0.359362</td>\n",
       "      <td>1.790579</td>\n",
       "      <td>-1.126071</td>\n",
       "      <td>0.215241</td>\n",
       "      <td>5</td>\n",
       "      <td>page000_line006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.930825</td>\n",
       "      <td>-0.975236</td>\n",
       "      <td>0.020694</td>\n",
       "      <td>-0.367364</td>\n",
       "      <td>-1.166840</td>\n",
       "      <td>0.080084</td>\n",
       "      <td>-0.683109</td>\n",
       "      <td>-0.879427</td>\n",
       "      <td>0.645276</td>\n",
       "      <td>-0.609716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.961264</td>\n",
       "      <td>0.433916</td>\n",
       "      <td>1.019151</td>\n",
       "      <td>0.424877</td>\n",
       "      <td>0.402371</td>\n",
       "      <td>0.975544</td>\n",
       "      <td>-0.754261</td>\n",
       "      <td>0.599763</td>\n",
       "      <td>5</td>\n",
       "      <td>page000_line007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.381054</td>\n",
       "      <td>0.377363</td>\n",
       "      <td>-0.349268</td>\n",
       "      <td>1.053214</td>\n",
       "      <td>-0.778858</td>\n",
       "      <td>0.223258</td>\n",
       "      <td>0.133051</td>\n",
       "      <td>-0.763046</td>\n",
       "      <td>0.515453</td>\n",
       "      <td>-1.888904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.357223</td>\n",
       "      <td>0.837642</td>\n",
       "      <td>1.390144</td>\n",
       "      <td>0.551295</td>\n",
       "      <td>-0.113882</td>\n",
       "      <td>2.524674</td>\n",
       "      <td>-0.827479</td>\n",
       "      <td>0.618074</td>\n",
       "      <td>5</td>\n",
       "      <td>page000_line009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.482022</td>\n",
       "      <td>-0.530190</td>\n",
       "      <td>0.555034</td>\n",
       "      <td>0.061592</td>\n",
       "      <td>-1.501323</td>\n",
       "      <td>0.552592</td>\n",
       "      <td>-0.453617</td>\n",
       "      <td>-0.881997</td>\n",
       "      <td>1.265358</td>\n",
       "      <td>-0.469314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.759997</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>1.045778</td>\n",
       "      <td>0.133436</td>\n",
       "      <td>0.532937</td>\n",
       "      <td>1.433050</td>\n",
       "      <td>-0.866951</td>\n",
       "      <td>0.660781</td>\n",
       "      <td>5</td>\n",
       "      <td>page000_line008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.425163</td>\n",
       "      <td>-0.889256</td>\n",
       "      <td>0.680910</td>\n",
       "      <td>1.174501</td>\n",
       "      <td>-0.299338</td>\n",
       "      <td>1.439548</td>\n",
       "      <td>-1.017437</td>\n",
       "      <td>-2.315849</td>\n",
       "      <td>1.217635</td>\n",
       "      <td>-2.012322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.548484</td>\n",
       "      <td>-0.967192</td>\n",
       "      <td>0.089741</td>\n",
       "      <td>0.390196</td>\n",
       "      <td>-0.447207</td>\n",
       "      <td>1.349188</td>\n",
       "      <td>-0.345251</td>\n",
       "      <td>-0.153885</td>\n",
       "      <td>6</td>\n",
       "      <td>page000_line003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.371337</td>\n",
       "      <td>-1.743062</td>\n",
       "      <td>0.156865</td>\n",
       "      <td>1.695572</td>\n",
       "      <td>-0.686044</td>\n",
       "      <td>0.506810</td>\n",
       "      <td>-1.419559</td>\n",
       "      <td>-2.573834</td>\n",
       "      <td>2.023610</td>\n",
       "      <td>-1.558440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066427</td>\n",
       "      <td>-1.449065</td>\n",
       "      <td>1.377814</td>\n",
       "      <td>0.322283</td>\n",
       "      <td>-1.037573</td>\n",
       "      <td>1.489391</td>\n",
       "      <td>-0.015439</td>\n",
       "      <td>0.281922</td>\n",
       "      <td>6</td>\n",
       "      <td>page000_line002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-1.375505</td>\n",
       "      <td>-1.034224</td>\n",
       "      <td>0.728940</td>\n",
       "      <td>1.947940</td>\n",
       "      <td>-1.999517</td>\n",
       "      <td>0.405978</td>\n",
       "      <td>-1.565957</td>\n",
       "      <td>-2.758316</td>\n",
       "      <td>1.679069</td>\n",
       "      <td>-2.602715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782819</td>\n",
       "      <td>-1.618669</td>\n",
       "      <td>1.490047</td>\n",
       "      <td>-0.033443</td>\n",
       "      <td>-1.110051</td>\n",
       "      <td>2.042918</td>\n",
       "      <td>-1.068701</td>\n",
       "      <td>0.377701</td>\n",
       "      <td>6</td>\n",
       "      <td>page000_line000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-1.546735</td>\n",
       "      <td>-0.665076</td>\n",
       "      <td>0.014008</td>\n",
       "      <td>2.013012</td>\n",
       "      <td>-0.570232</td>\n",
       "      <td>0.899402</td>\n",
       "      <td>-0.864737</td>\n",
       "      <td>-2.181496</td>\n",
       "      <td>1.139154</td>\n",
       "      <td>-2.252067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292332</td>\n",
       "      <td>-0.215581</td>\n",
       "      <td>0.287592</td>\n",
       "      <td>0.188674</td>\n",
       "      <td>-0.013113</td>\n",
       "      <td>2.173856</td>\n",
       "      <td>-0.742428</td>\n",
       "      <td>-0.962788</td>\n",
       "      <td>6</td>\n",
       "      <td>page000_line001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.900881 -1.535855  1.216326  0.263924  0.861893  0.184795 -1.468211   \n",
       "1   1.134265 -1.362282  2.273987  0.284600 -0.652768 -0.222237 -0.832183   \n",
       "2   0.593472 -0.976235  0.744769  0.308163 -0.685127 -0.755348 -2.012943   \n",
       "3   1.280957 -1.285501  1.829224  0.499230 -0.052572  0.709289 -1.074080   \n",
       "4   1.312774 -0.413435  2.063291  0.887190  0.801703 -0.023718 -2.104139   \n",
       "5  -0.088423 -0.558079  2.144183  0.348551 -0.823501 -0.331861 -1.095646   \n",
       "6   1.352457 -1.241885  1.946865  0.645203 -0.915543 -0.268871 -1.386410   \n",
       "7   1.507467 -1.915475  2.334567  0.967679  0.755115  0.768464 -1.766531   \n",
       "8   1.369867 -1.144850  2.374497  1.486444  0.057034  0.659323 -0.906150   \n",
       "9  -0.611749 -2.095418  0.496747  1.899151 -0.842998  0.447551 -1.261050   \n",
       "10 -2.290432 -1.823981 -0.245025  1.480978 -0.356717  0.568426 -0.646507   \n",
       "11  0.207571 -1.161908 -0.629806  1.927256  0.069100  0.012873 -0.593543   \n",
       "12 -1.589233 -1.054851 -0.275232  2.352102 -1.657410  0.068928 -0.326524   \n",
       "13 -0.566000 -1.090448  0.432487  1.193386 -0.284967  0.979698 -1.883320   \n",
       "14 -0.757621 -0.894421  0.013984  2.179670 -1.608992  0.379539 -1.496733   \n",
       "15 -1.511285 -0.159393 -1.285892  0.883206 -0.240112 -0.082843 -1.698460   \n",
       "16 -0.915069  0.126906 -1.253779  1.961727 -0.480075  0.358586 -1.083527   \n",
       "17 -1.399246 -0.449594 -0.050102  0.851918 -0.061686  0.489559 -1.947546   \n",
       "18 -0.400874 -0.573764  0.262399  1.218095 -1.354946 -0.158789 -1.226880   \n",
       "19 -0.533533 -0.670471  0.355615  0.896869 -0.754374 -0.275247 -0.353749   \n",
       "20  0.068758  0.346009 -0.542015  1.277306 -0.596175 -0.407558 -0.964712   \n",
       "21 -0.444731  0.605384 -0.279393  0.143534  0.397796  1.124081 -2.198709   \n",
       "22 -0.397368 -0.024730  0.542317  0.416974 -0.672300 -0.102507 -1.310768   \n",
       "23  0.548182 -0.110832 -0.298195  1.482604  0.476659  0.750116 -1.455401   \n",
       "24 -0.899175 -0.069753  0.300784  1.329214  0.137482  0.115308 -1.185902   \n",
       "25  0.284822  0.144479  1.242482  0.102223  0.683352 -0.399493 -2.077096   \n",
       "26 -1.417261 -0.195526  1.855916 -0.288126 -0.700317  0.378725 -1.840963   \n",
       "27  0.821136 -0.514354  1.380523  1.737670  0.180128 -0.046532 -1.691870   \n",
       "28  0.760303  0.895791  1.491342  1.343078 -1.067421 -0.851370 -2.226929   \n",
       "29 -0.041007  1.633261  1.741746  0.625358 -2.341788  0.233289 -0.732800   \n",
       "30 -1.236749  0.548504  1.412555  1.065041 -1.589259  1.144025 -1.113644   \n",
       "31 -0.675129 -0.100372  0.126636  1.903031 -0.932906 -0.029992 -1.508575   \n",
       "32  0.822720  0.914817  1.206195 -0.679650 -0.894523  0.185949 -1.684727   \n",
       "33 -0.458307 -0.958887  0.033891  0.733709 -1.697282  0.062691 -0.451608   \n",
       "34 -0.445179  0.306864  0.132252  0.909049  0.891211  1.804006 -0.754798   \n",
       "35 -0.252033 -0.476010  0.220876  0.839237 -1.177432  0.260475 -0.280225   \n",
       "36 -0.677300 -1.044457 -0.132667  0.260955 -1.494067 -0.060972 -0.560856   \n",
       "37 -0.309948 -0.487609 -0.666604 -0.209792 -0.239032  0.296499 -0.499096   \n",
       "38 -1.014642 -0.620240 -0.015325 -0.020156 -0.255930  0.195686 -0.450148   \n",
       "39  0.016063 -0.432868  0.193906  0.723087 -1.509290  0.137060 -0.258605   \n",
       "40 -0.930825 -0.975236  0.020694 -0.367364 -1.166840  0.080084 -0.683109   \n",
       "41 -0.381054  0.377363 -0.349268  1.053214 -0.778858  0.223258  0.133051   \n",
       "42 -0.482022 -0.530190  0.555034  0.061592 -1.501323  0.552592 -0.453617   \n",
       "43 -0.425163 -0.889256  0.680910  1.174501 -0.299338  1.439548 -1.017437   \n",
       "44 -0.371337 -1.743062  0.156865  1.695572 -0.686044  0.506810 -1.419559   \n",
       "45 -1.375505 -1.034224  0.728940  1.947940 -1.999517  0.405978 -1.565957   \n",
       "46 -1.546735 -0.665076  0.014008  2.013012 -0.570232  0.899402 -0.864737   \n",
       "\n",
       "           7         8         9  ...       632       633       634       635  \\\n",
       "0  -0.903002  0.471242 -1.091495  ...  0.058538 -1.304109  1.541442 -0.424794   \n",
       "1  -1.145109  0.296855 -2.368747  ...  0.157107 -1.092878  1.892547 -0.487107   \n",
       "2   0.673236 -0.896982 -1.988740  ... -0.753516 -0.608883  1.339883  0.432048   \n",
       "3  -1.166486  0.981797 -1.591591  ...  0.361287 -0.495855  1.635529 -0.772384   \n",
       "4   0.721972  0.649561 -2.637098  ... -0.471062  0.093955  0.671852  0.130571   \n",
       "5   0.077632  0.161654 -2.837906  ... -0.645933 -0.706350  0.919395  1.023801   \n",
       "6  -0.908995  0.262660 -2.861198  ...  0.164378  0.277399  2.058115  0.161064   \n",
       "7  -0.953910  0.261470 -2.457000  ...  0.438582 -0.710739  1.944403 -0.137118   \n",
       "8  -0.305979 -0.087208 -2.945641  ...  0.621893 -1.044549  1.939120  0.076557   \n",
       "9  -2.167131  1.413064 -2.242526  ...  0.244677 -0.928682  1.154003 -0.196702   \n",
       "10 -2.733148  2.006800 -2.515923  ...  0.518083  0.408829  0.237417  0.417480   \n",
       "11 -1.862664  1.482231 -1.305336  ... -0.328434 -0.731346  0.970486  1.150844   \n",
       "12 -2.286921  1.303765 -1.600224  ...  0.040765 -0.186851  1.600801 -1.122975   \n",
       "13 -2.088283  1.133648 -1.532070  ... -0.282095 -0.349165  0.040628  0.709523   \n",
       "14 -1.766940  1.191479 -2.852113  ...  0.270399 -1.446855  0.904377  0.191518   \n",
       "15 -0.617277  0.631346 -0.851741  ... -1.025800 -0.099167  0.538432  1.420944   \n",
       "16 -0.397470  0.726015 -0.928387  ... -0.101263  1.035422  1.443239  1.378848   \n",
       "17 -0.186119  0.788533 -0.059928  ... -0.674960 -0.008328  1.219678  0.704170   \n",
       "18 -1.198591  1.332944 -0.620245  ... -1.091506 -0.495805  1.265438 -0.169847   \n",
       "19 -0.542393  1.092196 -0.064769  ... -1.027692  0.260945  0.967058  0.834612   \n",
       "20 -0.631917  0.919562 -0.919415  ... -0.815364  1.021727  0.367840  1.065763   \n",
       "21 -1.187628 -0.474654 -0.966479  ... -1.146562  0.336720  0.784339  1.202369   \n",
       "22 -1.528256  1.811763 -0.126442  ... -1.013625 -0.614783  1.282822  0.886146   \n",
       "23 -0.521254 -0.555038 -1.956491  ... -0.474841  1.053458  1.735331  0.864692   \n",
       "24  0.520195  0.858706 -0.186683  ... -1.164044  0.219707  0.772808  0.317163   \n",
       "25 -0.811740 -0.200744  0.034794  ...  0.042854 -0.243000  0.752491  0.674273   \n",
       "26  0.380007  0.541137 -1.394863  ... -0.626281 -0.301799  1.171829  1.421664   \n",
       "27 -1.303176  1.069632 -0.133193  ... -0.534704 -0.607059  1.583575  0.309247   \n",
       "28 -0.464046  0.225262 -1.644391  ... -0.097913 -0.260226  0.071615  0.132198   \n",
       "29  0.654997  0.318321 -2.387836  ... -0.583906 -1.380787  0.505839  1.876584   \n",
       "30  0.296600  0.547062 -1.320060  ... -0.442539 -0.172453  0.856218  1.816082   \n",
       "31 -0.105283  0.430275  0.556498  ... -1.010932 -0.733464  1.022323  0.607367   \n",
       "32  0.270091  0.664255 -1.572916  ... -0.540149  0.325710  0.972612  0.808860   \n",
       "33 -0.958972  0.942517 -0.618566  ... -0.634955  0.610513  1.195423 -0.118988   \n",
       "34 -1.965100  0.157875 -0.436323  ... -0.707230  1.010410  0.389437  0.302703   \n",
       "35 -0.906387  0.332400 -1.462990  ... -0.287458  1.036865  1.163799 -0.082156   \n",
       "36 -0.633262  0.928054 -0.655661  ... -0.441678  0.718351  1.001258  0.492759   \n",
       "37 -1.200930  0.313259 -0.516922  ...  0.722910  0.663737  0.804323  0.604769   \n",
       "38  0.205388  0.008288 -0.246765  ...  0.685066  0.696252  1.672011 -0.140407   \n",
       "39 -0.686176  0.678195 -0.838486  ... -0.594982  0.161270  1.042325  0.256729   \n",
       "40 -0.879427  0.645276 -0.609716  ... -0.961264  0.433916  1.019151  0.424877   \n",
       "41 -0.763046  0.515453 -1.888904  ... -0.357223  0.837642  1.390144  0.551295   \n",
       "42 -0.881997  1.265358 -0.469314  ... -0.759997 -0.130000  1.045778  0.133436   \n",
       "43 -2.315849  1.217635 -2.012322  ... -0.548484 -0.967192  0.089741  0.390196   \n",
       "44 -2.573834  2.023610 -1.558440  ... -0.066427 -1.449065  1.377814  0.322283   \n",
       "45 -2.758316  1.679069 -2.602715  ...  0.782819 -1.618669  1.490047 -0.033443   \n",
       "46 -2.181496  1.139154 -2.252067  ... -0.292332 -0.215581  0.287592  0.188674   \n",
       "\n",
       "         636       637       638       639  name             form  \n",
       "0  -0.802706  1.041371 -0.328758  3.136823     0  page000_line003  \n",
       "1   0.093969  2.060857 -1.213497  2.975895     0  page000_line002  \n",
       "2   0.636367  1.714106  0.504608  1.266553     0  page000_line000  \n",
       "3   1.012281  2.350589 -0.735705  2.450419     0  page000_line001  \n",
       "4  -0.747895  2.493425 -1.339399  1.875247     0  page000_line005  \n",
       "5  -0.501715  1.016948 -1.168648  1.912641     0  page000_line004  \n",
       "6   0.208770  3.003321 -1.318584  2.281312     0  page000_line006  \n",
       "7  -0.349195  2.496340 -0.891258  2.711566     0  page000_line007  \n",
       "8   0.389761  1.469566 -0.691275  1.780019     0  page000_line008  \n",
       "9  -1.030584  1.451702 -0.573324  0.096913     1  page000_line003  \n",
       "10  0.410241  1.516244 -0.792029 -1.057558     1  page000_line002  \n",
       "11 -0.227760  0.252524  0.596436 -0.253897     1  page000_line000  \n",
       "12 -0.408834  3.436998 -1.169829  0.025704     1  page000_line001  \n",
       "13 -0.784128  1.829252 -1.324068  0.003215     1  page000_line005  \n",
       "14 -1.545192  2.216811 -1.141569 -1.106837     1  page000_line004  \n",
       "15 -0.220729  1.039717 -0.968723  1.182505     3  page000_line003  \n",
       "16  0.203002  2.551162 -1.204188  1.095948     3  page000_line002  \n",
       "17  0.378878  1.588672 -0.762329  1.949395     3  page000_line001  \n",
       "18  1.055912  0.814413 -0.812493  1.728397     3  page000_line011  \n",
       "19  0.744693  1.368777 -0.804311  0.008971     3  page000_line004  \n",
       "20  0.284883  1.136353 -0.157914  0.340986     3  page000_line010  \n",
       "21 -0.798215  1.212639  0.039807  0.586837     3  page000_line006  \n",
       "22  0.687368 -0.209796 -0.947312  1.506792     3  page000_line012  \n",
       "23 -1.156795  1.644365 -0.368903  1.727635     3  page000_line007  \n",
       "24  0.655635  0.852677 -0.745911  2.183578     3  page000_line009  \n",
       "25 -1.771868  1.580923 -1.103293  0.902760     4  page000_line017  \n",
       "26 -1.447193  1.612703 -0.498627  1.497717     4  page000_line002  \n",
       "27 -0.134333  1.478819 -0.539329  2.961042     4  page000_line000  \n",
       "28 -0.743547  2.387686 -2.363768  0.895487     4  page000_line015  \n",
       "29 -1.684255  1.480990 -0.773467  0.373090     4  page000_line010  \n",
       "30 -0.560511  2.593247 -0.520242  0.937336     4  page000_line007  \n",
       "31  0.387326 -0.199046 -0.843895  1.147886     4  page000_line018  \n",
       "32 -1.446238  2.323844 -1.479796  1.605714     4  page000_line019  \n",
       "33  0.832401  1.701328 -0.965071  0.606653     5  page000_line003  \n",
       "34  0.415911  2.397123  0.484518  0.141263     5  page000_line002  \n",
       "35 -0.498177  2.336817 -0.725767  0.363254     5  page000_line000  \n",
       "36  0.786731  1.663528 -0.647642  0.667600     5  page000_line001  \n",
       "37 -0.081573  2.726238 -0.843379 -0.493157     5  page000_line005  \n",
       "38 -0.659373  1.700073 -0.392945  0.668212     5  page000_line004  \n",
       "39  0.359362  1.790579 -1.126071  0.215241     5  page000_line006  \n",
       "40  0.402371  0.975544 -0.754261  0.599763     5  page000_line007  \n",
       "41 -0.113882  2.524674 -0.827479  0.618074     5  page000_line009  \n",
       "42  0.532937  1.433050 -0.866951  0.660781     5  page000_line008  \n",
       "43 -0.447207  1.349188 -0.345251 -0.153885     6  page000_line003  \n",
       "44 -1.037573  1.489391 -0.015439  0.281922     6  page000_line002  \n",
       "45 -1.110051  2.042918 -1.068701  0.377701     6  page000_line000  \n",
       "46 -0.013113  2.173856 -0.742428 -0.962788     6  page000_line001  \n",
       "\n",
       "[47 rows x 642 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = feature_extraction(real_world_data['name'], real_world_data['images_path'])\n",
    "all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d640991",
   "metadata": {},
   "source": [
    "# Feature Extraction for Training Set (class-wise fixed images_per_subwrite sizes and bootstrapping, but dynamic sub_profile_per_writer)\n",
    "- 4 Sentence-Level Images per Sub-writer Profile for English, creating 3 Sub-writer Profiles.\n",
    "- 4 Sentence-Level Images per Sub-writer Profile for German/French, creating 12 Sub-writer Profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec8a8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_writers_bootstrap(train_df, feature_store, images_per_subwriter=4, fold_seed=42):\n",
    "  \n",
    "    writer_names_in_fold = train_df['name'].unique()\n",
    "    feature_df = feature_store[feature_store['name'].isin(writer_names_in_fold)]\n",
    "\n",
    "    feature_columns = [col for col in feature_df.columns if col not in ['name', 'form']]\n",
    "    aggregated_data = []\n",
    "    \n",
    "    unique_writers = feature_df['name'].unique()\n",
    "    \n",
    "    for writer_id in unique_writers:\n",
    "        writer_df = feature_df[feature_df['name'] == writer_id]\n",
    "        num_images = len(writer_df)\n",
    "        \n",
    "        if num_images == 0:\n",
    "            continue\n",
    "\n",
    "\n",
    "        try:\n",
    "            language = train_df.loc[train_df['name'] == writer_id, 'NativeLanguage'].iloc[0]\n",
    "        except IndexError:\n",
    "            print(f\"Warning: Could not find language for writer_id {writer_id}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        if language == 'English':\n",
    "            current_num_profiles_per_writer = 3  # Create fewer profiles for the low-data class\n",
    "        else:  # For German and French\n",
    "            current_num_profiles_per_writer = 12 # Create more profiles for the high-data classes\n",
    "\n",
    "\n",
    "        if num_images <= images_per_subwriter:\n",
    "            feature_chunk = writer_df[feature_columns]\n",
    "            mean_features = feature_chunk.mean(axis=0)\n",
    "            median_features = feature_chunk.median(axis=0)\n",
    "            std_features = feature_chunk.std(axis=0).fillna(0)\n",
    "            skew_features = feature_chunk.skew(axis=0).fillna(0)\n",
    "            \n",
    "            new_row = {}\n",
    "            for col in feature_columns:\n",
    "                new_row[f'{col}|mean'] = mean_features[col]\n",
    "                new_row[f'{col}|median'] = median_features[col]\n",
    "                new_row[f'{col}|std'] = std_features[col]\n",
    "                new_row[f'{col}|skew'] = skew_features[col]\n",
    "                \n",
    "            new_row['original_writer_id'] = writer_id\n",
    "            new_row['sub_writer_id'] = f\"{writer_id}-agg-0\"\n",
    "            aggregated_data.append(new_row)\n",
    "            continue\n",
    "\n",
    "        writer_profiles = []\n",
    "        max_attempts = current_num_profiles_per_writer * 5\n",
    "        \n",
    "        for i in range(max_attempts):\n",
    "            sample_chunk = writer_df.sample(\n",
    "                n=images_per_subwriter, \n",
    "                replace=True, \n",
    "                random_state=fold_seed + hash(writer_id) % 100000 + i\n",
    "            )\n",
    "            feature_chunk = sample_chunk[feature_columns]\n",
    "            \n",
    "            mean_features = feature_chunk.mean(axis=0)\n",
    "            median_features = feature_chunk.median(axis=0)\n",
    "            std_features = feature_chunk.std(axis=0).fillna(0)\n",
    "            skew_features = feature_chunk.skew(axis=0).fillna(0)\n",
    "            \n",
    "            profile_dict = {}\n",
    "            for col in feature_columns:\n",
    "                profile_dict[f'{col}|mean'] = mean_features[col]\n",
    "                profile_dict[f'{col}|median'] = median_features[col]\n",
    "                profile_dict[f'{col}|std'] = std_features[col]\n",
    "                profile_dict[f'{col}|skew'] = skew_features[col]\n",
    "                \n",
    "            writer_profiles.append(profile_dict)\n",
    "            \n",
    "            temp_df = pd.DataFrame(writer_profiles).drop_duplicates()\n",
    "            if len(temp_df) >= current_num_profiles_per_writer:\n",
    "                break\n",
    "        \n",
    "        if writer_profiles:\n",
    "            profiles_df = pd.DataFrame(writer_profiles)\n",
    "            unique_profiles_df = profiles_df.drop_duplicates().reset_index(drop=True)\n",
    "            final_profiles_df = unique_profiles_df.head(current_num_profiles_per_writer)\n",
    "\n",
    "            for i, row in final_profiles_df.iterrows():\n",
    "                profile_data = row.to_dict()\n",
    "                profile_data['original_writer_id'] = writer_id\n",
    "                profile_data['sub_writer_id'] = f\"{writer_id}-boot-{i}\"\n",
    "                aggregated_data.append(profile_data)\n",
    "            \n",
    "    final_df = pd.DataFrame(aggregated_data)\n",
    "    \n",
    "    if final_df.empty:\n",
    "        return pd.DataFrame(), pd.Series(dtype='int')\n",
    "\n",
    "    new_feature_columns = []\n",
    "    for col in feature_columns:\n",
    "        new_feature_columns.append(f'{col}|mean')\n",
    "        new_feature_columns.append(f'{col}|median')\n",
    "        new_feature_columns.append(f'{col}|std')\n",
    "        new_feature_columns.append(f'{col}|skew')\n",
    "\n",
    "    cols = ['sub_writer_id', 'original_writer_id'] + new_feature_columns\n",
    "    final_df = final_df[cols]\n",
    "    display(final_df)\n",
    "    \n",
    "    final_df = pd.merge(final_df, train_df[['name', 'NativeLanguage']], how='inner', left_on='original_writer_id', right_on='name')\n",
    "    X_train = final_df.drop(columns=['sub_writer_id', 'original_writer_id','name','NativeLanguage'])\n",
    "    y_train = final_df['NativeLanguage']\n",
    "    y_train = np.vectorize(convert_y)(y_train)\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14fe3c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>632</th>\n",
       "      <th>633</th>\n",
       "      <th>634</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "      <th>name</th>\n",
       "      <th>form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.372276</td>\n",
       "      <td>0.224989</td>\n",
       "      <td>-0.467460</td>\n",
       "      <td>1.820759</td>\n",
       "      <td>-0.586967</td>\n",
       "      <td>1.776678</td>\n",
       "      <td>-3.153311</td>\n",
       "      <td>-2.495186</td>\n",
       "      <td>0.968704</td>\n",
       "      <td>-1.006844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.981443</td>\n",
       "      <td>-0.273160</td>\n",
       "      <td>1.014988</td>\n",
       "      <td>1.218125</td>\n",
       "      <td>-0.981978</td>\n",
       "      <td>3.083691</td>\n",
       "      <td>-1.024849</td>\n",
       "      <td>2.180169</td>\n",
       "      <td>10000</td>\n",
       "      <td>z01-000-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.033635</td>\n",
       "      <td>-0.905358</td>\n",
       "      <td>0.258783</td>\n",
       "      <td>1.923517</td>\n",
       "      <td>-0.866238</td>\n",
       "      <td>0.205671</td>\n",
       "      <td>-1.162825</td>\n",
       "      <td>-0.941368</td>\n",
       "      <td>1.491512</td>\n",
       "      <td>-0.259629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438199</td>\n",
       "      <td>-1.047727</td>\n",
       "      <td>1.526454</td>\n",
       "      <td>-0.711613</td>\n",
       "      <td>-0.884340</td>\n",
       "      <td>0.576500</td>\n",
       "      <td>-1.261368</td>\n",
       "      <td>1.769279</td>\n",
       "      <td>10000</td>\n",
       "      <td>z01-000-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025888</td>\n",
       "      <td>-0.592650</td>\n",
       "      <td>0.585571</td>\n",
       "      <td>2.040271</td>\n",
       "      <td>-0.155405</td>\n",
       "      <td>-0.120354</td>\n",
       "      <td>-1.829877</td>\n",
       "      <td>-1.252309</td>\n",
       "      <td>1.205214</td>\n",
       "      <td>-0.259600</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.126850</td>\n",
       "      <td>-1.122187</td>\n",
       "      <td>0.977126</td>\n",
       "      <td>0.345049</td>\n",
       "      <td>-0.814934</td>\n",
       "      <td>0.962746</td>\n",
       "      <td>-0.548778</td>\n",
       "      <td>2.673030</td>\n",
       "      <td>10000</td>\n",
       "      <td>z01-000-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.510987</td>\n",
       "      <td>-0.666809</td>\n",
       "      <td>-1.368710</td>\n",
       "      <td>1.987004</td>\n",
       "      <td>-0.221620</td>\n",
       "      <td>0.672618</td>\n",
       "      <td>-3.057467</td>\n",
       "      <td>-1.380301</td>\n",
       "      <td>1.458408</td>\n",
       "      <td>-1.007992</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.292161</td>\n",
       "      <td>-1.257141</td>\n",
       "      <td>-0.041370</td>\n",
       "      <td>1.655186</td>\n",
       "      <td>-0.791135</td>\n",
       "      <td>2.099786</td>\n",
       "      <td>-1.133589</td>\n",
       "      <td>1.716038</td>\n",
       "      <td>10000</td>\n",
       "      <td>z01-000-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.917990</td>\n",
       "      <td>-0.359039</td>\n",
       "      <td>0.085779</td>\n",
       "      <td>1.985653</td>\n",
       "      <td>-1.203340</td>\n",
       "      <td>0.940839</td>\n",
       "      <td>-2.236159</td>\n",
       "      <td>-2.180054</td>\n",
       "      <td>1.759380</td>\n",
       "      <td>-1.052856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.828048</td>\n",
       "      <td>-1.400792</td>\n",
       "      <td>1.134104</td>\n",
       "      <td>0.957654</td>\n",
       "      <td>-0.926594</td>\n",
       "      <td>2.193790</td>\n",
       "      <td>-1.190055</td>\n",
       "      <td>2.018496</td>\n",
       "      <td>10000</td>\n",
       "      <td>z01-000-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>-0.166905</td>\n",
       "      <td>-1.087335</td>\n",
       "      <td>0.436946</td>\n",
       "      <td>0.041008</td>\n",
       "      <td>-1.445201</td>\n",
       "      <td>0.030634</td>\n",
       "      <td>-0.942336</td>\n",
       "      <td>-1.672251</td>\n",
       "      <td>2.018108</td>\n",
       "      <td>0.040737</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.728344</td>\n",
       "      <td>-0.209595</td>\n",
       "      <td>1.440409</td>\n",
       "      <td>0.387701</td>\n",
       "      <td>0.704579</td>\n",
       "      <td>0.775189</td>\n",
       "      <td>-1.445656</td>\n",
       "      <td>1.703038</td>\n",
       "      <td>25</td>\n",
       "      <td>page000_line001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>-1.020958</td>\n",
       "      <td>-0.973095</td>\n",
       "      <td>-0.202618</td>\n",
       "      <td>0.460286</td>\n",
       "      <td>-0.908080</td>\n",
       "      <td>0.431273</td>\n",
       "      <td>-1.310988</td>\n",
       "      <td>-2.186874</td>\n",
       "      <td>1.921045</td>\n",
       "      <td>-1.022282</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.463473</td>\n",
       "      <td>-0.259575</td>\n",
       "      <td>0.989406</td>\n",
       "      <td>0.643102</td>\n",
       "      <td>0.046823</td>\n",
       "      <td>0.620898</td>\n",
       "      <td>-0.797454</td>\n",
       "      <td>2.097991</td>\n",
       "      <td>25</td>\n",
       "      <td>page000_line005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>0.187808</td>\n",
       "      <td>-0.616186</td>\n",
       "      <td>0.712529</td>\n",
       "      <td>1.516693</td>\n",
       "      <td>-1.776467</td>\n",
       "      <td>1.043272</td>\n",
       "      <td>-0.366190</td>\n",
       "      <td>-1.701217</td>\n",
       "      <td>1.274346</td>\n",
       "      <td>-1.977084</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142874</td>\n",
       "      <td>1.226076</td>\n",
       "      <td>0.536600</td>\n",
       "      <td>0.963856</td>\n",
       "      <td>0.226091</td>\n",
       "      <td>1.882359</td>\n",
       "      <td>-2.185912</td>\n",
       "      <td>1.138407</td>\n",
       "      <td>25</td>\n",
       "      <td>page000_line006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>-0.546677</td>\n",
       "      <td>-1.329427</td>\n",
       "      <td>-0.422880</td>\n",
       "      <td>1.233715</td>\n",
       "      <td>-1.006450</td>\n",
       "      <td>0.287910</td>\n",
       "      <td>-1.033419</td>\n",
       "      <td>-2.418210</td>\n",
       "      <td>1.775813</td>\n",
       "      <td>-1.206054</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.083004</td>\n",
       "      <td>-0.112003</td>\n",
       "      <td>0.532118</td>\n",
       "      <td>0.783740</td>\n",
       "      <td>0.341568</td>\n",
       "      <td>0.286427</td>\n",
       "      <td>-0.865030</td>\n",
       "      <td>1.536021</td>\n",
       "      <td>25</td>\n",
       "      <td>page000_line009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>-1.812275</td>\n",
       "      <td>-0.585898</td>\n",
       "      <td>0.796219</td>\n",
       "      <td>1.554841</td>\n",
       "      <td>-0.928513</td>\n",
       "      <td>0.570940</td>\n",
       "      <td>-1.218171</td>\n",
       "      <td>-2.051419</td>\n",
       "      <td>1.197945</td>\n",
       "      <td>-1.020835</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.561254</td>\n",
       "      <td>0.868786</td>\n",
       "      <td>-0.505556</td>\n",
       "      <td>1.034004</td>\n",
       "      <td>0.054721</td>\n",
       "      <td>0.630044</td>\n",
       "      <td>-1.163606</td>\n",
       "      <td>-0.114015</td>\n",
       "      <td>25</td>\n",
       "      <td>page000_line008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2841 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.372276  0.224989 -0.467460  1.820759 -0.586967  1.776678 -3.153311   \n",
       "1    -0.033635 -0.905358  0.258783  1.923517 -0.866238  0.205671 -1.162825   \n",
       "2     0.025888 -0.592650  0.585571  2.040271 -0.155405 -0.120354 -1.829877   \n",
       "3    -1.510987 -0.666809 -1.368710  1.987004 -0.221620  0.672618 -3.057467   \n",
       "4    -0.917990 -0.359039  0.085779  1.985653 -1.203340  0.940839 -2.236159   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2836 -0.166905 -1.087335  0.436946  0.041008 -1.445201  0.030634 -0.942336   \n",
       "2837 -1.020958 -0.973095 -0.202618  0.460286 -0.908080  0.431273 -1.310988   \n",
       "2838  0.187808 -0.616186  0.712529  1.516693 -1.776467  1.043272 -0.366190   \n",
       "2839 -0.546677 -1.329427 -0.422880  1.233715 -1.006450  0.287910 -1.033419   \n",
       "2840 -1.812275 -0.585898  0.796219  1.554841 -0.928513  0.570940 -1.218171   \n",
       "\n",
       "             7         8         9  ...       632       633       634  \\\n",
       "0    -2.495186  0.968704 -1.006844  ... -0.981443 -0.273160  1.014988   \n",
       "1    -0.941368  1.491512 -0.259629  ... -0.438199 -1.047727  1.526454   \n",
       "2    -1.252309  1.205214 -0.259600  ... -1.126850 -1.122187  0.977126   \n",
       "3    -1.380301  1.458408 -1.007992  ... -1.292161 -1.257141 -0.041370   \n",
       "4    -2.180054  1.759380 -1.052856  ... -0.828048 -1.400792  1.134104   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2836 -1.672251  2.018108  0.040737  ... -1.728344 -0.209595  1.440409   \n",
       "2837 -2.186874  1.921045 -1.022282  ... -1.463473 -0.259575  0.989406   \n",
       "2838 -1.701217  1.274346 -1.977084  ... -0.142874  1.226076  0.536600   \n",
       "2839 -2.418210  1.775813 -1.206054  ... -1.083004 -0.112003  0.532118   \n",
       "2840 -2.051419  1.197945 -1.020835  ... -2.561254  0.868786 -0.505556   \n",
       "\n",
       "           635       636       637       638       639   name             form  \n",
       "0     1.218125 -0.981978  3.083691 -1.024849  2.180169  10000       z01-000-03  \n",
       "1    -0.711613 -0.884340  0.576500 -1.261368  1.769279  10000       z01-000-02  \n",
       "2     0.345049 -0.814934  0.962746 -0.548778  2.673030  10000       z01-000-01  \n",
       "3     1.655186 -0.791135  2.099786 -1.133589  1.716038  10000       z01-000-05  \n",
       "4     0.957654 -0.926594  2.193790 -1.190055  2.018496  10000       z01-000-04  \n",
       "...        ...       ...       ...       ...       ...    ...              ...  \n",
       "2836  0.387701  0.704579  0.775189 -1.445656  1.703038     25  page000_line001  \n",
       "2837  0.643102  0.046823  0.620898 -0.797454  2.097991     25  page000_line005  \n",
       "2838  0.963856  0.226091  1.882359 -2.185912  1.138407     25  page000_line006  \n",
       "2839  0.783740  0.341568  0.286427 -0.865030  1.536021     25  page000_line009  \n",
       "2840  1.034004  0.054721  0.630044 -1.163606 -0.114015     25  page000_line008  \n",
       "\n",
       "[2841 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_store = pd.read_csv('./Final-Data/All-Writers-Feature-Vectors-GrayScale.csv', index_col=[0])\n",
    "display(feature_store)\n",
    "writers_info = pd.read_csv('./Final-Data/new-writers-info.csv')\n",
    "english_writer_info = pd.read_csv('../Data/Bristol-Corpus/English-GrayScale/english_df.csv')\n",
    "writers_info = pd.concat([writers_info, english_writer_info], axis=0, ignore_index=True)\n",
    "writers_info = writers_info.loc[(writers_info['NativeLanguage'] != 'Swiss German')]\n",
    "all_writers_info = feature_store[['name']].drop_duplicates().reset_index(drop=True)\n",
    "all_writers_info = pd.merge(all_writers_info, writers_info[['name', 'NativeLanguage']], how='inner', on='name')\n",
    "all_labels = all_writers_info['NativeLanguage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d6368a",
   "metadata": {},
   "source": [
    "## X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d95d4177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_writer_level_profile(test_df, feature_store):\n",
    "\n",
    "  writer_names_in_fold = test_df['name'].unique()\n",
    "  print(writer_names_in_fold)\n",
    "  test_features_df = feature_store[feature_store['name'].isin(writer_names_in_fold)]\n",
    "  \n",
    "  writer_level_feature_df = test_features_df.groupby(['name'], as_index=False)[test_features_df.columns[:-2]].agg(['mean', 'median', 'std', 'skew']).fillna(0)\n",
    "  writer_level_feature_df.columns = writer_level_feature_df.columns.map(lambda x: '|'.join(map(str, x)))\n",
    "  \n",
    "  final_test_df = pd.merge(writer_level_feature_df, test_df[['name', 'NativeLanguage']], how='inner', left_on='name|', right_on='name')\n",
    "  \n",
    "  X_test = final_test_df.drop(columns=['name','name|','NativeLanguage'])\n",
    "  y_test = final_test_df['NativeLanguage']\n",
    "  y_test = np.vectorize(convert_y)(y_test)\n",
    "  \n",
    "  return X_test, y_test\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f7d27",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf6fbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_writer_id</th>\n",
       "      <th>original_writer_id</th>\n",
       "      <th>0|mean</th>\n",
       "      <th>0|median</th>\n",
       "      <th>0|std</th>\n",
       "      <th>0|skew</th>\n",
       "      <th>1|mean</th>\n",
       "      <th>1|median</th>\n",
       "      <th>1|std</th>\n",
       "      <th>1|skew</th>\n",
       "      <th>...</th>\n",
       "      <th>637|std</th>\n",
       "      <th>637|skew</th>\n",
       "      <th>638|mean</th>\n",
       "      <th>638|median</th>\n",
       "      <th>638|std</th>\n",
       "      <th>638|skew</th>\n",
       "      <th>639|mean</th>\n",
       "      <th>639|median</th>\n",
       "      <th>639|std</th>\n",
       "      <th>639|skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000-boot-0</td>\n",
       "      <td>10000</td>\n",
       "      <td>-1.267652</td>\n",
       "      <td>-1.268100</td>\n",
       "      <td>0.415971</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>-0.720088</td>\n",
       "      <td>-0.715909</td>\n",
       "      <td>0.304577</td>\n",
       "      <td>-0.079466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571644</td>\n",
       "      <td>0.665995</td>\n",
       "      <td>-0.984765</td>\n",
       "      <td>-1.105879</td>\n",
       "      <td>0.482978</td>\n",
       "      <td>1.371838</td>\n",
       "      <td>2.088727</td>\n",
       "      <td>1.771725</td>\n",
       "      <td>0.717917</td>\n",
       "      <td>1.939357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000-boot-1</td>\n",
       "      <td>10000</td>\n",
       "      <td>-0.096789</td>\n",
       "      <td>-0.033635</td>\n",
       "      <td>0.126309</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.000710</td>\n",
       "      <td>-0.905358</td>\n",
       "      <td>0.190704</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045445</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.136550</td>\n",
       "      <td>-1.261368</td>\n",
       "      <td>0.249637</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.853013</td>\n",
       "      <td>1.769279</td>\n",
       "      <td>0.167468</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000-boot-2</td>\n",
       "      <td>10000</td>\n",
       "      <td>-1.080543</td>\n",
       "      <td>-1.316513</td>\n",
       "      <td>0.827803</td>\n",
       "      <td>0.996498</td>\n",
       "      <td>-0.784924</td>\n",
       "      <td>-0.843327</td>\n",
       "      <td>0.369418</td>\n",
       "      <td>0.334582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709097</td>\n",
       "      <td>1.841362</td>\n",
       "      <td>-1.149286</td>\n",
       "      <td>-1.309606</td>\n",
       "      <td>0.415903</td>\n",
       "      <td>1.599816</td>\n",
       "      <td>2.752915</td>\n",
       "      <td>2.916548</td>\n",
       "      <td>0.540770</td>\n",
       "      <td>-1.103018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000-boot-3</td>\n",
       "      <td>10000</td>\n",
       "      <td>-1.363532</td>\n",
       "      <td>-1.356938</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>-0.140316</td>\n",
       "      <td>-0.020133</td>\n",
       "      <td>0.062116</td>\n",
       "      <td>1.058608</td>\n",
       "      <td>-0.082969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>-0.523828</td>\n",
       "      <td>-1.178393</td>\n",
       "      <td>-1.103123</td>\n",
       "      <td>0.167589</td>\n",
       "      <td>-1.970004</td>\n",
       "      <td>1.825675</td>\n",
       "      <td>1.492511</td>\n",
       "      <td>0.943967</td>\n",
       "      <td>1.410531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000-boot-4</td>\n",
       "      <td>10000</td>\n",
       "      <td>-0.650433</td>\n",
       "      <td>-0.645133</td>\n",
       "      <td>0.375076</td>\n",
       "      <td>-0.024936</td>\n",
       "      <td>-0.546456</td>\n",
       "      <td>-0.562023</td>\n",
       "      <td>0.639290</td>\n",
       "      <td>0.126352</td>\n",
       "      <td>...</td>\n",
       "      <td>1.055851</td>\n",
       "      <td>0.284084</td>\n",
       "      <td>-1.013792</td>\n",
       "      <td>-1.051509</td>\n",
       "      <td>0.181371</td>\n",
       "      <td>1.139840</td>\n",
       "      <td>2.032573</td>\n",
       "      <td>2.061356</td>\n",
       "      <td>0.151884</td>\n",
       "      <td>-0.961866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>22-boot-1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.644612</td>\n",
       "      <td>0.619500</td>\n",
       "      <td>0.758466</td>\n",
       "      <td>0.015167</td>\n",
       "      <td>-1.920069</td>\n",
       "      <td>-2.102232</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>1.586929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410881</td>\n",
       "      <td>-1.675974</td>\n",
       "      <td>-0.887732</td>\n",
       "      <td>-0.987716</td>\n",
       "      <td>0.505605</td>\n",
       "      <td>0.512837</td>\n",
       "      <td>-0.423427</td>\n",
       "      <td>-0.777453</td>\n",
       "      <td>0.844441</td>\n",
       "      <td>1.775209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>22-boot-2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.257158</td>\n",
       "      <td>-0.055582</td>\n",
       "      <td>0.734057</td>\n",
       "      <td>1.918920</td>\n",
       "      <td>-0.621170</td>\n",
       "      <td>-0.918728</td>\n",
       "      <td>0.997249</td>\n",
       "      <td>1.338300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883145</td>\n",
       "      <td>-1.152537</td>\n",
       "      <td>-0.625930</td>\n",
       "      <td>-0.338597</td>\n",
       "      <td>0.930939</td>\n",
       "      <td>-1.604537</td>\n",
       "      <td>-0.643648</td>\n",
       "      <td>-0.737771</td>\n",
       "      <td>1.140437</td>\n",
       "      <td>0.458236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>25-boot-0</td>\n",
       "      <td>25</td>\n",
       "      <td>-1.114425</td>\n",
       "      <td>-1.416616</td>\n",
       "      <td>0.944905</td>\n",
       "      <td>1.208600</td>\n",
       "      <td>-0.690269</td>\n",
       "      <td>-0.601042</td>\n",
       "      <td>0.189090</td>\n",
       "      <td>-1.966474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627697</td>\n",
       "      <td>1.999716</td>\n",
       "      <td>-1.327645</td>\n",
       "      <td>-1.163606</td>\n",
       "      <td>0.597646</td>\n",
       "      <td>-1.481425</td>\n",
       "      <td>0.752092</td>\n",
       "      <td>0.512196</td>\n",
       "      <td>1.074083</td>\n",
       "      <td>0.643611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>25-boot-1</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.783817</td>\n",
       "      <td>-0.783817</td>\n",
       "      <td>0.273827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.151261</td>\n",
       "      <td>-1.151261</td>\n",
       "      <td>0.205728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.831242</td>\n",
       "      <td>-0.831242</td>\n",
       "      <td>0.039015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.817006</td>\n",
       "      <td>1.817006</td>\n",
       "      <td>0.324453</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>25-boot-2</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.203062</td>\n",
       "      <td>0.010452</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>-1.536842</td>\n",
       "      <td>-0.823201</td>\n",
       "      <td>-0.794641</td>\n",
       "      <td>0.243547</td>\n",
       "      <td>-0.187020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686660</td>\n",
       "      <td>-0.043541</td>\n",
       "      <td>-1.653734</td>\n",
       "      <td>-1.815784</td>\n",
       "      <td>0.669064</td>\n",
       "      <td>0.746578</td>\n",
       "      <td>1.519460</td>\n",
       "      <td>1.420722</td>\n",
       "      <td>0.468616</td>\n",
       "      <td>0.577600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486 rows × 2562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sub_writer_id  original_writer_id    0|mean  0|median     0|std    0|skew  \\\n",
       "0    10000-boot-0               10000 -1.267652 -1.268100  0.415971  0.003528   \n",
       "1    10000-boot-1               10000 -0.096789 -0.033635  0.126309 -2.000000   \n",
       "2    10000-boot-2               10000 -1.080543 -1.316513  0.827803  0.996498   \n",
       "3    10000-boot-3               10000 -1.363532 -1.356938  0.281721 -0.140316   \n",
       "4    10000-boot-4               10000 -0.650433 -0.645133  0.375076 -0.024936   \n",
       "..            ...                 ...       ...       ...       ...       ...   \n",
       "481     22-boot-1                  22  0.644612  0.619500  0.758466  0.015167   \n",
       "482     22-boot-2                  22  0.257158 -0.055582  0.734057  1.918920   \n",
       "483     25-boot-0                  25 -1.114425 -1.416616  0.944905  1.208600   \n",
       "484     25-boot-1                  25 -0.783817 -0.783817  0.273827  0.000000   \n",
       "485     25-boot-2                  25 -0.203062  0.010452  0.570328 -1.536842   \n",
       "\n",
       "       1|mean  1|median     1|std    1|skew  ...   637|std  637|skew  \\\n",
       "0   -0.720088 -0.715909  0.304577 -0.079466  ...  0.571644  0.665995   \n",
       "1   -1.000710 -0.905358  0.190704 -2.000000  ...  0.045445  2.000000   \n",
       "2   -0.784924 -0.843327  0.369418  0.334582  ...  0.709097  1.841362   \n",
       "3   -0.020133  0.062116  1.058608 -0.082969  ...  0.724032 -0.523828   \n",
       "4   -0.546456 -0.562023  0.639290  0.126352  ...  1.055851  0.284084   \n",
       "..        ...       ...       ...       ...  ...       ...       ...   \n",
       "481 -1.920069 -2.102232  0.475410  1.586929  ...  0.410881 -1.675974   \n",
       "482 -0.621170 -0.918728  0.997249  1.338300  ...  0.883145 -1.152537   \n",
       "483 -0.690269 -0.601042  0.189090 -1.966474  ...  0.627697  1.999716   \n",
       "484 -1.151261 -1.151261  0.205728  0.000000  ...  0.193107  0.000000   \n",
       "485 -0.823201 -0.794641  0.243547 -0.187020  ...  0.686660 -0.043541   \n",
       "\n",
       "     638|mean  638|median   638|std  638|skew  639|mean  639|median   639|std  \\\n",
       "0   -0.984765   -1.105879  0.482978  1.371838  2.088727    1.771725  0.717917   \n",
       "1   -1.136550   -1.261368  0.249637  2.000000  1.853013    1.769279  0.167468   \n",
       "2   -1.149286   -1.309606  0.415903  1.599816  2.752915    2.916548  0.540770   \n",
       "3   -1.178393   -1.103123  0.167589 -1.970004  1.825675    1.492511  0.943967   \n",
       "4   -1.013792   -1.051509  0.181371  1.139840  2.032573    2.061356  0.151884   \n",
       "..        ...         ...       ...       ...       ...         ...       ...   \n",
       "481 -0.887732   -0.987716  0.505605  0.512837 -0.423427   -0.777453  0.844441   \n",
       "482 -0.625930   -0.338597  0.930939 -1.604537 -0.643648   -0.737771  1.140437   \n",
       "483 -1.327645   -1.163606  0.597646 -1.481425  0.752092    0.512196  1.074083   \n",
       "484 -0.831242   -0.831242  0.039015  0.000000  1.817006    1.817006  0.324453   \n",
       "485 -1.653734   -1.815784  0.669064  0.746578  1.519460    1.420722  0.468616   \n",
       "\n",
       "     639|skew  \n",
       "0    1.939357  \n",
       "1    2.000000  \n",
       "2   -1.103018  \n",
       "3    1.410531  \n",
       "4   -0.961866  \n",
       "..        ...  \n",
       "481  1.775209  \n",
       "482  0.458236  \n",
       "483  0.643611  \n",
       "484  0.000000  \n",
       "485  0.577600  \n",
       "\n",
       "[486 rows x 2562 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:20:24,565] A new study created in memory with name: no-name-af885b1b-c206-4252-b56f-1472299ce1f6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented training set created with 486 samples.\n",
      "\n",
      "Starting Optuna hyperparameter search for 100 trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.835838:   1%|          | 1/100 [00:11<19:45, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:20:36,534] Trial 0 finished with value: 0.8358382537126499 and parameters: {'feature_selection__max_features': 641, 'classification__n_estimators': 333, 'classification__learning_rate': 0.002946670582665134, 'classification__max_depth': 4, 'classification__subsample': 0.8486504178871404, 'classification__colsample_bytree': 0.9760663579788829, 'classification__lambda': 21.121453126520688, 'classification__alpha': 10.357116633455888, 'classification__min_child_weight': 2}. Best is trial 0 with value: 0.8358382537126499.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:   2%|▏         | 2/100 [00:24<19:51, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:20:48,829] Trial 1 finished with value: 0.8628747795414462 and parameters: {'feature_selection__max_features': 330, 'classification__n_estimators': 848, 'classification__learning_rate': 0.009054555995909505, 'classification__max_depth': 6, 'classification__subsample': 0.7124167389427697, 'classification__colsample_bytree': 0.7822094262551019, 'classification__lambda': 13.13947097840283, 'classification__alpha': 0.21984108905456892, 'classification__min_child_weight': 6}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:   3%|▎         | 3/100 [00:33<17:37, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:20:58,225] Trial 2 finished with value: 0.8358382537126499 and parameters: {'feature_selection__max_features': 200, 'classification__n_estimators': 807, 'classification__learning_rate': 0.007847712717851183, 'classification__max_depth': 8, 'classification__subsample': 0.6152140049526106, 'classification__colsample_bytree': 0.6667460335074715, 'classification__lambda': 0.21434425521526845, 'classification__alpha': 14.738403063928812, 'classification__min_child_weight': 4}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:   4%|▍         | 4/100 [00:50<20:55, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:21:14,638] Trial 3 finished with value: 0.843862041104883 and parameters: {'feature_selection__max_features': 305, 'classification__n_estimators': 592, 'classification__learning_rate': 0.0017241717026134607, 'classification__max_depth': 6, 'classification__subsample': 0.7905564444804322, 'classification__colsample_bytree': 0.835139086721246, 'classification__lambda': 1.215289811891079, 'classification__alpha': 0.6998757871902586, 'classification__min_child_weight': 2}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:   5%|▌         | 5/100 [01:06<22:22, 14.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:21:30,653] Trial 4 finished with value: 0.851992122405696 and parameters: {'feature_selection__max_features': 236, 'classification__n_estimators': 635, 'classification__learning_rate': 0.006347451922783713, 'classification__max_depth': 11, 'classification__subsample': 0.9806562669278565, 'classification__colsample_bytree': 0.6959200298289209, 'classification__lambda': 0.10988824074872876, 'classification__alpha': 0.8201655835201137, 'classification__min_child_weight': 1}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:   6%|▌         | 6/100 [01:17<20:51, 13.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:21:42,358] Trial 5 finished with value: 0.8351463912536056 and parameters: {'feature_selection__max_features': 853, 'classification__n_estimators': 374, 'classification__learning_rate': 0.004484116159615471, 'classification__max_depth': 14, 'classification__subsample': 0.7380173779371622, 'classification__colsample_bytree': 0.8496583150398244, 'classification__lambda': 0.3842431091429304, 'classification__alpha': 0.8015089368931341, 'classification__min_child_weight': 7}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:   7%|▋         | 7/100 [01:20<15:23,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:21:45,329] Trial 6 finished with value: 0.8351463912536056 and parameters: {'feature_selection__max_features': 597, 'classification__n_estimators': 121, 'classification__learning_rate': 0.004897235253806007, 'classification__max_depth': 3, 'classification__subsample': 0.6431602711032735, 'classification__colsample_bytree': 0.6415326750714742, 'classification__lambda': 0.5399510666107141, 'classification__alpha': 0.8593883266085615, 'classification__min_child_weight': 9}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:   8%|▊         | 8/100 [01:38<19:05, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:22:03,167] Trial 7 finished with value: 0.8473183195405417 and parameters: {'feature_selection__max_features': 792, 'classification__n_estimators': 525, 'classification__learning_rate': 0.0033907063167969613, 'classification__max_depth': 7, 'classification__subsample': 0.6578348364804464, 'classification__colsample_bytree': 0.6572641617475958, 'classification__lambda': 7.718635747918464, 'classification__alpha': 0.12167736636935834, 'classification__min_child_weight': 3}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:   9%|▉         | 9/100 [01:46<16:37, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:22:10,874] Trial 8 finished with value: 0.8335151845790144 and parameters: {'feature_selection__max_features': 602, 'classification__n_estimators': 315, 'classification__learning_rate': 0.0051386287368829185, 'classification__max_depth': 9, 'classification__subsample': 0.8276831492697142, 'classification__colsample_bytree': 0.6445304906579671, 'classification__lambda': 0.6600401005500346, 'classification__alpha': 0.3110043066562891, 'classification__min_child_weight': 10}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:  10%|█         | 10/100 [01:47<12:07,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:22:12,513] Trial 9 finished with value: 0.8284059524780627 and parameters: {'feature_selection__max_features': 77, 'classification__n_estimators': 62, 'classification__learning_rate': 0.002315256341522965, 'classification__max_depth': 6, 'classification__subsample': 0.8636069581846166, 'classification__colsample_bytree': 0.7551468283122076, 'classification__lambda': 0.1537168363726508, 'classification__alpha': 0.44582825879843174, 'classification__min_child_weight': 6}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:  11%|█         | 11/100 [02:06<16:37, 11.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:22:30,808] Trial 10 finished with value: 0.8358382537126499 and parameters: {'feature_selection__max_features': 405, 'classification__n_estimators': 994, 'classification__learning_rate': 0.0010413979652598502, 'classification__max_depth': 11, 'classification__subsample': 0.7384446324425695, 'classification__colsample_bytree': 0.918939145787927, 'classification__lambda': 4.563835656175795, 'classification__alpha': 3.960929579825326, 'classification__min_child_weight': 8}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:  12%|█▏        | 12/100 [02:10<13:13,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:22:34,825] Trial 11 finished with value: 0.7977220654418279 and parameters: {'feature_selection__max_features': 31, 'classification__n_estimators': 768, 'classification__learning_rate': 0.00991351542029569, 'classification__max_depth': 12, 'classification__subsample': 0.9990848238685484, 'classification__colsample_bytree': 0.7321112696347131, 'classification__lambda': 3.242887778483523, 'classification__alpha': 0.1590653729351457, 'classification__min_child_weight': 5}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:  13%|█▎        | 13/100 [02:30<18:07, 12.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:22:55,330] Trial 12 finished with value: 0.8440687063875468 and parameters: {'feature_selection__max_features': 254, 'classification__n_estimators': 775, 'classification__learning_rate': 0.007184539491830894, 'classification__max_depth': 11, 'classification__subsample': 0.9652764726334495, 'classification__colsample_bytree': 0.7417872912863951, 'classification__lambda': 19.825638959273846, 'classification__alpha': 2.3001528792302466, 'classification__min_child_weight': 1}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:  14%|█▍        | 14/100 [02:49<20:37, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:23:14,075] Trial 13 finished with value: 0.8613736263736264 and parameters: {'feature_selection__max_features': 403, 'classification__n_estimators': 997, 'classification__learning_rate': 0.006931172582940143, 'classification__max_depth': 15, 'classification__subsample': 0.9152029489271344, 'classification__colsample_bytree': 0.7773773526888486, 'classification__lambda': 1.9410243276333567, 'classification__alpha': 0.23280473220770884, 'classification__min_child_weight': 5}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.862875:  15%|█▌        | 15/100 [03:05<21:09, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:23:30,274] Trial 14 finished with value: 0.8613736263736264 and parameters: {'feature_selection__max_features': 447, 'classification__n_estimators': 994, 'classification__learning_rate': 0.00972930384971974, 'classification__max_depth': 14, 'classification__subsample': 0.9274954751187283, 'classification__colsample_bytree': 0.8161533808866067, 'classification__lambda': 8.344741100108953, 'classification__alpha': 0.2386525659407139, 'classification__min_child_weight': 6}. Best is trial 1 with value: 0.8628747795414462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  16%|█▌        | 16/100 [03:21<21:24, 15.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:23:46,398] Trial 15 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 368, 'classification__n_estimators': 880, 'classification__learning_rate': 0.006114714583116497, 'classification__max_depth': 15, 'classification__subsample': 0.901700668393699, 'classification__colsample_bytree': 0.7847195847246358, 'classification__lambda': 1.4045286841754425, 'classification__alpha': 0.1201110470614429, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  17%|█▋        | 17/100 [03:40<22:39, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:24:05,318] Trial 16 finished with value: 0.8628747795414462 and parameters: {'feature_selection__max_features': 523, 'classification__n_estimators': 872, 'classification__learning_rate': 0.004066062599644616, 'classification__max_depth': 5, 'classification__subsample': 0.7256131784696446, 'classification__colsample_bytree': 0.8656924452295917, 'classification__lambda': 1.3015585934355338, 'classification__alpha': 0.10087529968728232, 'classification__min_child_weight': 7}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  18%|█▊        | 18/100 [04:06<26:13, 19.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:24:31,019] Trial 17 finished with value: 0.8623361009028628 and parameters: {'feature_selection__max_features': 988, 'classification__n_estimators': 658, 'classification__learning_rate': 0.005770440333726704, 'classification__max_depth': 9, 'classification__subsample': 0.7820011268263173, 'classification__colsample_bytree': 0.8794812640683918, 'classification__lambda': 13.168585927922619, 'classification__alpha': 1.84467720907127, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  19%|█▉        | 19/100 [04:13<20:54, 15.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:24:37,885] Trial 18 finished with value: 0.8513150831991411 and parameters: {'feature_selection__max_features': 140, 'classification__n_estimators': 869, 'classification__learning_rate': 0.008400444652221286, 'classification__max_depth': 13, 'classification__subsample': 0.6882214062103271, 'classification__colsample_bytree': 0.7921360211094995, 'classification__lambda': 3.019483787106197, 'classification__alpha': 0.17176662922056907, 'classification__min_child_weight': 7}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  20%|██        | 20/100 [04:28<20:41, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:24:53,480] Trial 19 finished with value: 0.8467288235560999 and parameters: {'feature_selection__max_features': 356, 'classification__n_estimators': 700, 'classification__learning_rate': 0.0026486367118762227, 'classification__max_depth': 8, 'classification__subsample': 0.892629715884182, 'classification__colsample_bytree': 0.605753412217504, 'classification__lambda': 6.014428167553055, 'classification__alpha': 0.38091313699625307, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  21%|██        | 21/100 [04:38<18:12, 13.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:25:03,387] Trial 20 finished with value: 0.8196153741066445 and parameters: {'feature_selection__max_features': 536, 'classification__n_estimators': 474, 'classification__learning_rate': 0.003494297047166271, 'classification__max_depth': 3, 'classification__subsample': 0.6974036702614337, 'classification__colsample_bytree': 0.9151540897033119, 'classification__lambda': 29.289969779610097, 'classification__alpha': 5.2568996279083136, 'classification__min_child_weight': 8}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  22%|██▏       | 22/100 [04:58<20:15, 15.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:25:23,051] Trial 21 finished with value: 0.8548309178743961 and parameters: {'feature_selection__max_features': 494, 'classification__n_estimators': 877, 'classification__learning_rate': 0.003809228650528347, 'classification__max_depth': 5, 'classification__subsample': 0.7630228678177954, 'classification__colsample_bytree': 0.8558959794613593, 'classification__lambda': 1.2963102425956106, 'classification__alpha': 0.10591881270775814, 'classification__min_child_weight': 7}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  23%|██▎       | 23/100 [05:26<24:51, 19.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:25:51,234] Trial 22 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 743, 'classification__n_estimators': 881, 'classification__learning_rate': 0.00402153168900449, 'classification__max_depth': 5, 'classification__subsample': 0.7208749691720542, 'classification__colsample_bytree': 0.8915099194628952, 'classification__lambda': 0.7155589340996313, 'classification__alpha': 0.106260334631811, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  24%|██▍       | 24/100 [05:56<28:24, 22.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:26:20,809] Trial 23 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 719, 'classification__n_estimators': 908, 'classification__learning_rate': 0.005689256717007075, 'classification__max_depth': 5, 'classification__subsample': 0.7089360045686284, 'classification__colsample_bytree': 0.9881586012532749, 'classification__lambda': 0.7961165291336861, 'classification__alpha': 0.1783418952276388, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  25%|██▌       | 25/100 [06:22<29:29, 23.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:26:47,140] Trial 24 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 726, 'classification__n_estimators': 920, 'classification__learning_rate': 0.005643195209356361, 'classification__max_depth': 4, 'classification__subsample': 0.6682430808699463, 'classification__colsample_bytree': 0.9946184914492162, 'classification__lambda': 0.7197244118726221, 'classification__alpha': 0.478832660961114, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  26%|██▌       | 26/100 [07:01<34:36, 28.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:27:25,616] Trial 25 finished with value: 0.8542007637752319 and parameters: {'feature_selection__max_features': 902, 'classification__n_estimators': 726, 'classification__learning_rate': 0.0021984306619116573, 'classification__max_depth': 9, 'classification__subsample': 0.8222309563036687, 'classification__colsample_bytree': 0.949386846373925, 'classification__lambda': 0.38395189297417526, 'classification__alpha': 0.15660630933792413, 'classification__min_child_weight': 3}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  27%|██▋       | 27/100 [07:28<34:01, 27.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:27:53,340] Trial 26 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 680, 'classification__n_estimators': 935, 'classification__learning_rate': 0.004617259606986103, 'classification__max_depth': 7, 'classification__subsample': 0.7668205435082377, 'classification__colsample_bytree': 0.9127003102294938, 'classification__lambda': 2.2283375118903463, 'classification__alpha': 0.2764917537279375, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  28%|██▊       | 28/100 [07:49<31:01, 25.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:28:14,260] Trial 27 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 763, 'classification__n_estimators': 814, 'classification__learning_rate': 0.006032128762890667, 'classification__max_depth': 4, 'classification__subsample': 0.6162379893166547, 'classification__colsample_bytree': 0.9414310979860273, 'classification__lambda': 0.8812506266325266, 'classification__alpha': 0.15383294416679208, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  29%|██▉       | 29/100 [08:24<33:41, 28.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:28:48,841] Trial 28 finished with value: 0.842531635666647 and parameters: {'feature_selection__max_features': 850, 'classification__n_estimators': 936, 'classification__learning_rate': 0.0017249090694040324, 'classification__max_depth': 10, 'classification__subsample': 0.8059203411616132, 'classification__colsample_bytree': 0.8846984774192332, 'classification__lambda': 0.4504494568763528, 'classification__alpha': 0.5399427386508211, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  30%|███       | 30/100 [08:56<34:32, 29.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:29:21,124] Trial 29 finished with value: 0.8196153741066445 and parameters: {'feature_selection__max_features': 708, 'classification__n_estimators': 737, 'classification__learning_rate': 0.0030845505368782473, 'classification__max_depth': 5, 'classification__subsample': 0.8670146534788064, 'classification__colsample_bytree': 0.9624317023164949, 'classification__lambda': 0.29594639892196345, 'classification__alpha': 1.2480303739968106, 'classification__min_child_weight': 3}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  31%|███       | 31/100 [09:15<30:13, 26.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:29:39,659] Trial 30 finished with value: 0.8623361009028628 and parameters: {'feature_selection__max_features': 648, 'classification__n_estimators': 431, 'classification__learning_rate': 0.00426465560768873, 'classification__max_depth': 7, 'classification__subsample': 0.6814092078166579, 'classification__colsample_bytree': 0.9923461240158968, 'classification__lambda': 0.9985374134266645, 'classification__alpha': 0.10326789907448046, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  32%|███▏      | 32/100 [09:32<26:53, 23.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:29:57,424] Trial 31 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 726, 'classification__n_estimators': 925, 'classification__learning_rate': 0.005598409855907004, 'classification__max_depth': 3, 'classification__subsample': 0.6673008770276417, 'classification__colsample_bytree': 0.9828961926252454, 'classification__lambda': 0.7088772495354843, 'classification__alpha': 0.3913377515117485, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  33%|███▎      | 33/100 [09:57<26:55, 24.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:30:22,421] Trial 32 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 795, 'classification__n_estimators': 915, 'classification__learning_rate': 0.005257951437434617, 'classification__max_depth': 4, 'classification__subsample': 0.7107274691777512, 'classification__colsample_bytree': 0.9968248842104539, 'classification__lambda': 1.6169908586957666, 'classification__alpha': 0.19660098591150105, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  34%|███▍      | 34/100 [10:20<26:02, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:30:45,076] Trial 33 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 935, 'classification__n_estimators': 822, 'classification__learning_rate': 0.007429189643005597, 'classification__max_depth': 4, 'classification__subsample': 0.636412961581606, 'classification__colsample_bytree': 0.9659877826844887, 'classification__lambda': 0.24821890226394763, 'classification__alpha': 0.30114168852311035, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  35%|███▌      | 35/100 [10:42<25:10, 23.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:31:07,318] Trial 34 finished with value: 0.8623361009028628 and parameters: {'feature_selection__max_features': 578, 'classification__n_estimators': 836, 'classification__learning_rate': 0.006507247641039209, 'classification__max_depth': 5, 'classification__subsample': 0.7497014424308295, 'classification__colsample_bytree': 0.9049864509840744, 'classification__lambda': 0.8417079698970609, 'classification__alpha': 0.13975657902910368, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  36%|███▌      | 36/100 [10:55<21:23, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:31:19,930] Trial 35 finished with value: 0.8277582982702197 and parameters: {'feature_selection__max_features': 668, 'classification__n_estimators': 584, 'classification__learning_rate': 0.008167249292055305, 'classification__max_depth': 6, 'classification__subsample': 0.6038855448356794, 'classification__colsample_bytree': 0.8199140041607574, 'classification__lambda': 0.5662277820878292, 'classification__alpha': 19.89761987888178, 'classification__min_child_weight': 8}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  37%|███▋      | 37/100 [11:03<17:21, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:31:28,231] Trial 36 finished with value: 0.8351463912536056 and parameters: {'feature_selection__max_features': 845, 'classification__n_estimators': 220, 'classification__learning_rate': 0.0038831893874597726, 'classification__max_depth': 4, 'classification__subsample': 0.7249530666317956, 'classification__colsample_bytree': 0.9326242489641577, 'classification__lambda': 2.484202642837419, 'classification__alpha': 0.616157200733333, 'classification__min_child_weight': 3}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  38%|███▊      | 38/100 [11:21<17:30, 16.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:31:46,142] Trial 37 finished with value: 0.8628747795414462 and parameters: {'feature_selection__max_features': 304, 'classification__n_estimators': 784, 'classification__learning_rate': 0.004741877851611815, 'classification__max_depth': 8, 'classification__subsample': 0.6991960892310012, 'classification__colsample_bytree': 0.6989173494965656, 'classification__lambda': 0.17763861652495652, 'classification__alpha': 0.2070741991491324, 'classification__min_child_weight': 2}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  39%|███▉      | 39/100 [11:43<18:52, 18.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:32:08,500] Trial 38 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 783, 'classification__n_estimators': 676, 'classification__learning_rate': 0.0063882081096370774, 'classification__max_depth': 6, 'classification__subsample': 0.6663218153843872, 'classification__colsample_bytree': 0.9760904540336118, 'classification__lambda': 1.4401645051835281, 'classification__alpha': 1.0497028296807172, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  40%|████      | 40/100 [11:58<17:23, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:32:23,119] Trial 39 finished with value: 0.8623361009028628 and parameters: {'feature_selection__max_features': 618, 'classification__n_estimators': 614, 'classification__learning_rate': 0.002745193428818985, 'classification__max_depth': 3, 'classification__subsample': 0.6345433331259998, 'classification__colsample_bytree': 0.836677702230964, 'classification__lambda': 1.039285773358072, 'classification__alpha': 0.48258626985670944, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  41%|████      | 41/100 [12:25<19:51, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:32:49,871] Trial 40 finished with value: 0.8623361009028628 and parameters: {'feature_selection__max_features': 728, 'classification__n_estimators': 898, 'classification__learning_rate': 0.005328851125167298, 'classification__max_depth': 7, 'classification__subsample': 0.9461471123918817, 'classification__colsample_bytree': 0.7719927652744032, 'classification__lambda': 0.3386090202526188, 'classification__alpha': 0.13064712753703744, 'classification__min_child_weight': 7}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  42%|████▏     | 42/100 [12:58<23:25, 24.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:33:23,537] Trial 41 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 680, 'classification__n_estimators': 932, 'classification__learning_rate': 0.004523801176058459, 'classification__max_depth': 6, 'classification__subsample': 0.7731331331377238, 'classification__colsample_bytree': 0.9582772143582126, 'classification__lambda': 2.249630697136011, 'classification__alpha': 0.29084605222285276, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  43%|████▎     | 43/100 [13:36<26:52, 28.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:34:01,280] Trial 42 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 747, 'classification__n_estimators': 960, 'classification__learning_rate': 0.0035303863080744847, 'classification__max_depth': 7, 'classification__subsample': 0.7543743298501026, 'classification__colsample_bytree': 0.897107841443808, 'classification__lambda': 0.7034469842379019, 'classification__alpha': 0.24201075465517674, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  44%|████▍     | 44/100 [14:02<25:45, 27.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:34:27,245] Trial 43 finished with value: 0.8623361009028628 and parameters: {'feature_selection__max_features': 561, 'classification__n_estimators': 849, 'classification__learning_rate': 0.004796783971245263, 'classification__max_depth': 5, 'classification__subsample': 0.7158469908437544, 'classification__colsample_bytree': 0.9270093861209331, 'classification__lambda': 0.5045816692078615, 'classification__alpha': 0.3385397469760396, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  45%|████▌     | 45/100 [14:45<29:21, 32.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:35:09,616] Trial 44 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 820, 'classification__n_estimators': 957, 'classification__learning_rate': 0.00579166875548496, 'classification__max_depth': 8, 'classification__subsample': 0.8406036172878485, 'classification__colsample_bytree': 0.8080223149974289, 'classification__lambda': 3.836633706519517, 'classification__alpha': 0.18680613177369348, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  46%|████▌     | 46/100 [15:15<28:29, 31.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:35:40,430] Trial 45 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 685, 'classification__n_estimators': 891, 'classification__learning_rate': 0.004369191619612257, 'classification__max_depth': 5, 'classification__subsample': 0.811389580106124, 'classification__colsample_bytree': 0.8345543534065134, 'classification__lambda': 1.802374020268895, 'classification__alpha': 0.12339955366629227, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  47%|████▋     | 47/100 [15:37<25:19, 28.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:36:02,116] Trial 46 finished with value: 0.8623361009028628 and parameters: {'feature_selection__max_features': 477, 'classification__n_estimators': 756, 'classification__learning_rate': 0.006868359946936732, 'classification__max_depth': 10, 'classification__subsample': 0.7401090851220204, 'classification__colsample_bytree': 0.9969564506608608, 'classification__lambda': 1.0627727503473086, 'classification__alpha': 0.7169785086127854, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  48%|████▊     | 48/100 [16:05<24:34, 28.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:36:29,750] Trial 47 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 906, 'classification__n_estimators': 807, 'classification__learning_rate': 0.004958614828448245, 'classification__max_depth': 15, 'classification__subsample': 0.6536628419316236, 'classification__colsample_bytree': 0.9425652806781495, 'classification__lambda': 2.293359403989676, 'classification__alpha': 0.2702590183955579, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  49%|████▉     | 49/100 [16:52<28:57, 34.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:37:17,166] Trial 48 finished with value: 0.8542007637752319 and parameters: {'feature_selection__max_features': 604, 'classification__n_estimators': 972, 'classification__learning_rate': 0.001034108221578124, 'classification__max_depth': 6, 'classification__subsample': 0.7948946359874729, 'classification__colsample_bytree': 0.8725330097452454, 'classification__lambda': 0.6363844629173522, 'classification__alpha': 0.19720116152491843, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  50%|█████     | 50/100 [17:06<23:25, 28.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:37:31,345] Trial 49 finished with value: 0.8473183195405417 and parameters: {'feature_selection__max_features': 433, 'classification__n_estimators': 897, 'classification__learning_rate': 0.00860143016589707, 'classification__max_depth': 12, 'classification__subsample': 0.682147788039763, 'classification__colsample_bytree': 0.9016059714388236, 'classification__lambda': 4.999366974007928, 'classification__alpha': 0.43045285456261584, 'classification__min_child_weight': 10}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  51%|█████     | 51/100 [17:22<19:53, 24.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:37:46,923] Trial 50 finished with value: 0.8277582982702197 and parameters: {'feature_selection__max_features': 356, 'classification__n_estimators': 846, 'classification__learning_rate': 0.00390912617759562, 'classification__max_depth': 4, 'classification__subsample': 0.7833489336955766, 'classification__colsample_bytree': 0.7201918650863205, 'classification__lambda': 0.4449677256721322, 'classification__alpha': 7.400136916499161, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  52%|█████▏    | 52/100 [17:45<19:11, 23.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:38:10,048] Trial 51 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 763, 'classification__n_estimators': 800, 'classification__learning_rate': 0.006293464136166024, 'classification__max_depth': 4, 'classification__subsample': 0.6154325501073241, 'classification__colsample_bytree': 0.9417972091626649, 'classification__lambda': 0.838629123866954, 'classification__alpha': 0.14883631631116787, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  53%|█████▎    | 53/100 [18:04<17:40, 22.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:38:29,284] Trial 52 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 637, 'classification__n_estimators': 957, 'classification__learning_rate': 0.0059943529334214865, 'classification__max_depth': 3, 'classification__subsample': 0.6316933723645888, 'classification__colsample_bytree': 0.9752904034624778, 'classification__lambda': 0.8832116586910109, 'classification__alpha': 0.16440271149951424, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  54%|█████▍    | 54/100 [18:28<17:30, 22.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:38:52,774] Trial 53 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 817, 'classification__n_estimators': 832, 'classification__learning_rate': 0.007503896629806304, 'classification__max_depth': 5, 'classification__subsample': 0.6505163527775651, 'classification__colsample_bytree': 0.9188672869987726, 'classification__lambda': 1.2162656865067911, 'classification__alpha': 0.12915502318269442, 'classification__min_child_weight': 3}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  55%|█████▌    | 55/100 [18:51<17:07, 22.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:39:15,627] Trial 54 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 702, 'classification__n_estimators': 997, 'classification__learning_rate': 0.005448866338185689, 'classification__max_depth': 4, 'classification__subsample': 0.7067494081593377, 'classification__colsample_bytree': 0.7598228323249184, 'classification__lambda': 1.6490327400119136, 'classification__alpha': 0.24562680296601833, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  56%|█████▌    | 56/100 [19:01<13:57, 19.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:39:25,764] Trial 55 finished with value: 0.8548309178743961 and parameters: {'feature_selection__max_features': 206, 'classification__n_estimators': 862, 'classification__learning_rate': 0.003275538205335125, 'classification__max_depth': 6, 'classification__subsample': 0.6004099184230999, 'classification__colsample_bytree': 0.9526510579451088, 'classification__lambda': 0.7710771826842094, 'classification__alpha': 0.11403637601352802, 'classification__min_child_weight': 7}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  57%|█████▋    | 57/100 [19:25<14:47, 20.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:39:50,122] Trial 56 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 877, 'classification__n_estimators': 711, 'classification__learning_rate': 0.005135129229715072, 'classification__max_depth': 7, 'classification__subsample': 0.7309682343442435, 'classification__colsample_bytree': 0.9795752914356908, 'classification__lambda': 0.5841190798321917, 'classification__alpha': 0.1695481305205016, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  58%|█████▊    | 58/100 [19:47<14:43, 21.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:40:12,123] Trial 57 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 783, 'classification__n_estimators': 927, 'classification__learning_rate': 0.004505951844623749, 'classification__max_depth': 3, 'classification__subsample': 0.6667690346479607, 'classification__colsample_bytree': 0.8885050227050667, 'classification__lambda': 2.969854253584586, 'classification__alpha': 2.6081917950130604, 'classification__min_child_weight': 2}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  59%|█████▉    | 59/100 [20:03<13:14, 19.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:40:27,589] Trial 58 finished with value: 0.8628747795414462 and parameters: {'feature_selection__max_features': 751, 'classification__n_estimators': 549, 'classification__learning_rate': 0.005970366189683135, 'classification__max_depth': 5, 'classification__subsample': 0.6171367466632768, 'classification__colsample_bytree': 0.7950306200114821, 'classification__lambda': 1.4332667742510492, 'classification__alpha': 0.3500809009034484, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  60%|██████    | 60/100 [20:14<11:15, 16.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:40:38,693] Trial 59 finished with value: 0.8628747795414462 and parameters: {'feature_selection__max_features': 272, 'classification__n_estimators': 770, 'classification__learning_rate': 0.006974073738486275, 'classification__max_depth': 14, 'classification__subsample': 0.8669195840174578, 'classification__colsample_bytree': 0.933907660307925, 'classification__lambda': 0.11312913773447719, 'classification__alpha': 0.2118587528358721, 'classification__min_child_weight': 3}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  61%|██████    | 61/100 [20:33<11:22, 17.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:40:57,639] Trial 60 finished with value: 0.843260090384915 and parameters: {'feature_selection__max_features': 993, 'classification__n_estimators': 901, 'classification__learning_rate': 0.0012295755043308144, 'classification__max_depth': 4, 'classification__subsample': 0.8882099001318214, 'classification__colsample_bytree': 0.8552004125628916, 'classification__lambda': 0.44114795945605956, 'classification__alpha': 0.10198194438882838, 'classification__min_child_weight': 7}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  62%|██████▏   | 62/100 [20:44<09:58, 15.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:41:09,272] Trial 61 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 711, 'classification__n_estimators': 930, 'classification__learning_rate': 0.005586184713637, 'classification__max_depth': 3, 'classification__subsample': 0.672238099343826, 'classification__colsample_bytree': 0.9762263058601829, 'classification__lambda': 0.6925935143237858, 'classification__alpha': 0.5944943804382541, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  63%|██████▎   | 63/100 [20:58<09:17, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:41:22,723] Trial 62 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 741, 'classification__n_estimators': 865, 'classification__learning_rate': 0.00406579378607974, 'classification__max_depth': 3, 'classification__subsample': 0.6908305227806778, 'classification__colsample_bytree': 0.9863520069992957, 'classification__lambda': 1.0357095810793806, 'classification__alpha': 0.37218241453382656, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  64%|██████▍   | 64/100 [21:14<09:19, 15.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:41:39,355] Trial 63 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 809, 'classification__n_estimators': 976, 'classification__learning_rate': 0.006345357593942009, 'classification__max_depth': 4, 'classification__subsample': 0.7656563234819209, 'classification__colsample_bytree': 0.963072772031164, 'classification__lambda': 0.910798051083047, 'classification__alpha': 0.14314426693251195, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  65%|██████▌   | 65/100 [21:28<08:40, 14.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:41:52,727] Trial 64 finished with value: 0.8628747795414462 and parameters: {'feature_selection__max_features': 650, 'classification__n_estimators': 814, 'classification__learning_rate': 0.009201344398367183, 'classification__max_depth': 13, 'classification__subsample': 0.67416254684605, 'classification__colsample_bytree': 0.9974395859090021, 'classification__lambda': 0.301026533531465, 'classification__alpha': 0.45539701188511117, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  66%|██████▌   | 66/100 [21:49<09:35, 16.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:42:14,460] Trial 65 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 719, 'classification__n_estimators': 935, 'classification__learning_rate': 0.004902531268546024, 'classification__max_depth': 5, 'classification__subsample': 0.7215787982388165, 'classification__colsample_bytree': 0.9490672529834915, 'classification__lambda': 2.0650426127416037, 'classification__alpha': 0.26942766310594557, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  67%|██████▋   | 67/100 [21:55<07:22, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:42:19,667] Trial 66 finished with value: 0.8277582982702197 and parameters: {'feature_selection__max_features': 537, 'classification__n_estimators': 327, 'classification__learning_rate': 0.0036827013387993536, 'classification__max_depth': 3, 'classification__subsample': 0.6997179458352251, 'classification__colsample_bytree': 0.9679688742066598, 'classification__lambda': 1.2786398306568427, 'classification__alpha': 1.035790008305797, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  68%|██████▊   | 68/100 [21:58<05:37, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:42:23,508] Trial 67 finished with value: 0.8358382537126499 and parameters: {'feature_selection__max_features': 128, 'classification__n_estimators': 870, 'classification__learning_rate': 0.007858667532009214, 'classification__max_depth': 4, 'classification__subsample': 0.7477236622541709, 'classification__colsample_bytree': 0.9093495870979234, 'classification__lambda': 0.4976995083090702, 'classification__alpha': 0.17394442707719754, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  69%|██████▉   | 69/100 [22:17<06:43, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:42:42,313] Trial 68 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 953, 'classification__n_estimators': 903, 'classification__learning_rate': 0.005568666206485473, 'classification__max_depth': 10, 'classification__subsample': 0.6434325262315471, 'classification__colsample_bytree': 0.987699672165756, 'classification__lambda': 0.7570461605409003, 'classification__alpha': 0.11898502949197896, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  70%|███████   | 70/100 [22:42<08:12, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:43:06,604] Trial 69 finished with value: 0.838561556646663 and parameters: {'feature_selection__max_features': 774, 'classification__n_estimators': 751, 'classification__learning_rate': 0.004211127878618478, 'classification__max_depth': 8, 'classification__subsample': 0.9957379204061638, 'classification__colsample_bytree': 0.9241634752172357, 'classification__lambda': 2.7015904860660673, 'classification__alpha': 0.2280726198971141, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  71%|███████   | 71/100 [22:59<08:08, 16.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:43:24,511] Trial 70 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 630, 'classification__n_estimators': 794, 'classification__learning_rate': 0.004635655343886658, 'classification__max_depth': 5, 'classification__subsample': 0.6589458489794774, 'classification__colsample_bytree': 0.9397492057215666, 'classification__lambda': 1.559081575356124, 'classification__alpha': 0.40228931332723794, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  72%|███████▏  | 72/100 [23:17<07:58, 17.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:43:42,136] Trial 71 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 841, 'classification__n_estimators': 924, 'classification__learning_rate': 0.005207636201937696, 'classification__max_depth': 4, 'classification__subsample': 0.7057453134041237, 'classification__colsample_bytree': 0.9991984819008136, 'classification__lambda': 1.862129638848307, 'classification__alpha': 0.18971184510321043, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  73%|███████▎  | 73/100 [23:34<07:36, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:43:58,645] Trial 72 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 882, 'classification__n_estimators': 909, 'classification__learning_rate': 0.006673366596808499, 'classification__max_depth': 4, 'classification__subsample': 0.7325680351213154, 'classification__colsample_bytree': 0.9846313596578569, 'classification__lambda': 1.1218774170998287, 'classification__alpha': 0.14268031405644932, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  74%|███████▍  | 74/100 [23:40<05:58, 13.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:44:05,088] Trial 73 finished with value: 0.8351463912536056 and parameters: {'feature_selection__max_features': 668, 'classification__n_estimators': 250, 'classification__learning_rate': 0.005960269810168549, 'classification__max_depth': 6, 'classification__subsample': 0.7179878947187388, 'classification__colsample_bytree': 0.9763125478092318, 'classification__lambda': 0.6282365438211929, 'classification__alpha': 0.3199687718070006, 'classification__min_child_weight': 9}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  75%|███████▌  | 75/100 [23:53<05:37, 13.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:44:17,927] Trial 74 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 806, 'classification__n_estimators': 953, 'classification__learning_rate': 0.005336506806326678, 'classification__max_depth': 3, 'classification__subsample': 0.6211561849786569, 'classification__colsample_bytree': 0.9573805275085279, 'classification__lambda': 1.3062372258193558, 'classification__alpha': 0.22387162333607868, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  76%|███████▌  | 76/100 [24:07<05:28, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:44:32,098] Trial 75 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 726, 'classification__n_estimators': 836, 'classification__learning_rate': 0.004960152604128292, 'classification__max_depth': 4, 'classification__subsample': 0.6886896464080816, 'classification__colsample_bytree': 0.7833002018503362, 'classification__lambda': 0.957415717347946, 'classification__alpha': 0.5152484898245298, 'classification__min_child_weight': 7}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  77%|███████▋  | 77/100 [24:27<05:58, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:44:52,120] Trial 76 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 698, 'classification__n_estimators': 978, 'classification__learning_rate': 0.006085823650771848, 'classification__max_depth': 5, 'classification__subsample': 0.7128011202584054, 'classification__colsample_bytree': 0.967818046283015, 'classification__lambda': 1.7250752656662, 'classification__alpha': 0.28496378345405005, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  78%|███████▊  | 78/100 [24:40<05:24, 14.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:45:04,910] Trial 77 finished with value: 0.8623361009028628 and parameters: {'feature_selection__max_features': 578, 'classification__n_estimators': 884, 'classification__learning_rate': 0.005588622689047469, 'classification__max_depth': 3, 'classification__subsample': 0.7590536226644294, 'classification__colsample_bytree': 0.9879647065730687, 'classification__lambda': 3.927939503418578, 'classification__alpha': 0.15446301898300058, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  79%|███████▉  | 79/100 [24:54<05:03, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:45:18,663] Trial 78 finished with value: 0.8542007637752319 and parameters: {'feature_selection__max_features': 764, 'classification__n_estimators': 469, 'classification__learning_rate': 0.007295497966495662, 'classification__max_depth': 7, 'classification__subsample': 0.7411562131193716, 'classification__colsample_bytree': 0.8906333047043044, 'classification__lambda': 0.3519117617900916, 'classification__alpha': 1.6121154547337384, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  80%|████████  | 80/100 [25:16<05:39, 16.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:45:41,466] Trial 79 finished with value: 0.8616731221994379 and parameters: {'feature_selection__max_features': 671, 'classification__n_estimators': 908, 'classification__learning_rate': 0.004285463734746533, 'classification__max_depth': 5, 'classification__subsample': 0.9661138624021699, 'classification__colsample_bytree': 0.9446085960797324, 'classification__lambda': 0.5223360250903414, 'classification__alpha': 0.12028836405449198, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  81%|████████  | 81/100 [25:35<05:31, 17.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:46:00,124] Trial 80 finished with value: 0.8623361009028628 and parameters: {'feature_selection__max_features': 845, 'classification__n_estimators': 948, 'classification__learning_rate': 0.00301389190076821, 'classification__max_depth': 4, 'classification__subsample': 0.7761023256551558, 'classification__colsample_bytree': 0.82610011177983, 'classification__lambda': 0.7761565097960623, 'classification__alpha': 0.18432764471490454, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  82%|████████▏ | 82/100 [25:50<04:59, 16.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:46:14,908] Trial 81 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 934, 'classification__n_estimators': 827, 'classification__learning_rate': 0.007629355565454454, 'classification__max_depth': 4, 'classification__subsample': 0.6396825907365878, 'classification__colsample_bytree': 0.9667378649729206, 'classification__lambda': 0.2354087804320019, 'classification__alpha': 0.30058538453816547, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  83%|████████▎ | 83/100 [25:58<04:00, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:46:23,222] Trial 82 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 374, 'classification__n_estimators': 872, 'classification__learning_rate': 0.006841855234044376, 'classification__max_depth': 3, 'classification__subsample': 0.629264588259303, 'classification__colsample_bytree': 0.9564573361821663, 'classification__lambda': 0.24748213335040117, 'classification__alpha': 0.20848906498356437, 'classification__min_child_weight': 3}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  84%|████████▍ | 84/100 [26:12<03:44, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:46:36,861] Trial 83 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 947, 'classification__n_estimators': 841, 'classification__learning_rate': 0.006282519914643058, 'classification__max_depth': 4, 'classification__subsample': 0.6505028448149285, 'classification__colsample_bytree': 0.9711624699016834, 'classification__lambda': 0.16638613184567605, 'classification__alpha': 0.2606461776612585, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  85%|████████▌ | 85/100 [26:34<04:05, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:46:58,668] Trial 84 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 794, 'classification__n_estimators': 814, 'classification__learning_rate': 0.008012901204097112, 'classification__max_depth': 5, 'classification__subsample': 0.6781499423251736, 'classification__colsample_bytree': 0.9907881321688532, 'classification__lambda': 1.4544777224663565, 'classification__alpha': 0.712443265521699, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  86%|████████▌ | 86/100 [26:56<04:13, 18.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:47:21,007] Trial 85 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 746, 'classification__n_estimators': 997, 'classification__learning_rate': 0.005086711664613418, 'classification__max_depth': 6, 'classification__subsample': 0.610156403185781, 'classification__colsample_bytree': 0.9318473371828462, 'classification__lambda': 0.12672665590607457, 'classification__alpha': 0.3368195483180438, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  87%|████████▋ | 87/100 [27:08<03:30, 16.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:47:32,599] Trial 86 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 883, 'classification__n_estimators': 687, 'classification__learning_rate': 0.008670752043306622, 'classification__max_depth': 4, 'classification__subsample': 0.6611856097278128, 'classification__colsample_bytree': 0.7416803635553669, 'classification__lambda': 2.1624747467823346, 'classification__alpha': 0.10083182611702045, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  88%|████████▊ | 88/100 [27:20<03:00, 15.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:47:45,102] Trial 87 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 612, 'classification__n_estimators': 861, 'classification__learning_rate': 0.004746812173482423, 'classification__max_depth': 3, 'classification__subsample': 0.6254928074959791, 'classification__colsample_bytree': 0.9819250502724313, 'classification__lambda': 0.3989887784986765, 'classification__alpha': 0.1327440954090552, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  89%|████████▉ | 89/100 [27:50<03:36, 19.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:48:15,549] Trial 88 finished with value: 0.8623361009028628 and parameters: {'feature_selection__max_features': 826, 'classification__n_estimators': 916, 'classification__learning_rate': 0.005651726421595759, 'classification__max_depth': 6, 'classification__subsample': 0.9149113721588821, 'classification__colsample_bytree': 0.9995806320481359, 'classification__lambda': 1.1556275874301765, 'classification__alpha': 0.16029620841044812, 'classification__min_child_weight': 3}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  90%|█████████ | 90/100 [28:13<03:25, 20.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:48:38,047] Trial 89 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 912, 'classification__n_estimators': 784, 'classification__learning_rate': 0.006487747028021945, 'classification__max_depth': 15, 'classification__subsample': 0.6423684136655128, 'classification__colsample_bytree': 0.912159438748087, 'classification__lambda': 3.5779923121256676, 'classification__alpha': 0.3996329146887504, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  91%|█████████ | 91/100 [28:35<03:08, 20.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:48:59,871] Trial 90 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 865, 'classification__n_estimators': 884, 'classification__learning_rate': 0.007295285871656976, 'classification__max_depth': 9, 'classification__subsample': 0.8419531026094147, 'classification__colsample_bytree': 0.8692977043605515, 'classification__lambda': 2.5772778660967237, 'classification__alpha': 0.24501044791785212, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  92%|█████████▏| 92/100 [28:50<02:33, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:49:14,922] Trial 91 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 780, 'classification__n_estimators': 625, 'classification__learning_rate': 0.005978566423554116, 'classification__max_depth': 5, 'classification__subsample': 0.6919546013675383, 'classification__colsample_bytree': 0.9554059426064575, 'classification__lambda': 0.8927068217745023, 'classification__alpha': 1.0849860411870516, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  93%|█████████▎| 93/100 [29:04<02:04, 17.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:49:29,509] Trial 92 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 684, 'classification__n_estimators': 677, 'classification__learning_rate': 0.005319868892465408, 'classification__max_depth': 6, 'classification__subsample': 0.6592839067682047, 'classification__colsample_bytree': 0.7657558293195122, 'classification__lambda': 1.532729360184305, 'classification__alpha': 2.6627896886005264, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  94%|█████████▍| 94/100 [29:24<01:50, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:49:49,488] Trial 93 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 726, 'classification__n_estimators': 973, 'classification__learning_rate': 0.006426245294233153, 'classification__max_depth': 5, 'classification__subsample': 0.6709936343449938, 'classification__colsample_bytree': 0.979278368007067, 'classification__lambda': 0.7115191317873807, 'classification__alpha': 0.9127890297454705, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  95%|█████████▌| 95/100 [29:43<01:32, 18.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:50:08,366] Trial 94 finished with value: 0.8628747795414462 and parameters: {'feature_selection__max_features': 651, 'classification__n_estimators': 945, 'classification__learning_rate': 0.007050370817531231, 'classification__max_depth': 6, 'classification__subsample': 0.6089610086291665, 'classification__colsample_bytree': 0.9612594042549487, 'classification__lambda': 0.5775291462529094, 'classification__alpha': 0.6123593151921227, 'classification__min_child_weight': 6}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  96%|█████████▌| 96/100 [30:02<01:14, 18.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:50:26,923] Trial 95 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 786, 'classification__n_estimators': 854, 'classification__learning_rate': 0.004589256397120392, 'classification__max_depth': 6, 'classification__subsample': 0.7058704681910308, 'classification__colsample_bytree': 0.8095879606725076, 'classification__lambda': 2.0186375477607643, 'classification__alpha': 0.4989719594484411, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  97%|█████████▋| 97/100 [30:18<00:53, 17.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:50:42,983] Trial 96 finished with value: 0.8704106280193237 and parameters: {'feature_selection__max_features': 753, 'classification__n_estimators': 715, 'classification__learning_rate': 0.0057164879970536256, 'classification__max_depth': 7, 'classification__subsample': 0.8187960918570798, 'classification__colsample_bytree': 0.615804254219279, 'classification__lambda': 1.3829304454638764, 'classification__alpha': 0.20244216202632048, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  98%|█████████▊| 98/100 [30:38<00:36, 18.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:51:02,687] Trial 97 finished with value: 0.8623361009028628 and parameters: {'feature_selection__max_features': 704, 'classification__n_estimators': 650, 'classification__learning_rate': 0.004038335977760738, 'classification__max_depth': 12, 'classification__subsample': 0.7284470197584081, 'classification__colsample_bytree': 0.9375634025817563, 'classification__lambda': 1.140905854511062, 'classification__alpha': 0.17665213359847412, 'classification__min_child_weight': 4}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411:  99%|█████████▉| 99/100 [30:54<00:17, 17.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:51:18,913] Trial 98 finished with value: 0.843260090384915 and parameters: {'feature_selection__max_features': 482, 'classification__n_estimators': 889, 'classification__learning_rate': 0.0036352831479841484, 'classification__max_depth': 5, 'classification__subsample': 0.6852463620544742, 'classification__colsample_bytree': 0.9498076620197144, 'classification__lambda': 12.857004304288441, 'classification__alpha': 4.2335189121619905, 'classification__min_child_weight': 5}. Best is trial 15 with value: 0.8704106280193237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.870411: 100%|██████████| 100/100 [31:00<00:00, 18.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 02:51:24,602] Trial 99 finished with value: 0.8628747795414462 and parameters: {'feature_selection__max_features': 320, 'classification__n_estimators': 574, 'classification__learning_rate': 0.006181712960940829, 'classification__max_depth': 4, 'classification__subsample': 0.6362107729561277, 'classification__colsample_bytree': 0.9245900674378511, 'classification__lambda': 0.8176805240129692, 'classification__alpha': 1.2970802092354354, 'classification__min_child_weight': 7}. Best is trial 15 with value: 0.8704106280193237.\n",
      "\n",
      "--- Optuna Search Complete ---\n",
      "Best validation F1-score: 0.8704106280193237\n",
      "\n",
      "--- Final Best Hyperparameters for Production Model ---\n",
      "{'feature_selection__max_features': 368, 'classification__n_estimators': 880, 'classification__learning_rate': 0.006114714583116497, 'classification__max_depth': 15, 'classification__subsample': 0.901700668393699, 'classification__colsample_bytree': 0.7847195847246358, 'classification__lambda': 1.4045286841754425, 'classification__alpha': 0.1201110470614429, 'classification__min_child_weight': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "N_TRIALS = 100  \n",
    "VALIDATION_SET_SIZE = 0.2 # Use 20% of the data for validation in each trial.\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "def final_objective(trial, X_train_full, y_train_full):\n",
    "    params = {\n",
    "        'feature_selection__max_features': trial.suggest_int('feature_selection__max_features', 10, 1000),\n",
    "        'classification__n_estimators': trial.suggest_int('classification__n_estimators', 50, 1000),\n",
    "        'classification__learning_rate': trial.suggest_float('classification__learning_rate', 1e-3, 0.01, log=True),\n",
    "        'classification__max_depth': trial.suggest_int('classification__max_depth', 3, 15),\n",
    "        'classification__subsample': trial.suggest_float('classification__subsample', 0.6, 1.0),\n",
    "        'classification__colsample_bytree': trial.suggest_float('classification__colsample_bytree', 0.6, 1.0),\n",
    "        'classification__lambda': trial.suggest_float('classification__lambda', 0.1, 30.0, log=True),\n",
    "        'classification__alpha': trial.suggest_float('classification__alpha', 0.1, 20.0, log=True),\n",
    "        'classification__min_child_weight': trial.suggest_int('classification__min_child_weight', 1, 10)\n",
    "    }\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('feature_selection', SelectFromModel(RandomForestClassifier(random_state=42))),\n",
    "        ('classification', XGBClassifier(random_state=42, eval_metric='mlogloss'))\n",
    "    ])\n",
    "    pipeline.set_params(**params)\n",
    "\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=VALIDATION_SET_SIZE, random_state=42)\n",
    "    train_idx, val_idx = next(sss.split(X_train_full, y_train_full))\n",
    "\n",
    "    X_train, X_val = X_train_full.iloc[train_idx], X_train_full.iloc[val_idx]\n",
    "    y_train, y_val = y_train_full[train_idx], y_train_full[val_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    predictions = pipeline.predict(X_val)\n",
    "    score = f1_score(y_val, predictions, average='macro')\n",
    "\n",
    "    return score\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train_full, y_train_full = create_sub_writers_bootstrap(\n",
    "        train_df=all_writers_info,\n",
    "        feature_store=feature_store,\n",
    "        images_per_subwriter=4,\n",
    "        fold_seed=42 \n",
    "    )\n",
    "    print(f\"Augmented training set created with {len(X_train_full)} samples.\")\n",
    "\n",
    "    print(f\"\\nStarting Optuna hyperparameter search for {N_TRIALS} trials...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    objective_with_data = lambda trial: final_objective(trial, X_train_full, y_train_full)\n",
    "    \n",
    "    study.optimize(objective_with_data, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "    final_best_params = study.best_params\n",
    "    print(\"\\n--- Optuna Search Complete ---\")\n",
    "    print(f\"Best validation F1-score: {study.best_value}\")\n",
    "    print(\"\\n--- Final Best Hyperparameters for Production Model ---\")\n",
    "    print(final_best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b997dd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;smote&#x27;, SMOTE(random_state=42)),\n",
       "                (&#x27;feature_selection&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42),\n",
       "                                 max_features=368)),\n",
       "                (&#x27;classification&#x27;,\n",
       "                 XGBClassifier(alpha=0.1201110470614429, base_score=None,\n",
       "                               booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.78...\n",
       "                               feature_types=None, feature_weights=None,\n",
       "                               gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               lambda=1.4045286841754425,\n",
       "                               learning_rate=0.006114714583116497, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=15,\n",
       "                               max_leaves=None, min_child_weight=5, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=880, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;smote&#x27;, SMOTE(random_state=42)),\n",
       "                (&#x27;feature_selection&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42),\n",
       "                                 max_features=368)),\n",
       "                (&#x27;classification&#x27;,\n",
       "                 XGBClassifier(alpha=0.1201110470614429, base_score=None,\n",
       "                               booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.78...\n",
       "                               feature_types=None, feature_weights=None,\n",
       "                               gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               lambda=1.4045286841754425,\n",
       "                               learning_rate=0.006114714583116497, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=15,\n",
       "                               max_leaves=None, min_child_weight=5, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=880, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SMOTE</div></div></label><div class=\"sk-toggleable__content \"><pre>SMOTE(random_state=42)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>feature_selection: SelectFromModel</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_selection.SelectFromModel.html\">?<span>Documentation for feature_selection: SelectFromModel</span></a></div></label><div class=\"sk-toggleable__content \"><pre>SelectFromModel(estimator=RandomForestClassifier(random_state=42),\n",
       "                max_features=368)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>estimator: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content \"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content \"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content \"><pre>XGBClassifier(alpha=0.1201110470614429, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7847195847246358, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;mlogloss&#x27;, feature_types=None, feature_weights=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, lambda=1.4045286841754425,\n",
       "              learning_rate=0.006114714583116497, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=15, max_leaves=None,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=880, ...)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('smote', SMOTE(random_state=42)),\n",
       "                ('feature_selection',\n",
       "                 SelectFromModel(estimator=RandomForestClassifier(random_state=42),\n",
       "                                 max_features=368)),\n",
       "                ('classification',\n",
       "                 XGBClassifier(alpha=0.1201110470614429, base_score=None,\n",
       "                               booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.78...\n",
       "                               feature_types=None, feature_weights=None,\n",
       "                               gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               lambda=1.4045286841754425,\n",
       "                               learning_rate=0.006114714583116497, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=15,\n",
       "                               max_leaves=None, min_child_weight=5, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=880, ...))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import optuna\n",
    "from optuna.distributions import FloatDistribution, IntDistribution\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import joblib\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('smote', SMOTE(random_state=42)),\n",
    "            ('feature_selection', SelectFromModel(RandomForestClassifier(random_state=42))),\n",
    "            ('classification', XGBClassifier(random_state=42, eval_metric='mlogloss'))\n",
    "        ])\n",
    "\n",
    "\n",
    "best_hyperparameters = final_best_params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipeline.set_params(**best_hyperparameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3491f44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 3 4 5 6]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0|mean</th>\n",
       "      <th>0|median</th>\n",
       "      <th>0|std</th>\n",
       "      <th>0|skew</th>\n",
       "      <th>1|mean</th>\n",
       "      <th>1|median</th>\n",
       "      <th>1|std</th>\n",
       "      <th>1|skew</th>\n",
       "      <th>2|mean</th>\n",
       "      <th>2|median</th>\n",
       "      <th>...</th>\n",
       "      <th>637|std</th>\n",
       "      <th>637|skew</th>\n",
       "      <th>638|mean</th>\n",
       "      <th>638|median</th>\n",
       "      <th>638|std</th>\n",
       "      <th>638|skew</th>\n",
       "      <th>639|mean</th>\n",
       "      <th>639|median</th>\n",
       "      <th>639|std</th>\n",
       "      <th>639|skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.040413</td>\n",
       "      <td>1.280957</td>\n",
       "      <td>0.507247</td>\n",
       "      <td>-1.634625</td>\n",
       "      <td>-1.159289</td>\n",
       "      <td>-1.241885</td>\n",
       "      <td>0.464899</td>\n",
       "      <td>0.226526</td>\n",
       "      <td>1.880857</td>\n",
       "      <td>2.063291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694412</td>\n",
       "      <td>-0.121321</td>\n",
       "      <td>-0.798057</td>\n",
       "      <td>-0.891258</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>1.456927</td>\n",
       "      <td>2.265608</td>\n",
       "      <td>2.281312</td>\n",
       "      <td>0.613156</td>\n",
       "      <td>-0.070073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.934578</td>\n",
       "      <td>-0.684685</td>\n",
       "      <td>0.876675</td>\n",
       "      <td>-0.531585</td>\n",
       "      <td>-1.353505</td>\n",
       "      <td>-1.126178</td>\n",
       "      <td>0.485313</td>\n",
       "      <td>-0.955035</td>\n",
       "      <td>-0.034474</td>\n",
       "      <td>-0.115520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.043964</td>\n",
       "      <td>0.250822</td>\n",
       "      <td>-0.734064</td>\n",
       "      <td>-0.966799</td>\n",
       "      <td>0.707600</td>\n",
       "      <td>1.696434</td>\n",
       "      <td>-0.382077</td>\n",
       "      <td>-0.125341</td>\n",
       "      <td>0.555364</td>\n",
       "      <td>-0.791461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.588434</td>\n",
       "      <td>-0.489132</td>\n",
       "      <td>0.626406</td>\n",
       "      <td>0.217603</td>\n",
       "      <td>-0.098024</td>\n",
       "      <td>-0.090292</td>\n",
       "      <td>0.398646</td>\n",
       "      <td>0.237709</td>\n",
       "      <td>-0.224826</td>\n",
       "      <td>-0.164748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706273</td>\n",
       "      <td>-0.112840</td>\n",
       "      <td>-0.673228</td>\n",
       "      <td>-0.783320</td>\n",
       "      <td>0.388836</td>\n",
       "      <td>0.768802</td>\n",
       "      <td>1.231104</td>\n",
       "      <td>1.344649</td>\n",
       "      <td>0.723773</td>\n",
       "      <td>-0.476075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.085146</td>\n",
       "      <td>0.121908</td>\n",
       "      <td>0.921798</td>\n",
       "      <td>-0.473916</td>\n",
       "      <td>0.415825</td>\n",
       "      <td>0.346491</td>\n",
       "      <td>0.712960</td>\n",
       "      <td>0.447135</td>\n",
       "      <td>1.307174</td>\n",
       "      <td>1.396539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875910</td>\n",
       "      <td>-1.390163</td>\n",
       "      <td>-1.015302</td>\n",
       "      <td>-0.808681</td>\n",
       "      <td>0.640124</td>\n",
       "      <td>-1.573374</td>\n",
       "      <td>1.290129</td>\n",
       "      <td>1.042611</td>\n",
       "      <td>0.776999</td>\n",
       "      <td>1.529961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.493525</td>\n",
       "      <td>-0.451743</td>\n",
       "      <td>0.309951</td>\n",
       "      <td>-0.359937</td>\n",
       "      <td>-0.484127</td>\n",
       "      <td>-0.508899</td>\n",
       "      <td>0.491227</td>\n",
       "      <td>0.855808</td>\n",
       "      <td>-0.000721</td>\n",
       "      <td>0.027293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550214</td>\n",
       "      <td>-0.093284</td>\n",
       "      <td>-0.666505</td>\n",
       "      <td>-0.790870</td>\n",
       "      <td>0.448327</td>\n",
       "      <td>2.162568</td>\n",
       "      <td>0.404768</td>\n",
       "      <td>0.603208</td>\n",
       "      <td>0.371432</td>\n",
       "      <td>-1.817523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.929685</td>\n",
       "      <td>-0.900334</td>\n",
       "      <td>0.618008</td>\n",
       "      <td>-0.059490</td>\n",
       "      <td>-1.082905</td>\n",
       "      <td>-0.961740</td>\n",
       "      <td>0.465567</td>\n",
       "      <td>-1.370025</td>\n",
       "      <td>0.395181</td>\n",
       "      <td>0.418887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405486</td>\n",
       "      <td>-0.012981</td>\n",
       "      <td>-0.542955</td>\n",
       "      <td>-0.543840</td>\n",
       "      <td>0.459550</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>-0.114262</td>\n",
       "      <td>0.064019</td>\n",
       "      <td>0.611162</td>\n",
       "      <td>-1.255014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 2560 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0|mean  0|median     0|std    0|skew    1|mean  1|median     1|std  \\\n",
       "0  1.040413  1.280957  0.507247 -1.634625 -1.159289 -1.241885  0.464899   \n",
       "1 -0.934578 -0.684685  0.876675 -0.531585 -1.353505 -1.126178  0.485313   \n",
       "2 -0.588434 -0.489132  0.626406  0.217603 -0.098024 -0.090292  0.398646   \n",
       "3 -0.085146  0.121908  0.921798 -0.473916  0.415825  0.346491  0.712960   \n",
       "4 -0.493525 -0.451743  0.309951 -0.359937 -0.484127 -0.508899  0.491227   \n",
       "5 -0.929685 -0.900334  0.618008 -0.059490 -1.082905 -0.961740  0.465567   \n",
       "\n",
       "     1|skew    2|mean  2|median  ...   637|std  637|skew  638|mean  \\\n",
       "0  0.226526  1.880857  2.063291  ...  0.694412 -0.121321 -0.798057   \n",
       "1 -0.955035 -0.034474 -0.115520  ...  1.043964  0.250822 -0.734064   \n",
       "2  0.237709 -0.224826 -0.164748  ...  0.706273 -0.112840 -0.673228   \n",
       "3  0.447135  1.307174  1.396539  ...  0.875910 -1.390163 -1.015302   \n",
       "4  0.855808 -0.000721  0.027293  ...  0.550214 -0.093284 -0.666505   \n",
       "5 -1.370025  0.395181  0.418887  ...  0.405486 -0.012981 -0.542955   \n",
       "\n",
       "   638|median   638|std  638|skew  639|mean  639|median   639|std  639|skew  \n",
       "0   -0.891258  0.593199  1.456927  2.265608    2.281312  0.613156 -0.070073  \n",
       "1   -0.966799  0.707600  1.696434 -0.382077   -0.125341  0.555364 -0.791461  \n",
       "2   -0.783320  0.388836  0.768802  1.231104    1.344649  0.723773 -0.476075  \n",
       "3   -0.808681  0.640124 -1.573374  1.290129    1.042611  0.776999  1.529961  \n",
       "4   -0.790870  0.448327  2.162568  0.404768    0.603208  0.371432 -1.817523  \n",
       "5   -0.543840  0.459550  0.008677 -0.114262    0.064019  0.611162 -1.255014  \n",
       "\n",
       "[6 rows x 2560 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test, y_test = create_writer_level_profile(real_world_data, all_features)\n",
    "display(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99156986",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train_full, y_train_full)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e72c15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0525282 , 0.07964426, 0.8678275 ],\n",
       "       [0.02773642, 0.07820041, 0.89406323],\n",
       "       [0.01624911, 0.04607202, 0.9376788 ],\n",
       "       [0.01100672, 0.03801341, 0.9509799 ],\n",
       "       [0.02335433, 0.03333496, 0.9433108 ],\n",
       "       [0.07614478, 0.0617345 , 0.86212075]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dba1bebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[0 0 3]\n",
      " [0 0 3]\n",
      " [0 0 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(type(cm))\n",
    "print(cm)\n",
    "cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['German', 'French', 'English']).plot(cmap='viridis', values_format='d')\n",
    "cm_disp\n",
    "\n",
    "colorbar = cm_disp.im_.colorbar\n",
    "colorbar.set_ticks([0, 1, 2, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf92641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525beb16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
